# Convolutional Implementation of Sliding Windows

## Introduction

The convolutional implementation of sliding windows is an efficient technique for object detection that eliminates redundant computations by converting a network to be fully convolutional and processing all window positions in a single forward pass.

## Traditional Sliding Window Approach

### The Basic Algorithm

For each position in the image with a fixed stride, we extract a window and run it through a CNN classifier. This requires many forward passes.

**Example:**
```
Image size: 1000×1000
Window size: 100×100
Stride: 20
Windows needed: 46×46 = 2,116 windows
Forward passes: 2,116 separate passes
```

### The Redundancy Problem

Windows overlap, causing the same pixels to be processed multiple times. A pixel at the center might be processed 16+ times, while edge pixels only once.

## The Convolutional Solution

### Key Insight

Convolution already slides filters across images. By making the network fully convolutional, we can process all windows simultaneously.

**Traditional:** Extract N windows → Run CNN N times → N predictions

**Convolutional:** Run FCN once → Get N predictions in output grid

### How It Works

Convert fully connected layers to convolutional layers with appropriate kernel sizes. The network can then process larger inputs and produce multiple predictions.

**Example:**
```
Training: 14×14 input → 1×1×4 output (single prediction)
Testing: 28×28 input → 8×8×4 output (64 predictions)
```

## Converting FC to Convolutional

### The Conversion Rule

A fully connected layer operating on features of shape H×W×C becomes a convolutional layer with kernel size H×W.

**Example:**
```
FC layer: 5×5×8 = 200 inputs → 120 outputs
Becomes: Conv 5×5, 8 input channels, 120 output channels
```

### Complete Example

**Original Network:**
```
14×14×3 input
Conv 5×5, 8 filters → 10×10×8
MaxPool 2×2, stride=2 → 5×5×8
Flatten → 200 values
FC: 200 → 200
FC: 200 → 4 classes
```

**Converted:**
```
H×W×3 input
Conv 5×5, 8 filters → depends on H,W
MaxPool 2×2, stride=2 → depends on H,W
Conv 5×5, 200 filters → spatial output
Conv 1×1, 200 filters → spatial output
Conv 1×1, 4 filters → spatial_grid×4
```

## Mathematical Formulation

### Equivalence

At each output position i,j:
```
FCN_output[i,j] = Original_CNN(window at corresponding input position)
```

Same computation, different organization.

### Shape Analysis

For original network trained on size N×N:
```
Input: N×N → Output: 1×1×K (K classes)
Input: 2N×2N → Output: M×M×K (M predictions)
```

The value of M depends on network architecture and stride.

## Computational Savings

### Speedup Analysis

**Traditional:** N windows × T time per window = N×T

**FCN:** Approximately T × area_ratio time

**Example:**
```
100 windows on 224×224 image
Traditional: 100T
FCN: approximately 1.2T
Speedup: 83×
```

More windows = greater speedup. With 1000 windows, approximately 800× faster!

## Forward Propagation

### Algorithm

```
1. Pass full image through convolutional layers
2. Apply converted FC layers as convolutions
3. Output is spatial grid where each position is a window prediction
4. Threshold and extract detections
```

### Numerical Example

Network trained on 6×6 produces 5×5×2 features before FC.

Testing on 10×10:
```
10×10 → Conv layers → 9×9×2
      → Conv 5×5 (FC replacement) → 5×5×2

Each of 25 positions contains class scores for a window
```

## Backward Propagation

### Gradient Flow

Backpropagation is standard CNN backprop. The network processes one large input, not N separate windows.

**Traditional:** N backprop passes, accumulate gradients

**FCN:** 1 backprop pass, gradients computed over all positions

Speedup: N× faster

## Summary

The convolutional implementation converts sliding window detection into a single forward pass by:

1. Making the network fully convolutional
2. Replacing FC layers with Conv layers
3. Processing the full image once
4. Getting spatial output where each position = one window prediction

**Key Benefits:**
- Massive speedup (10-1000×)
- Shared computation
- Single forward/backward pass
- Enables real-time detection

This technique is fundamental to modern object detection systems.