# Intersection Over Union, Non-Maximum Suppression, and Anchor Boxes

## Table of Contents

1. [Intersection Over Union (IoU)](#intersection-over-union-iou)
2. [Non-Maximum Suppression (NMS)](#non-maximum-suppression-nms)
3. [Anchor Boxes](#anchor-boxes)
4. [Putting It All Together](#putting-it-all-together)

---

## Intersection Over Union (IoU)

### What is IoU?

**Plain English Overview:**

Intersection over Union (IoU) is a metric that measures how much two bounding boxes overlap. It answers the question: "How well does the predicted box match the actual box?" The value ranges from 0 (no overlap) to 1 (perfect match).

**Analogy:** Imagine you and a friend are both trying to draw a circle around the same object in a photo. IoU measures how well your circles agree. If your circles perfectly overlap, IoU = 1 (100% agreement). If they don't touch at all, IoU = 0 (no agreement). If they partially overlap, IoU is between 0 and 1.

**Visual Illustration:**

```
Two Bounding Boxes:

Box A (Predicted):          Box B (Ground Truth):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          â”‚               â”‚          â”‚
â”‚   Car?   â”‚               â”‚   Car    â”‚
â”‚          â”‚               â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

When overlaid:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  
â”‚   â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚   â”‚  â–‘ = Intersection (both boxes)
â”‚   â”‚ â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚   â”‚  
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  Entire shaded area = Union (either box)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

IoU = Area of Intersection / Area of Union
```

### Mathematical Formula

**Complete Formula:**

```
IoU(A, B) = Area(A âˆ© B) / Area(A âˆª B)
```

**Symbol Legend:**
- `A`: Predicted bounding box
- `B`: Ground truth bounding box (or another predicted box)
- `A âˆ© B`: Intersection (overlap region)
- `A âˆª B`: Union (combined area covered by both boxes)
- `Area()`: Function computing area in pixels

**Expanded Formula:**

```
IoU = Intersection_Area / (Area_A + Area_B - Intersection_Area)
```

Why subtract intersection? Because union means "area covered by A OR B", and if we just add the areas, we count the overlap twice.

**Bounding Box Representation:**

```
Box = (x_min, y_min, x_max, y_max)

Where:
- (x_min, y_min): top-left corner
- (x_max, y_max): bottom-right corner

Area = (x_max - x_min) Ã— (y_max - y_min)
```

### Step-by-Step IoU Calculation

**Example 1: Moderate Overlap**

**Given:**
```
Box A (predicted): (50, 50, 150, 150)
  Top-left: (50, 50)
  Bottom-right: (150, 150)
  Width: 150 - 50 = 100
  Height: 150 - 50 = 100
  Area_A = 100 Ã— 100 = 10,000 pixels

Box B (ground truth): (100, 100, 200, 200)
  Top-left: (100, 100)
  Bottom-right: (200, 200)
  Width: 200 - 100 = 100
  Height: 200 - 100 = 100
  Area_B = 100 Ã— 100 = 10,000 pixels
```

**Visual:**

```
Coordinate system (showing relevant region):
    50      100     150     200
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
50  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”        
    â”‚   A    â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚        
    â”‚        â”‚â–‘ Inter-â”‚        
100 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â–‘sectionâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚   B    â”‚
    â”‚        â”‚        â”‚        â”‚
150 â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
             â”‚        â”‚        â”‚
             â”‚        â”‚        â”‚
200          â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Box A: from (50,50) to (150,150)
Box B: from (100,100) to (200,200)
Intersection: from (100,100) to (150,150)
```

**Step 1: Calculate Intersection**

```
Intersection_x_min = max(A_x_min, B_x_min) = max(50, 100) = 100
Intersection_y_min = max(A_y_min, B_y_min) = max(50, 100) = 100
Intersection_x_max = min(A_x_max, B_x_max) = min(150, 200) = 150
Intersection_y_max = min(A_y_max, B_y_max) = min(150, 200) = 150

Intersection_width = 150 - 100 = 50
Intersection_height = 150 - 100 = 50
Intersection_Area = 50 Ã— 50 = 2,500 pixels
```

**Step 2: Calculate Union**

```
Union_Area = Area_A + Area_B - Intersection_Area
           = 10,000 + 10,000 - 2,500
           = 17,500 pixels
```

**Step 3: Calculate IoU**

```
IoU = Intersection_Area / Union_Area
    = 2,500 / 17,500
    = 0.1429
    â‰ˆ 0.14 or 14.3% overlap
```

**Interpretation:** IoU of 0.14 indicates poor overlap. The boxes partially overlap but don't match well.

**Example 2: High Overlap**

**Given:**
```
Box A: (50, 50, 150, 150)  - Area = 10,000
Box B: (60, 60, 150, 150)  - Area = 8,100
```

**Visual:**
```
    50      60      150
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
50  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”        
    â”‚   A    â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚        
    â”‚        â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚        
60  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  
    â”‚        â”‚â–‘â–‘ B â–‘â–‘â–‘â”‚  Most of B inside A
    â”‚        â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  High overlap!
150 â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Intersection: (60, 60, 150, 150)
```

**Calculation:**

```
Intersection:
width = 150 - 60 = 90
height = 150 - 60 = 90
area = 90 Ã— 90 = 8,100

Union:
area = 10,000 + 8,100 - 8,100 = 10,000

IoU = 8,100 / 10,000 = 0.81 or 81%
```


**Common IoU Thresholds:**

```
IoU â‰¥ 0.5: Often used as "correct detection" threshold
IoU â‰¥ 0.7: Stricter threshold for high-quality detections
IoU â‰¥ 0.9: Very strict, requires near-perfect alignment

In practice:
- IoU < 0.3: Usually considered a miss
- 0.3 â‰¤ IoU < 0.5: Borderline, might need review
- IoU â‰¥ 0.5: Generally accepted as correct
- IoU â‰¥ 0.75: High-quality detection
```

### When and How to Use IoU

**Use Case 1: Evaluating Detections**

Compare predicted boxes with ground truth:

```
For each predicted box:
  Find best matching ground truth box (highest IoU)
  If IoU â‰¥ threshold: True Positive
  If IoU < threshold: False Positive

For each ground truth box not matched:
  False Negative
```

**Use Case 2: Training Object Detectors**

IoU helps assign predictions to ground truth during training:

```
For each anchor/predicted box:
  Calculate IoU with all ground truth boxes
  If max_IoU â‰¥ 0.5: This is a positive example (train to detect object)
  If max_IoU < 0.3: This is a negative example (train to reject)
  If 0.3 â‰¤ max_IoU < 0.5: Ignore (ambiguous)
```

**Use Case 3: Non-Maximum Suppression (see next section)**

IoU determines which boxes are duplicates and should be suppressed.

---

## Non-Maximum Suppression (NMS)

### What is NMS?

**Plain English Overview:**

Non-Maximum Suppression (NMS) is a post-processing technique that eliminates duplicate detections of the same object. Object detectors often produce multiple overlapping bounding boxes for a single object (especially with sliding windows). NMS keeps only the best detection and removes the redundant ones.

**Analogy:** Imagine 10 people all trying to point at the same car in a photo. Everyone's finger points to roughly the same location, but with slight variations. NMS is like saying "Okay, we all agree there's a car here. Let's just keep the most confident person's answer and ignore the other 9 to avoid confusion."

**Visual Problem NMS Solves:**

```
Before NMS (Multiple Detections for Same Car):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                        â”‚
â”‚     â”â”â”â”â”â”â”â”“                          â”‚
â”‚     â”ƒ 0.92 â”ƒ  â”â”â”â”â”â”â”â”“               â”‚
â”‚     â”ƒ      â”ƒ  â”ƒ 0.88 â”ƒ               â”‚
â”‚     â”ƒ  ğŸš—  â”ƒ  â”ƒ      â”ƒ  â”â”â”â”â”â”â”â”“    â”‚
â”‚     â”ƒ      â”ƒ  â”ƒ      â”ƒ  â”ƒ 0.75 â”ƒ    â”‚
â”‚     â”—â”â”â”â”â”â”â”›  â”—â”â”â”â”â”â”â”›  â”—â”â”â”â”â”â”â”›    â”‚
â”‚     Detection  Detection  Detection   â”‚
â”‚     conf=0.92  conf=0.88  conf=0.75   â”‚
â”‚                                        â”‚
â”‚     All three boxes detect same car!   â”‚
â”‚     Redundant detections               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After NMS (Clean Single Detection):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                        â”‚
â”‚     â”â”â”â”â”â”â”â”“                          â”‚
â”‚     â”ƒ 0.92 â”ƒ                           â”‚
â”‚     â”ƒ      â”ƒ                           â”‚
â”‚     â”ƒ  ğŸš—  â”ƒ                           â”‚
â”‚     â”ƒ      â”ƒ                           â”‚
â”‚     â”—â”â”â”â”â”â”â”›                          â”‚
â”‚     Best detection kept                â”‚
â”‚     (highest confidence)               â”‚
â”‚                                        â”‚
â”‚     Other boxes suppressed             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Duplicate Detection Problem

**Why It Happens:**

```
Sliding window detector produces boxes at many positions:

Grid of windows (stride=4):
â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ W â”‚ W â”‚ W â”‚ W â”‚ W â”‚ W â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ W â”‚ W â”‚ W â”‚ W â”‚ W â”‚ W â”‚  W = Window position
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ W â”‚ W â”‚ W â”‚ W â”‚ W â”‚ W â”‚  Each gets classified
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ W â”‚ W â”‚ W â”‚ W â”‚ W â”‚ W â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

If car is at center:
        â”Œâ”€â”€â”€ Car location â”€â”€â”€â”
        â”‚                    â”‚
        â†“                    â†“
â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚0.1â”‚0.2â”‚0.3â”‚0.2â”‚0.1â”‚0.0â”‚  Numbers = confidence
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  that window contains car
â”‚0.2â”‚0.4â”‚0.9â”‚0.5â”‚0.2â”‚0.1â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  Multiple windows detect
â”‚0.3â”‚0.8â”‚0.95â”‚0.7â”‚0.3â”‚0.1â”‚ the same car!
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚0.1â”‚0.4â”‚0.6â”‚0.3â”‚0.1â”‚0.0â”‚  Need to keep only best one
â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
```

### NMS Algorithm

**Complete Algorithm:**

```
Algorithm: Non-Maximum Suppression

Input:
  - boxes: List of detected bounding boxes
  - scores: Confidence score for each box
  - iou_threshold: Overlap threshold (typically 0.5)

Output:
  - selected_boxes: Filtered list of boxes

Steps:

1. Sort all boxes by confidence score (descending)
   boxes_sorted = sort(boxes, by=scores, descending=True)

2. Initialize empty list for results:
   selected = []

3. While boxes_sorted is not empty:
   
   a. Take box with highest confidence:
      best_box = boxes_sorted[0]
      selected.append(best_box)
      boxes_sorted.remove(best_box)
   
   b. Remove all boxes that overlap significantly with best_box:
      For each remaining box in boxes_sorted:
         iou = calculate_IoU(best_box, box)
         if iou > iou_threshold:
            boxes_sorted.remove(box)  # Suppress this box
   
   c. Repeat until no boxes left

4. Return selected

Result: Only non-overlapping boxes (or minimally overlapping) remain
```

### Detailed NMS Example

**Scenario:** 6 detections of the same car

**Given Detections:**

```
Detection 1: Box=(50,50,150,150),   Score=0.95  (highest confidence)
Detection 2: Box=(55,55,155,155),   Score=0.88
Detection 3: Box=(60,50,160,150),   Score=0.82
Detection 4: Box=(45,48,145,148),   Score=0.75
Detection 5: Box=(200,50,300,150),  Score=0.70  (different location!)
Detection 6: Box=(52,52,148,152),   Score=0.65
```

**Visual Layout:**

```
Image showing all 6 detections:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚  â”â”â”â”â”â”â”â”“                                  â”‚
â”‚  â”ƒDet 4 â”ƒ  â”â”â”â”â”â”â”â”“                        â”‚
â”‚  â”ƒ0.75  â”ƒ  â”ƒDet 1 â”ƒ  â”â”â”â”â”â”â”â”“             â”‚
â”‚  â”ƒ      â”ƒ  â”ƒ0.95  â”ƒ  â”ƒDet 3 â”ƒ             â”‚
â”‚  â”ƒ  ğŸš—  â”ƒ  â”ƒ      â”ƒ  â”ƒ0.82  â”ƒ             â”‚
â”‚  â”—â”â”â”â”â”â”â”›  â”ƒ      â”ƒ  â”—â”â”â”â”â”â”â”›             â”‚
â”‚     â”â”â”â”â”â”â”â”«      â”ƒ                        â”‚
â”‚     â”ƒDet 6 â”ƒ      â”ƒ   â”â”â”â”â”â”â”â”“            â”‚
â”‚     â”ƒ0.65  â”ƒ      â”ƒ   â”ƒDet 2 â”ƒ            â”‚
â”‚     â”—â”â”â”â”â”â”â”›      â”ƒ   â”ƒ0.88  â”ƒ            â”‚
â”‚            â”—â”â”â”â”â”â”â”›   â”—â”â”â”â”â”â”â”›            â”‚
â”‚                                             â”‚
â”‚                    â”â”â”â”â”â”â”â”“                â”‚
â”‚                    â”ƒDet 5 â”ƒ                â”‚
â”‚                    â”ƒ0.70  â”ƒ Different car! â”‚
â”‚                    â”ƒ  ğŸš—  â”ƒ                â”‚
â”‚                    â”—â”â”â”â”â”â”â”›                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Detections 1,2,3,4,6: Same car (will suppress duplicates)
Detection 5: Different car (will keep)
```

**NMS Process (IoU threshold = 0.5):**

**Iteration 1:**

```
Step 1: Sort by score
[Det1(0.95), Det2(0.88), Det3(0.82), Det4(0.75), Det5(0.70), Det6(0.65)]

Step 2: Take highest score
best = Det1 (score=0.95)
selected = [Det1]

Step 3: Calculate IoU with remaining boxes

Det1 vs Det2:
Box1: (50,50,150,150)
Box2: (55,55,155,155)
Intersection: (55,55,150,150) = 95Ã—95 = 9,025
Union: 10,000 + 10,000 - 9,025 = 10,975
IoU = 9,025/10,975 = 0.82 > 0.5  â†’ SUPPRESS Det2

Det1 vs Det3:
Box1: (50,50,150,150)
Box3: (60,50,160,150)
Intersection: (60,50,150,150) = 90Ã—100 = 9,000
Union: 10,000 + 10,000 - 9,000 = 11,000
IoU = 9,000/11,000 = 0.82 > 0.5  â†’ SUPPRESS Det3

Det1 vs Det4:
Box1: (50,50,150,150)
Box4: (45,48,145,148)
Intersection: (50,50,145,148) = 95Ã—98 = 9,310
Union: 10,000 + 9,800 - 9,310 = 10,490
IoU = 9,310/10,490 = 0.89 > 0.5  â†’ SUPPRESS Det4

Det1 vs Det5:
Box1: (50,50,150,150)
Box5: (200,50,300,150)
No overlap â†’ IoU = 0 < 0.5  â†’ KEEP Det5

Det1 vs Det6:
Box1: (50,50,150,150)
Box6: (52,52,148,152)
Intersection: (52,52,148,148) = 96Ã—96 = 9,216
Union: 10,000 + 9,216 - 9,216 = 10,000
IoU = 9,216/10,000 = 0.92 > 0.5  â†’ SUPPRESS Det6

Remaining: [Det5]
```

**Iteration 2:**

```
Step 1: Take next highest
best = Det5 (score=0.70)
selected = [Det1, Det5]

Step 2: No more boxes to compare

Done!
```

**Final Result:**

```
Selected boxes: [Det1, Det5]

Before NMS: 6 detections
After NMS: 2 detections (one for each actual car)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚     â”â”â”â”â”â”â”â”“                               â”‚
â”‚     â”ƒDet 1 â”ƒ                                â”‚
â”‚     â”ƒ0.95  â”ƒ                                â”‚
â”‚     â”ƒ      â”ƒ                                â”‚
â”‚     â”ƒ  ğŸš—  â”ƒ                                â”‚
â”‚     â”—â”â”â”â”â”â”â”›                               â”‚
â”‚                                             â”‚
â”‚                    â”â”â”â”â”â”â”â”“                â”‚
â”‚                    â”ƒDet 5 â”ƒ                â”‚
â”‚                    â”ƒ0.70  â”ƒ                â”‚
â”‚                    â”ƒ  ğŸš—  â”ƒ                â”‚
â”‚                    â”—â”â”â”â”â”â”â”›                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Clean, non-redundant detections!
```

### NMS in Forward/Backward Propagation

**Plain English:**

NMS is a post-processing step that happens AFTER the network's forward pass. It's not part of the network itself - it's an algorithm we apply to the network's outputs.

**In the Detection Pipeline:**

```
Forward Propagation:
Image â†’ CNN â†’ Raw Detections (many overlapping boxes)
         â†“
      No NMS here - just standard CNN forward pass
         â†“
    Output: N detections (may have duplicates)

Post-Processing:
Raw Detections â†’ NMS Algorithm â†’ Final Detections
                      â†“
               Duplicates removed
                      â†“
            M detections (M < N, no duplicates)

Backward Propagation:
Not applicable - NMS has no learnable parameters
It's a discrete selection algorithm, not differentiable
Training uses loss on raw detections, before NMS
```

---

## Anchor Boxes

### What are Anchor Boxes?

**Plain English Overview:**

Anchor boxes (also called prior boxes or default boxes) are pre-defined bounding box templates with specific sizes and aspect ratios. Instead of predicting a box from scratch, the network predicts offsets from these anchors. This makes learning easier and allows detecting multiple objects at the same location.

**Analogy:** Think of anchor boxes like clothing size templates (Small, Medium, Large, XL) in different fits (Regular, Tall, Wide). When someone tries on clothes, we start with the closest template size and make small adjustments (hem length, waist) rather than measuring and cutting from raw fabric. Similarly, object detectors start with anchor box templates and make small adjustments rather than predicting boxes from scratch.

**Key Concept:** Each anchor box is defined by:
- Width and height (or aspect ratio)
- Position in the feature map
- The network predicts: "How much should I adjust this anchor to fit the actual object?"

### The Multi-Object Detection Problem

**The Problem:**

Traditional sliding windows with one prediction per position can only detect one object per window. But what if multiple objects overlap in the same region?

**Visual Example:**

```
Scene: Person holding a dog
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                 â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚      â”‚              â”‚           â”‚
â”‚      â”‚    ğŸ§        â”‚           â”‚  Single window
â”‚      â”‚    Person    â”‚           â”‚  Two objects!
â”‚      â”‚      ğŸ•       â”‚           â”‚
â”‚      â”‚      Dog      â”‚           â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Traditional sliding window: Can only output 1 prediction
"Person" OR "Dog" - can't detect both!

With Anchor Boxes: Can output M predictions (M anchor boxes)
Can predict both person AND dog from same location!
```

**Another Example:**

```
Overlapping objects at different scales:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“       â”‚
â”‚         â”ƒ   Truck      â”ƒ       â”‚  Large object
â”‚         â”ƒ   ğŸš›   â”â”â”â”â”â”ƒâ”â”â”“    â”‚  overlaps with
â”‚         â”ƒ       â”ƒ Car â”ƒ  â”ƒ    â”‚  small object
â”‚         â”—â”â”â”â”â”â”â”â”«  ğŸš—â”ƒâ”â”â”›    â”‚
â”‚                 â”—â”â”â”â”â”›         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Need to detect both truck AND car
They overlap spatially!
Anchor boxes allow multiple detections at same location
```

### How Anchor Boxes Work

**Basic Idea:**

At each position in the feature map, we have K different anchor boxes (different shapes/sizes). The network outputs predictions for ALL K anchors, allowing it to detect multiple objects.

**Visual Illustration:**

```
Single Feature Map Position:

Without Anchor Boxes:              With Anchor Boxes (K=3):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Position (i,j)  â”‚                â”‚ Position (i,j)              â”‚
â”‚                 â”‚                â”‚                             â”‚
â”‚  One anchor:    â”‚                â”‚  Three anchors:             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        â”‚    â”‚                â”‚  â”‚Anchorâ”‚ â”‚  Anchor 2  â”‚   â”‚
â”‚  â”‚        â”‚    â”‚                â”‚  â”‚  1   â”‚ â”‚  (wide)    â”‚   â”‚
â”‚  â”‚        â”‚    â”‚                â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚                 â”‚                â”‚  â”‚ Anchor 3 â”‚              â”‚
â”‚  Predicts:      â”‚                â”‚  â”‚  (tall)  â”‚              â”‚
â”‚  - Class (4)    â”‚                â”‚  â”‚          â”‚              â”‚
â”‚  - Box (4)      â”‚                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚  Total: 8 valuesâ”‚                â”‚                             â”‚
â”‚                 â”‚                â”‚  Each predicts:             â”‚
â”‚ Can detect only â”‚                â”‚  - Class (4)                â”‚
â”‚ 1 object here!  â”‚                â”‚  - Box offsets (4)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  Total: 3 Ã— 8 = 24 values   â”‚
                                   â”‚                             â”‚
                                   â”‚ Can detect up to 3 objects! â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mathematical Formulation:**

**Network Output at Position (i,j):**

```
Without anchors:
Output[i,j,:] = [p_class1, p_class2, p_class3, p_class4, bx, by, bw, bh]
                 \_________class probabilities_________/  \_box coords_/
Size: 8 values (4 classes + 4 box coords)

With K=3 anchors:
Output[i,j,:] = [anchor1_predictions, anchor2_predictions, anchor3_predictions]

anchor1_predictions = [p_c1, p_c2, p_c3, p_c4, tx, ty, tw, th]
anchor2_predictions = [p_c1, p_c2, p_c3, p_c4, tx, ty, tw, th]
anchor3_predictions = [p_c1, p_c2, p_c3, p_c4, tx, ty, tw, th]

Size: 3 Ã— 8 = 24 values
```

**Symbol Legend:**
- `p_ci`: Probability of class i
- `tx, ty`: Offsets for box center (relative to anchor)
- `tw, th`: Scale factors for box size (relative to anchor)
- `K`: Number of anchor boxes per position

### Anchor Box Design

**Common Anchor Box Configurations:**

```
Configuration 1: Different Sizes
Anchor 1: 32Ã—32    (small)
Anchor 2: 64Ã—64    (medium)
Anchor 3: 128Ã—128  (large)

Use case: Detect objects at different scales
â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ A1 â”‚  â”‚  A2  â”‚  â”‚     A3     â”‚
â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Small   Medium    Large object


Configuration 2: Different Aspect Ratios
Anchor 1: 64Ã—64    (square, ratio 1:1)
Anchor 2: 96Ã—48    (wide, ratio 2:1)
Anchor 3: 48Ã—96    (tall, ratio 1:2)

Use case: Detect objects with different shapes
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”
â”‚   A1   â”‚  â”‚      A2      â”‚  â”‚ A3  â”‚
â”‚ Square â”‚  â”‚   Wide       â”‚  â”‚Tall â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚
                               â””â”€â”€â”€â”€â”€â”˜
Person/car   Bus/truck         Bottle/pole


Configuration 3: Combined (3 scales Ã— 3 ratios = 9 anchors)
Small-square,  Small-wide,  Small-tall
Medium-square, Medium-wide, Medium-tall
Large-square,  Large-wide,  Large-tall

Used in: YOLO v3, SSD, Faster R-CNN
```

**Anchor Box Prediction:**

```
Anchor box definition:
anchor = (anchor_width, anchor_height, center_x, center_y)

Network predicts adjustments:
tx = predicted x offset
ty = predicted y offset
tw = predicted width scale
th = predicted height scale

Final box:
box_x = anchor_x + tx Ã— anchor_width
box_y = anchor_y + ty Ã— anchor_height
box_width = anchor_width Ã— exp(tw)
box_height = anchor_height Ã— exp(th)

The exp() ensures positive dimensions
Small adjustments: twâ‰ˆ0, thâ‰ˆ0 â†’ exp(0)=1 â†’ keep anchor size
Larger object: tw>0 â†’ exp(tw)>1 â†’ expand box
```

### Detailed Anchor Box Example

**Scenario:** Detect person and dog at same location

**Setup:**

```
Feature map position: (5, 5)
Two anchor boxes:
Anchor 1: 80Ã—120 (tall, for person)
Anchor 2: 60Ã—40  (wide, for dog)

Ground truth:
Person: (120, 100, 180, 280)  - Height=180, Width=60, tall
Dog: (150, 250, 230, 290)     - Height=40, Width=80, wide
```

**Visual:**

```
Scene:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”                       â”‚ Ground truth person
â”‚     â”‚      â”‚                       â”‚ (60 wide Ã— 180 tall)
â”‚     â”‚  ğŸ§  â”‚                       â”‚
â”‚     â”‚Personâ”‚                       â”‚ Anchor 1: 80Ã—120
â”‚     â”‚      â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚ (tall, good match!)
â”‚     â”‚      â”‚    â”‚   ğŸ•     â”‚      â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”˜    â”‚   Dog    â”‚      â”‚ Ground truth dog
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ (80 wide Ã— 40 tall)
â”‚                                    â”‚
â”‚                                    â”‚ Anchor 2: 60Ã—40
â”‚                                    â”‚ (wide, good match!)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Matching Process:**

**For Person:**
```
Compare with Anchor 1 (80Ã—120):
Person is 60Ã—180 vs Anchor 80Ã—120
Similar aspect ratio (tall)
Assign person to Anchor 1

IoU(Person, Anchor1) â‰ˆ 0.6 (good match)
IoU(Person, Anchor2) â‰ˆ 0.1 (poor match, wrong shape)

Person assigned to Anchor 1 âœ“
```

**For Dog:**
```
Compare with Anchor 2 (60Ã—40):
Dog is 80Ã—40 vs Anchor 60Ã—40
Similar aspect ratio (wide)
Assign dog to Anchor 2

IoU(Dog, Anchor1) â‰ˆ 0.15 (poor match, wrong shape)
IoU(Dog, Anchor2) â‰ˆ 0.7 (good match)

Dog assigned to Anchor 2 âœ“
```

**Network Predictions:**

```
At position (5,5):

Anchor 1 predictions:
- Object confidence: 0.95 (high, person present)
- Class: [0.05, 0.92, 0.02, 0.01] (class 1 = person)
- Box offsets: tx=-0.25, ty=0.0, tw=-0.3, th=0.4
  (adjust anchor to fit actual person box)

Anchor 2 predictions:
- Object confidence: 0.88 (high, dog present)
- Class: [0.02, 0.03, 0.01, 0.94] (class 3 = dog)
- Box offsets: tx=0.3, ty=0.0, tw=0.3, th=0.0
  (adjust anchor to fit actual dog box)

Both objects detected from same feature map position!
```

**Final Box Calculation:**

```
Person (from Anchor 1):
box_x = anchor1_x + (-0.25) Ã— 80 = center_x - 20
box_y = anchor1_y + 0.0 Ã— 120 = center_y
box_width = 80 Ã— exp(-0.3) = 80 Ã— 0.74 = 59.2 â‰ˆ 60 âœ“
box_height = 120 Ã— exp(0.4) = 120 Ã— 1.49 = 178.8 â‰ˆ 180 âœ“

Dog (from Anchor 2):
box_x = anchor2_x + 0.3 Ã— 60 = center_x + 18
box_y = anchor2_y + 0.0 Ã— 40 = center_y
box_width = 60 Ã— exp(0.3) = 60 Ã— 1.35 = 81 â‰ˆ 80 âœ“
box_height = 40 Ã— exp(0.0) = 40 Ã— 1 = 40 âœ“

Both boxes accurately predicted!
```

### Anchor Boxes in Forward/Backward Propagation

**Forward Propagation:**

```
At each feature map position (i,j):

1. For each anchor k=1 to K:
   
   a. Predict object confidence: p_obj
      (Is there an object for this anchor?)
   
   b. Predict class probabilities: [p_c1, p_c2, ..., p_cN]
      (What class is the object?)
   
   c. Predict box offsets: [tx, ty, tw, th]
      (How to adjust anchor to fit object?)

2. Apply offsets to anchor to get predicted box

3. Output shape: (H_feat Ã— W_feat Ã— K Ã— (5+N))
   where 5+N = 1 objectness + N classes + 4 box coords
```

**Backward Propagation:**

```
Loss Function with Anchors:

For each anchor at each position:

1. Match to ground truth:
   If IoU(anchor, any ground truth) > 0.5:
     This anchor is "responsible" for that object
     
2. Compute losses:
   a. Objectness loss (is there an object?)
   b. Classification loss (what class?)
   c. Box regression loss (how far from truth?)

3. Backprop gradients:
   Only for anchors matched to ground truth
   Other anchors: small or zero gradient
   
4. Update network to:
   - Better objectness predictions
   - Better class predictions
   - Better box offset predictions
```

---

## Putting It All Together

### How All Three Concepts Work Together

**Plain English Explanation:**

These three concepts form the core of modern object detection:

1. **Anchor Boxes** provide templates, allowing detection of multiple objects at each position
2. **IoU** determines which anchors match which objects during training and evaluation
3. **NMS** removes duplicate detections after the network runs

Think of it like a manufacturing quality control process:
- **Anchor Boxes** = Standard molds/templates for products
- **IoU** = Measurement tool to check if product matches specification
- **NMS** = Final inspection to remove duplicate products

### Complete Detection Pipeline

**End-to-End Example:**

**Step 1: Network Architecture with Anchors**

```
Input: 416Ã—416Ã—3 image
    â†“ CNN backbone
Feature Map: 13Ã—13Ã—256
    â†“ Detection head
Predictions: 13Ã—13Ã—(KÃ—(5+N))

Where:
- K = 3 anchors per position
- 5 = objectness + 4 box coords
- N = number of classes (e.g., 20)

Total: 13Ã—13Ã—3Ã—25 = 12,675 predictions
```

**Step 2: Apply Anchor Boxes**

```
At each of 13Ã—13 = 169 positions:

For each of K=3 anchors:
  
  Network outputs:
  - p_obj: Probability object exists (0 to 1)
  - [p_c1, ..., p_c20]: Class probabilities
  - [tx, ty, tw, th]: Box offsets
  
  Compute final box:
  box = apply_offsets(anchor, [tx, ty, tw, th])
  
  If p_obj > threshold (e.g., 0.5):
    Create detection: {box, class=argmax(p_ci), score=p_objÃ—p_class}

Total: 169 positions Ã— 3 anchors = 507 potential detections
But most have low p_obj and are filtered out
```

**Step 3: Apply Confidence Threshold**

```
Before: 507 potential detections
Filter by score > 0.3
After: Maybe 50-100 detections remain

Example results:
[{box:(120,80,180,200), class:person, score:0.95},
 {box:(125,85,185,205), class:person, score:0.88},  â† Duplicate!
 {box:(130,82,182,198), class:person, score:0.75},  â† Duplicate!
 {box:(300,150,380,210), class:car, score:0.92},
 {box:(305,152,385,215), class:car, score:0.85},    â† Duplicate!
 {box:(450,200,520,280), class:dog, score:0.78},
  ...]

Still have duplicates (multiple anchors detecting same object)
```

**Step 4: Apply NMS**

```
For each class separately:

Class "person":
Detections: [(120,80,180,200, 0.95), (125,85,185,205, 0.88), (130,82,182,198, 0.75)]
After NMS (IoU threshold=0.5): [(120,80,180,200, 0.95)]
Kept highest confidence, suppressed duplicates

Class "car":
Detections: [(300,150,380,210, 0.92), (305,152,385,215, 0.85)]
After NMS: [(300,150,380,210, 0.92)]

Class "dog":
Detections: [(450,200,520,280, 0.78)]
After NMS: [(450,200,520,280, 0.78)]  (no duplicates)

Final clean detections: 3 boxes (one per object)
```

**Step 5: Final Output**

```
Clean Detections:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”“                                â”‚
â”‚  â”ƒ Person â”ƒ                                 â”‚
â”‚  â”ƒ  0.95  â”ƒ                                 â”‚
â”‚  â”ƒ   ğŸ§   â”ƒ                                 â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”›                                â”‚
â”‚                                             â”‚
â”‚                  â”â”â”â”â”â”â”â”â”â”“                â”‚
â”‚                  â”ƒ  Car   â”ƒ                 â”‚
â”‚                  â”ƒ  0.92  â”ƒ                 â”‚
â”‚                  â”ƒ   ğŸš—   â”ƒ                 â”‚
â”‚                  â”—â”â”â”â”â”â”â”â”â”›                â”‚
â”‚                                             â”‚
â”‚                              â”â”â”â”â”â”â”â”â”â”“    â”‚
â”‚                              â”ƒ  Dog   â”ƒ    â”‚
â”‚                              â”ƒ  0.78  â”ƒ    â”‚
â”‚                              â”ƒ   ğŸ•   â”ƒ    â”‚
â”‚                              â”—â”â”â”â”â”â”â”â”â”›    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Perfect! One clean detection per object.
```

**Complete Pipeline Summary:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Image  â”‚
â”‚  416Ã—416Ã—3   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CNN Feature Extraction      â”‚
â”‚ (Conv + Pool layers)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prediction Layers           â”‚
â”‚ Output: 13Ã—13Ã—(KÃ—(5+N))     â”‚
â”‚ K anchors Ã— predictions     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Apply Anchor Offsets        â”‚
â”‚ Convert predictions to      â”‚
â”‚ actual bounding boxes       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Confidence Thresholding     â”‚
â”‚ Keep only high-conf boxes   â”‚
â”‚ (e.g., score > 0.3)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“ (Many boxes, duplicates)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Non-Maximum Suppression     â”‚
â”‚ Remove duplicate detections â”‚
â”‚ using IoU threshold         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Final Detections â”‚
â”‚ Clean, unique    â”‚
â”‚ bounding boxes   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Summary

**Intersection Over Union (IoU):**
- Measures bounding box overlap (0 to 1)
- Formula: Intersection area / Union area
- Used for: matching, evaluation, NMS
- Threshold: typically 0.5 for "correct"

**Non-Maximum Suppression (NMS):**
- Removes duplicate detections
- Keeps highest confidence box, suppresses overlapping ones
- Uses IoU to determine overlap
- Applied per class after detection

**Anchor Boxes:**
- Pre-defined box templates (sizes/shapes)
- Network predicts offsets from anchors
- Enables multiple objects per position
- Typically 3-9 anchors per position

**Together:**
```
1. Anchors allow detecting multiple objects per location
2. IoU determines which anchors match which objects (training)
3. Network predicts adjustments to anchors
4. IoU used in NMS to remove duplicates (inference)
5. Clean final detections
```

This is the foundation of modern object detectors like YOLO, SSD, and Faster R-CNN!