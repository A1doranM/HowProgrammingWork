# Gated Recurrent Unit (GRU)

## Table of Contents
1. [Plain English Explanation](#plain-english-explanation)
2. [Mathematical Foundation](#mathematical-foundation)
3. [Forward Propagation](#forward-propagation)
4. [Backward Propagation Through Time (BPTT) for GRU](#backward-propagation-through-time-bptt-for-gru)
5. [GRU vs Vanilla RNN Comparison](#gru-vs-vanilla-rnn-comparison)
6. [Key Insights and Summary](#key-insights-and-summary)

---

## Plain English Explanation

### What is a GRU?

**Gated Recurrent Unit (GRU)** is an advanced type of recurrent neural network architecture designed to solve the fundamental problems of vanilla RNNs, particularly the **vanishing gradient problem**. Introduced by Cho et al. in 2014, GRUs use a gating mechanism to control the flow of information, making it easier to capture long-term dependencies in sequential data.

Think of a GRU as a smarter version of an RNN that can decide:
- **What to remember** from the past
- **What to forget** from the current memory
- **How much new information to add** to the memory

### Why Were GRUs Developed?

#### Problems with Vanilla RNNs:

1. **Vanishing Gradient Problem**: 
   - Gradients become extremely small when backpropagating through many time steps
   - Makes it nearly impossible to learn long-term dependencies
   - Example: In "The clouds are in the sky", by the time we process "sky", the gradient from "clouds" has vanished

2. **Difficulty Capturing Long-Term Dependencies**:
   - Information from early time steps gets diluted or lost
   - Network struggles to remember important context from far in the past

3. **Unstable Training**:
   - Exploding gradients can make training unstable
   - Requires careful initialization and learning rate tuning

#### GRU Solutions:

```
┌────────────────────────────────────────────────────────────┐
│ GRU Innovations to Solve RNN Problems                      │
├────────────────────────────────────────────────────────────┤
│                                                            │
│ 1. GATING MECHANISM                                        │
│    → Controls information flow with learned gates          │
│    → Decides what to keep and what to discard              │
│                                                            │
│ 2. UPDATE GATE (z_t)                                       │
│    → Controls how much of past memory to keep              │
│    → "How much should I remember from before?"             │
│                                                            │
│ 3. RESET GATE (r_t)                                        │
│    → Controls how much past information to use             │
│    → "Should I forget the past when computing new info?"   │
│                                                            │
│ 4. DIRECT PATH FOR GRADIENT FLOW                           │
│    → Gradients can flow directly through update gate       │
│    → Mitigates vanishing gradient problem                  │
│                                                            │
│ 5. SIMPLER THAN LSTM                                       │
│    → Fewer parameters (2 gates vs 3 gates in LSTM)        │
│    → Faster training and inference                         │
│    → Often similar performance to LSTM                     │
└────────────────────────────────────────────────────────────┘
```

### Key Innovations

**1. Gated Information Flow**: Unlike vanilla RNNs that always mix old and new information in the same way, GRUs use gates to adaptively control this mixing.

**2. Learned Forgetting**: The network learns when to forget irrelevant past information.

**3. Selective Memory Update**: Can preserve important information over many time steps while still accepting new relevant information.

### Basic Architecture

The GRU has **three main components**:
1. **Reset Gate** ($r_t$): Determines how much of the previous hidden state to "forget"
2. **Update Gate** ($z_t$): Decides how much to update the hidden state
3. **Candidate Hidden State** ($\tilde{h}_t$): New candidate information to potentially add

#### Folded (Compact) Representation:

```
         ┌─────────────────┐
     x_t │                 │ y_t
    ────►│   GRU Cell      │────►
         │  ┌─────────┐    │
         │  │ Gates:  │    │
         │  │  - z_t  │    │
         │  │  - r_t  │    │
         │  └─────────┘    │
         └────┬────────────┘
              │
              │ h_t (hidden state)
              │
              └──────┐
                     │
                     ▼
```

#### Unfolded (Over Time) Representation:

```
Time:    t=0           t=1           t=2           t=3
         ┌───┐        ┌───┐        ┌───┐        ┌───┐
   h_0   │   │  h_1   │   │  h_2   │   │  h_3   │   │
   ─────►│GRU├───────►│GRU├───────►│GRU├───────►│GRU│
         │   │        │   │        │   │        │   │
         └─┬─┘        └─┬─┘        └─┬─┘        └─┬─┘
           ▲            ▲            ▲            ▲
           │            │            │            │
          x_0          x_1          x_2          x_3
           │            │            │            │
           ▼            ▼            ▼            ▼
          y_0          y_1          y_2          y_3
```

### The Three Gates Explained

#### 1. Reset Gate ($r_t$)

**Purpose**: Decides how much of the previous hidden state should be used when computing the new candidate hidden state.

**Question it answers**: "How relevant is the past information for computing new memory?"

```
╔════════════════════════════════════════════════════════════╗
║                    RESET GATE (r_t)                        ║
╠════════════════════════════════════════════════════════════╣
║                                                            ║
║  Input: Current input (x_t) + Previous hidden state (h_t-1)║
║  Output: Reset gate value between 0 and 1                  ║
║                                                            ║
║  ┌──────────┐                                              ║
║  │  x_t     │                                              ║
║  │  h_{t-1} │                                              ║
║  └────┬─────┘                                              ║
║       │                                                    ║
║       │ Linear transformation                              ║
║       │ (W_r · [h_{t-1}, x_t])                            ║
║       ▼                                                    ║
║  ┌─────────┐                                               ║
║  │ Sigmoid │  ← Outputs value in [0, 1]                   ║
║  └────┬────┘                                               ║
║       │                                                    ║
║       ▼                                                    ║
║      r_t                                                   ║
║                                                            ║
║  r_t ≈ 0: "Forget the past! Start fresh!"                 ║
║  r_t ≈ 1: "Remember everything from the past!"            ║
║  r_t ≈ 0.5: "Consider some of the past"                   ║
║                                                            ║
║  Example Use Case:                                         ║
║  In "The cat, which was very fluffy, sat on the mat"      ║
║  When processing "sat", the reset gate might:             ║
║  - Keep high value for "cat" (subject is relevant)        ║
║  - Reduce value for "fluffy" (less relevant to action)    ║
╚════════════════════════════════════════════════════════════╝
```

**Visualization of Reset Gate Values**:

```
r_t = 0.0          r_t = 0.5          r_t = 1.0
───────────        ───────────        ───────────

h_{t-1} ━━━━►      h_{t-1} ━━━━►      h_{t-1} ━━━━►
  [5.0]              [5.0]              [5.0]
    │                  │                  │
    │ ×0.0             │ ×0.5             │ ×1.0
    ▼                  ▼                  ▼
  [0.0]              [2.5]              [5.0]

"Ignore past"    "Partial past"    "Keep all past"
```

#### 2. Update Gate ($z_t$)

**Purpose**: Controls how much of the previous hidden state to keep and how much new candidate information to add.

**Question it answers**: "How much should I update my memory with new information?"

```
╔════════════════════════════════════════════════════════════╗
║                   UPDATE GATE (z_t)                        ║
╠════════════════════════════════════════════════════════════╣
║                                                            ║
║  Input: Current input (x_t) + Previous hidden state (h_t-1)║
║  Output: Update gate value between 0 and 1                 ║
║                                                            ║
║  ┌──────────┐                                              ║
║  │  x_t     │                                              ║
║  │  h_{t-1} │                                              ║
║  └────┬─────┘                                              ║
║       │                                                    ║
║       │ Linear transformation                              ║
║       │ (W_z · [h_{t-1}, x_t])                            ║
║       ▼                                                    ║
║  ┌─────────┐                                               ║
║  │ Sigmoid │  ← Outputs value in [0, 1]                   ║
║  └────┬────┘                                               ║
║       │                                                    ║
║       ▼                                                    ║
║      z_t                                                   ║
║                                                            ║
║  z_t ≈ 0: "Update a lot! Use new information!"            ║
║  z_t ≈ 1: "Keep old memory! Ignore new information!"      ║
║  z_t ≈ 0.5: "Balance old and new equally"                 ║
║                                                            ║
║  Example Use Case:                                         ║
║  In "I grew up in France... I speak fluent [MASK]"        ║
║  When processing words after "France":                     ║
║  - z_t stays HIGH to remember "France" across many steps  ║
║  - Only updates when reaching the answer "French"         ║
╚════════════════════════════════════════════════════════════╝
```

**Visualization of Update Gate Effect**:

```
z_t = 0.0 (Update heavily)
──────────────────────────

h_{t-1}     (1-z_t) = 1.0          h_t
[3.0]  ────────×───────────┐    [7.0]
                            │
                            ├──► SUM ──►
                            │
h̃_t        z_t = 0.0        │
[7.0]  ────────×────────────┘

Result: New memory h_t = 7.0 (mostly new candidate)


z_t = 1.0 (Keep old memory)
───────────────────────────

h_{t-1}     (1-z_t) = 0.0          h_t
[3.0]  ────────×───────────┐    [3.0]
                            │
                            ├──► SUM ──►
                            │
h̃_t        z_t = 1.0        │
[7.0]  ────────×────────────┘

Result: New memory h_t = 3.0 (kept old memory entirely)


z_t = 0.5 (Balanced update)
───────────────────────────

h_{t-1}     (1-z_t) = 0.5          h_t
[3.0]  ────────×───────────┐    [5.0]
                  [1.5]     │
                            ├──► SUM ──►
                  [3.5]     │
h̃_t        z_t = 0.5        │
[7.0]  ────────×────────────┘

Result: New memory h_t = 1.5 + 3.5 = 5.0 (balanced)
```

#### 3. Candidate Hidden State ($\tilde{h}_t$)

**Purpose**: Proposes new information that could be added to the memory.

**Question it answers**: "What is the new information I want to potentially store?"

```
╔════════════════════════════════════════════════════════════╗
║              CANDIDATE HIDDEN STATE (h̃_t)                  ║
╠════════════════════════════════════════════════════════════╣
║                                                            ║
║  Input: Current input (x_t) + RESET previous state        ║
║  Output: Candidate values between -1 and 1                 ║
║                                                            ║
║  ┌──────────┐      ┌──────────┐                           ║
║  │  x_t     │      │ h_{t-1}  │                           ║
║  └────┬─────┘      └────┬─────┘                           ║
║       │                 │                                  ║
║       │                 │ ⊙ r_t  ← Reset gate applied!    ║
║       │                 ▼                                  ║
║       │          [ r_t ⊙ h_{t-1} ]                        ║
║       │                 │                                  ║
║       └────────┬────────┘                                  ║
║                │                                           ║
║                │ Linear transformation                     ║
║                │ (W_h · [r_t ⊙ h_{t-1}, x_t])             ║
║                ▼                                           ║
║           ┌────────┐                                       ║
║           │  tanh  │  ← Outputs value in [-1, 1]          ║
║           └───┬────┘                                       ║
║               │                                            ║
║               ▼                                            ║
║              h̃_t                                           ║
║                                                            ║
║  Key Difference from Vanilla RNN:                          ║
║  Uses RESET past: r_t ⊙ h_{t-1}, not just h_{t-1}        ║
║                                                            ║
║  This allows the network to "forget" irrelevant past      ║
║  information when computing new candidate!                 ║
╚════════════════════════════════════════════════════════════╝
```

### Step-by-Step: How GRU Works

Let's walk through a complete time step to see how all three components work together.

#### Complete GRU Cell Operation

```
═══════════════════════════════════════════════════════════════════════
                    GRU CELL: COMPLETE INFORMATION FLOW
═══════════════════════════════════════════════════════════════════════

INPUTS:
  x_t = Current input at time t
  h_{t-1} = Previous hidden state

OUTPUTS:
  h_t = New hidden state
  y_t = Output (if needed)


┌──────────────────────────────────────────────────────────────────┐
│  STEP 1: COMPUTE RESET GATE                                      │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│     x_t          h_{t-1}                                         │
│      │              │                                            │
│      └──────┬───────┘                                            │
│             │                                                    │
│             │ Concatenate: [h_{t-1}, x_t]                       │
│             ▼                                                    │
│      ┌─────────────┐                                             │
│      │   W_r · []  │  ← Apply weight matrix W_r                 │
│      │   + b_r     │  ← Add bias                                │
│      └──────┬──────┘                                             │
│             │                                                    │
│             ▼                                                    │
│      ┌───────────┐                                               │
│      │  σ(...)   │  ← Sigmoid activation                        │
│      └─────┬─────┘                                               │
│            │                                                     │
│            ▼                                                     │
│           r_t ∈ [0, 1]  ← Reset gate values                     │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘


┌──────────────────────────────────────────────────────────────────┐
│  STEP 2: COMPUTE UPDATE GATE                                     │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│     x_t          h_{t-1}                                         │
│      │              │                                            │
│      └──────┬───────┘                                            │
│             │                                                    │
│             │ Concatenate: [h_{t-1}, x_t]                       │
│             ▼                                                    │
│      ┌─────────────┐                                             │
│      │   W_z · []  │  ← Apply weight matrix W_z                 │
│      │   + b_z     │  ← Add bias                                │
│      └──────┬──────┘                                             │
│             │                                                    │
│             ▼                                                    │
│      ┌───────────┐                                               │
│      │  σ(...)   │  ← Sigmoid activation                        │
│      └─────┬─────┘                                               │
│            │                                                     │
│            ▼                                                     │
│           z_t ∈ [0, 1]  ← Update gate values                    │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘


┌──────────────────────────────────────────────────────────────────┐
│  STEP 3: COMPUTE CANDIDATE HIDDEN STATE                          │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│     x_t          h_{t-1}        r_t                              │
│      │              │            │                               │
│      │              └─────┬──────┘                               │
│      │                    │                                      │
│      │                    │ Element-wise multiply ⊙              │
│      │                    ▼                                      │
│      │             r_t ⊙ h_{t-1}  ← "Reset" past memory         │
│      │                    │                                      │
│      └──────┬─────────────┘                                      │
│             │                                                    │
│             │ Concatenate: [r_t ⊙ h_{t-1}, x_t]                │
│             ▼                                                    │
│      ┌─────────────┐                                             │
│      │   W_h · []  │  ← Apply weight matrix W_h                 │
│      │   + b_h     │  ← Add bias                                │
│      └──────┬──────┘                                             │
│             │                                                    │
│             ▼                                                    │
│      ┌───────────┐                                               │
│      │ tanh(...) │  ← Tanh activation                           │
│      └─────┬─────┘                                               │
│            │                                                     │
│            ▼                                                     │
│           h̃_t ∈ [-1, 1]  ← Candidate hidden state              │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘


┌──────────────────────────────────────────────────────────────────┐
│  STEP 4: UPDATE HIDDEN STATE (THE KEY STEP!)                     │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│     h_{t-1}          z_t              h̃_t                        │
│        │             │                 │                         │
│        │             │                 │                         │
│        │    ┌────────┴────────┐        │                         │
│        │    │                 │        │                         │
│        │    │  z_t ⊙ h_{t-1}  │        │  (1-z_t) ⊙ h̃_t         │
│        │    │   (keep old)    │        │  (add new)             │
│        │    │                 │        │                         │
│        └────┤                 ├────────┘                         │
│             │                 │                                  │
│             └────────┬────────┘                                  │
│                      │                                           │
│                      │ Element-wise addition                     │
│                      ▼                                           │
│             h_t = z_t ⊙ h_{t-1} + (1-z_t) ⊙ h̃_t                │
│                      │                                           │
│                      │                                           │
│                      ▼                                           │
│                 New hidden state h_t                             │
│                                                                  │
│  Interpretation:                                                 │
│  - When z_t ≈ 1: h_t ≈ h_{t-1}  (keep old memory)              │
│  - When z_t ≈ 0: h_t ≈ h̃_t      (use new candidate)            │
│  - When z_t ≈ 0.5: h_t is a blend of both                      │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘


┌──────────────────────────────────────────────────────────────────┐
│  STEP 5: COMPUTE OUTPUT (OPTIONAL)                               │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│           h_t                                                    │
│            │                                                     │
│            │ Apply output weights                                │
│            ▼                                                     │
│      ┌─────────────┐                                             │
│      │  W_y · h_t  │                                             │
│      │  + b_y      │                                             │
│      └──────┬──────┘                                             │
│             │                                                    │
│             │ Apply activation (e.g., softmax)                   │
│             ▼                                                    │
│            y_t  ← Output predictions                             │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

#### Numerical Example Walk-Through

Let's trace through a concrete example with actual numbers:

**Setup**:
```
Input: x_t = [1.0, 0.5]  (2D input)
Previous hidden state: h_{t-1} = [0.8, -0.3, 0.5]  (3D hidden)

Weight matrices (simplified):
W_r = [[0.2, 0.3, 0.1, 0.2, 0.4],    (3×5: 3 hidden × [3 hidden + 2 input])
       [0.1, 0.2, 0.3, 0.2, 0.1],
       [0.3, 0.1, 0.2, 0.4, 0.2]]

W_z = [[0.3, 0.2, 0.1, 0.3, 0.2],    (3×5)
       [0.2, 0.3, 0.2, 0.1, 0.3],
       [0.1, 0.2, 0.3, 0.2, 0.2]]

W_h = [[0.4, 0.2, 0.3, 0.2, 0.1],    (3×5)
       [0.2, 0.3, 0.1, 0.3, 0.2],
       [0.3, 0.1, 0.2, 0.1, 0.4]]

Biases: b_r = [0.1, 0.1, 0.1]
        b_z = [0.1, 0.1, 0.1]
        b_h = [0.0, 0.0, 0.0]
```

**Step 1: Compute Reset Gate**

```
Concatenate: [h_{t-1}, x_t] = [0.8, -0.3, 0.5, 1.0, 0.5]

Linear transformation:
z_r = W_r · [h_{t-1}, x_t] + b_r

For first dimension:
z_r[0] = 0.2×0.8 + 0.3×(-0.3) + 0.1×0.5 + 0.2×1.0 + 0.4×0.5 + 0.1
       = 0.16 - 0.09 + 0.05 + 0.2 + 0.2 + 0.1
       = 0.62

Similarly:
z_r[1] = 0.45
z_r[2] = 0.68

Apply sigmoid: r_t = σ(z_r)
r_t[0] = 1/(1 + e^(-0.62)) ≈ 0.650
r_t[1] = 1/(1 + e^(-0.45)) ≈ 0.610
r_t[2] = 1/(1 + e^(-0.68)) ≈ 0.664

r_t = [0.650, 0.610, 0.664]
```

**Step 2: Compute Update Gate**

```
z_z = W_z · [h_{t-1}, x_t] + b_z

z_z[0] = 0.3×0.8 + 0.2×(-0.3) + 0.1×0.5 + 0.3×1.0 + 0.2×0.5 + 0.1
       = 0.24 - 0.06 + 0.05 + 0.3 + 0.1 + 0.1
       = 0.73

Similarly:
z_z[1] = 0.68
z_z[2] = 0.58

Apply sigmoid: z_t = σ(z_z)
z_t[0] = 1/(1 + e^(-0.73)) ≈ 0.675
z_t[1] = 1/(1 + e^(-0.68)) ≈ 0.664
z_t[2] = 1/(1 + e^(-0.58)) ≈ 0.641

z_t = [0.675, 0.664, 0.641]
```

**Step 3: Compute Candidate Hidden State**

```
Reset previous hidden state:
r_t ⊙ h_{t-1} = [0.650, 0.610, 0.664] ⊙ [0.8, -0.3, 0.5]
              = [0.650×0.8, 0.610×(-0.3), 0.664×0.5]
              = [0.520, -0.183, 0.332]

Concatenate: [r_t ⊙ h_{t-1}, x_t] = [0.520, -0.183, 0.332, 1.0, 0.5]

Linear transformation:
z_h = W_h · [r_t ⊙ h_{t-1}, x_t] + b_h

z_h[0] = 0.4×0.520 + 0.2×(-0.183) + 0.3×0.332 + 0.2×1.0 + 0.1×0.5
       = 0.208 - 0.037 + 0.100 + 0.2 + 0.05
       = 0.521

Similarly:
z_h[1] = 0.385
z_h[2] = 0.428

Apply tanh: h̃_t = tanh(z_h)
h̃_t[0] = tanh(0.521) ≈ 0.479
h̃_t[1] = tanh(0.385) ≈ 0.366
h̃_t[2] = tanh(0.428) ≈ 0.403

h̃_t = [0.479, 0.366, 0.403]
```

**Step 4: Update Hidden State**

```
h_t = z_t ⊙ h_{t-1} + (1 - z_t) ⊙ h̃_t

Component 1: z_t ⊙ h_{t-1}
= [0.675, 0.664, 0.641] ⊙ [0.8, -0.3, 0.5]
= [0.540, -0.199, 0.321]

Component 2: (1 - z_t) ⊙ h̃_t
= [0.325, 0.336, 0.359] ⊙ [0.479, 0.366, 0.403]
= [0.156, 0.123, 0.145]

Final hidden state:
h_t = [0.540, -0.199, 0.321] + [0.156, 0.123, 0.145]
    = [0.696, -0.076, 0.466]
```

**Interpretation**:
```
╔════════════════════════════════════════════════════════════╗
║  Analysis of Gate Behavior                                 ║
╠════════════════════════════════════════════════════════════╣
║                                                            ║
║  RESET GATE: r_t = [0.650, 0.610, 0.664]                  ║
║  → All values > 0.6: Network decided to keep significant  ║
║    portions of past memory when computing candidate       ║
║                                                            ║
║  UPDATE GATE: z_t = [0.675, 0.664, 0.641]                 ║
║  → All values > 0.6: Network decided to keep more of old  ║
║    memory (h_{t-1}) than new candidate (h̃_t)             ║
║  → This suggests current input isn't very significant     ║
║                                                            ║
║  HIDDEN STATE CHANGE:                                      ║
║  h_{t-1} = [ 0.800, -0.300,  0.500]                       ║
║  h_t     = [ 0.696, -0.076,  0.466]                       ║
║  Change  = [-0.104,  0.224, -0.034]                       ║
║                                                            ║
║  → Modest changes: Network is gradually updating memory   ║
║  → Dimension 2 changed most (from -0.3 to -0.076)        ║
║    suggesting this dimension is being actively updated    ║
╚════════════════════════════════════════════════════════════╝
```

### Information Flow Summary

```
┌──────────────────────────────────────────────────────────────┐
│  GRU Information Flow at Time t                              │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  1. Both x_t and h_{t-1} influence reset gate r_t           │
│  2. Both x_t and h_{t-1} influence update gate z_t          │
│  3. Reset gate r_t modulates how much of h_{t-1} is used    │
│     to compute candidate h̃_t                                │
│  4. Update gate z_t controls the blend:                      │
│     - High z_t: Keep old memory (h_{t-1})                   │
│     - Low z_t: Accept new candidate (h̃_t)                   │
│  5. Hidden state h_t is a weighted average of old and new   │
│                                                              │
│  Key Advantage Over Vanilla RNN:                             │
│  - Gradients can flow directly through z_t path             │
│  - Network learns when to preserve vs. update memory        │
│  - Adaptive forgetting via r_t                              │
└──────────────────────────────────────────────────────────────┘
```

---

## Mathematical Foundation

### Core GRU Equations

The GRU consists of **five main equations** that define its behavior at each time step. Let's examine each one in detail.

#### Equation 1: Reset Gate

**Plain English**: The reset gate decides how much of the previous hidden state should be used when computing new candidate information. It takes the current input and previous hidden state, applies a linear transformation, and squashes the result to [0, 1] using sigmoid.

**Formula**:
$$r_t = \sigma(W_r [h_{t-1}, x_t] + b_r)$$

**Alternative notation** (separating weight matrices):
$$r_t = \sigma(W_{r,h} h_{t-1} + W_{r,x} x_t + b_r)$$

**Complete Legend**:
- $r_t$ = Reset gate activation at time $t$ (vector of size $n_h$, values in $[0, 1]$)
- $h_{t-1}$ = Previous hidden state at time $t-1$ (vector of size $n_h$)
- $x_t$ = Input at time $t$ (vector of size $n_x$)
- $[h_{t-1}, x_t]$ = Concatenation of $h_{t-1}$ and $x_t$ (vector of size $n_h + n_x$)
- $W_r$ = Weight matrix for reset gate (size $n_h \times (n_h + n_x)$)
- $W_{r,h}$ = Weight matrix from hidden state to reset gate (size $n_h \times n_h$)
- $W_{r,x}$ = Weight matrix from input to reset gate (size $n_h \times n_x$)
- $b_r$ = Bias vector for reset gate (size $n_h$)
- $\sigma$ = Sigmoid activation function: $\sigma(z) = \frac{1}{1 + e^{-z}}$
- Output range: $[0, 1]$ for each element

**Dimension Analysis**:
```
Input concatenation: [h_{t-1}, x_t]
   h_{t-1}: (n_h × 1)
   x_t:     (n_x × 1)
   Result:  ((n_h + n_x) × 1)

Weight multiplication: W_r · [h_{t-1}, x_t]
   W_r:     (n_h × (n_h + n_x))
   Input:   ((n_h + n_x) × 1)
   Result:  (n_h × 1)

Add bias: + b_r
   b_r:     (n_h × 1)
   Result:  (n_h × 1)

Apply sigmoid: σ(...)
   Input:   (n_h × 1)
   Output:  (n_h × 1), each element ∈ [0, 1]

Final r_t: (n_h × 1) with values in [0, 1]
```

**Step-by-Step Visualization**:

```
Example: n_h = 3, n_x = 2

Time step t:
────────────

h_{t-1} = [0.5]        x_t = [1.0]
          [0.3]              [0.8]
          [0.7]

Step 1: Concatenate
[h_{t-1}, x_t] = [0.5, 0.3, 0.7, 1.0, 0.8]ᵀ
                  └────h_{t-1}────┘ └─x_t──┘

Step 2: Linear transformation
         ┌                                  ┐
W_r =    │ 0.2  0.3  0.1  0.4  0.2  │  (3×5)
         │ 0.1  0.2  0.3  0.2  0.3  │
         │ 0.3  0.1  0.2  0.3  0.1  │
         └                                  ┘

W_r · [h_{t-1}, x_t] = [0.2×0.5 + 0.3×0.3 + 0.1×0.7 + 0.4×1.0 + 0.2×0.8]
                        [0.1×0.5 + 0.2×0.3 + 0.3×0.7 + 0.2×1.0 + 0.3×0.8]
                        [0.3×0.5 + 0.1×0.3 + 0.2×0.7 + 0.3×1.0 + 0.1×0.8]

                     = [0.10 + 0.09 + 0.07 + 0.40 + 0.16]   [0.82]
                       [0.05 + 0.06 + 0.21 + 0.20 + 0.24] = [0.76]
                       [0.15 + 0.03 + 0.14 + 0.30 + 0.08]   [0.70]

Step 3: Add bias
b_r = [0.1]
      [0.1]
      [0.1]

z_r = [0.82] + [0.1] = [0.92]
      [0.76]   [0.1]   [0.86]
      [0.70]   [0.1]   [0.80]

Step 4: Apply sigmoid
r_t = σ(z_r) = [σ(0.92)]   [0.715]
               [σ(0.86)] = [0.703]
               [σ(0.80)]   [0.690]

Interpretation:
├─ r_t[0] = 0.715: Use 71.5% of h_{t-1}[0] for candidate computation
├─ r_t[1] = 0.703: Use 70.3% of h_{t-1}[1] for candidate computation
└─ r_t[2] = 0.690: Use 69.0% of h_{t-1}[2] for candidate computation

All gates are relatively high → Network wants to consider past memory
when computing new candidate information.
```

#### Equation 2: Update Gate

**Plain English**: The update gate controls how much of the old memory to keep versus how much new candidate information to incorporate. Like the reset gate, it uses current input and previous hidden state, but has its own learned weights.

**Formula**:
$$z_t = \sigma(W_z [h_{t-1}, x_t] + b_z)$$

**Alternative notation**:
$$z_t = \sigma(W_{z,h} h_{t-1} + W_{z,x} x_t + b_z)$$

**Complete Legend**:
- $z_t$ = Update gate activation at time $t$ (vector of size $n_h$, values in $[0, 1]$)
- $h_{t-1}$ = Previous hidden state at time $t-1$ (vector of size $n_h$)
- $x_t$ = Input at time $t$ (vector of size $n_x$)
- $[h_{t-1}, x_t]$ = Concatenation of $h_{t-1}$ and $x_t$ (vector of size $n_h + n_x$)
- $W_z$ = Weight matrix for update gate (size $n_h \times (n_h + n_x)$)
- $W_{z,h}$ = Weight matrix from hidden state to update gate (size $n_h \times n_h$)
- $W_{z,x}$ = Weight matrix from input to update gate (size $n_h \times n_x$)
- $b_z$ = Bias vector for update gate (size $n_h$)
- $\sigma$ = Sigmoid activation function
- Output range: $[0, 1]$ for each element

**Dimension Analysis**:
```
Same structure as reset gate:

[h_{t-1}, x_t]: ((n_h + n_x) × 1)
W_z:            (n_h × (n_h + n_x))
W_z · []:       (n_h × 1)
+ b_z:          (n_h × 1)
σ(...):         (n_h × 1) with values ∈ [0, 1]

Final z_t: (n_h × 1) with values in [0, 1]
```

**Step-by-Step Visualization**:

```
Continuing with n_h = 3, n_x = 2

h_{t-1} = [0.5]        x_t = [1.0]
          [0.3]              [0.8]
          [0.7]

Step 1: Concatenate (same as before)
[h_{t-1}, x_t] = [0.5, 0.3, 0.7, 1.0, 0.8]ᵀ

Step 2: Linear transformation with UPDATE gate weights
         ┌                                  ┐
W_z =    │ 0.3  0.2  0.2  0.3  0.1  │  (3×5)
         │ 0.2  0.3  0.1  0.2  0.2  │
         │ 0.1  0.2  0.3  0.1  0.3  │
         └                                  ┘

W_z · [h_{t-1}, x_t] = [0.3×0.5 + 0.2×0.3 + 0.2×0.7 + 0.3×1.0 + 0.1×0.8]
                        [0.2×0.5 + 0.3×0.3 + 0.1×0.7 + 0.2×1.0 + 0.2×0.8]
                        [0.1×0.5 + 0.2×0.3 + 0.3×0.7 + 0.1×1.0 + 0.3×0.8]

                     = [0.15 + 0.06 + 0.14 + 0.30 + 0.08]   [0.73]
                       [0.10 + 0.09 + 0.07 + 0.20 + 0.16] = [0.62]
                       [0.05 + 0.06 + 0.21 + 0.10 + 0.24]   [0.66]

Step 3: Add bias
b_z = [0.1]
      [0.1]
      [0.1]

z_z = [0.73] + [0.1] = [0.83]
      [0.62]   [0.1]   [0.72]
      [0.66]   [0.1]   [0.76]

Step 4: Apply sigmoid
z_t = σ(z_z) = [σ(0.83)]   [0.696]
               [σ(0.72)] = [0.673]
               [σ(0.76)]   [0.681]

Interpretation:
├─ z_t[0] = 0.696: Keep 69.6% of old h_{t-1}[0], use 30.4% of new h̃_t[0]
├─ z_t[1] = 0.673: Keep 67.3% of old h_{t-1}[1], use 32.7% of new h̃_t[1]
└─ z_t[2] = 0.681: Keep 68.1% of old h_{t-1}[2], use 31.9% of new h̃_t[2]

All gates are relatively high (~0.7) → Network prefers to keep more of
the old memory rather than heavily updating with new information.
```

#### Equation 3: Candidate Hidden State

**Plain English**: The candidate hidden state proposes new information that could be added to memory. The key innovation here is that it uses the **reset gate** to selectively use information from the previous hidden state, allowing the network to "forget" irrelevant past information.

**Formula**:
$$\tilde{h}_t = \tanh(W_h [r_t \odot h_{t-1}, x_t] + b_h)$$

**Alternative notation**:
$$\tilde{h}_t = \tanh(W_{h,h}(r_t \odot h_{t-1}) + W_{h,x} x_t + b_h)$$

**Complete Legend**:
- $\tilde{h}_t$ = Candidate hidden state at time $t$ (vector of size $n_h$, values in $[-1, 1]$)
- $r_t$ = Reset gate activation (vector of size $n_h$, from Equation 1)
- $\odot$ = Element-wise (Hadamard) product
- $r_t \odot h_{t-1}$ = Element-wise multiplication of reset gate and previous hidden state
- $h_{t-1}$ = Previous hidden state (vector of size $n_h$)
- $x_t$ = Input at time $t$ (vector of size $n_x$)
- $[r_t \odot h_{t-1}, x_t]$ = Concatenation (vector of size $n_h + n_x$)
- $W_h$ = Weight matrix for candidate hidden state (size $n_h \times (n_h + n_x)$)
- $W_{h,h}$ = Weight matrix from reset hidden state (size $n_h \times n_h$)
- $W_{h,x}$ = Weight matrix from input (size $n_h \times n_x$)
- $b_h$ = Bias vector for candidate hidden state (size $n_h$)
- $\tanh$ = Hyperbolic tangent activation: $\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}$
- Output range: $[-1, 1]$ for each element

**Dimension Analysis**:
```
Reset gate application: r_t ⊙ h_{t-1}
   r_t:      (n_h × 1)
   h_{t-1}:  (n_h × 1)
   Result:   (n_h × 1)  [element-wise multiply]

Concatenation: [r_t ⊙ h_{t-1}, x_t]
   r_t ⊙ h_{t-1}: (n_h × 1)
   x_t:           (n_x × 1)
   Result:        ((n_h + n_x) × 1)

Weight multiplication: W_h · [r_t ⊙ h_{t-1}, x_t]
   W_h:     (n_h × (n_h + n_x))
   Input:   ((n_h + n_x) × 1)
   Result:  (n_h × 1)

Add bias and apply tanh: tanh(... + b_h)
   Result:  (n_h × 1) with values ∈ [-1, 1]

Final h̃_t: (n_h × 1) with values in [-1, 1]
```

**Step-by-Step Visualization**:

```
Continuing with our example: n_h = 3, n_x = 2

From previous steps:
h_{t-1} = [0.5]        r_t = [0.715]        x_t = [1.0]
          [0.3]              [0.703]              [0.8]
          [0.7]              [0.690]

Step 1: Apply reset gate (element-wise multiplication)

r_t ⊙ h_{t-1} = [0.715] ⊙ [0.5]   [0.715 × 0.5]   [0.358]
                [0.703]   [0.3] = [0.703 × 0.3] = [0.211]
                [0.690]   [0.7]   [0.690 × 0.7]   [0.483]

Interpretation: The reset gate has "filtered" the previous hidden state
├─ Original h_{t-1}[0] = 0.5 → Filtered to 0.358 (71.5% kept)
├─ Original h_{t-1}[1] = 0.3 → Filtered to 0.211 (70.3% kept)
└─ Original h_{t-1}[2] = 0.7 → Filtered to 0.483 (69.0% kept)

Step 2: Concatenate with input
[r_t ⊙ h_{t-1}, x_t] = [0.358, 0.211, 0.483, 1.0, 0.8]ᵀ
                        └──r_t ⊙ h_{t-1}──┘ └─x_t──┘

Step 3: Linear transformation with CANDIDATE weights
         ┌                                  ┐
W_h =    │ 0.4  0.3  0.2  0.3  0.2  │  (3×5)
         │ 0.2  0.4  0.3  0.2  0.1  │
         │ 0.3  0.2  0.4  0.1  0.3  │
         └                                  ┘

W_h · [r_t ⊙ h_{t-1}, x_t]
= [0.4×0.358 + 0.3×0.211 + 0.2×0.483 + 0.3×1.0 + 0.2×0.8]
  [0.2×0.358 + 0.4×0.211 + 0.3×0.483 + 0.2×1.0 + 0.1×0.8]
  [0.3×0.358 + 0.2×0.211 + 0.4×0.483 + 0.1×1.0 + 0.3×0.8]

= [0.143 + 0.063 + 0.097 + 0.300 + 0.160]   [0.763]
  [0.072 + 0.084 + 0.145 + 0.200 + 0.080] = [0.581]
  [0.107 + 0.042 + 0.193 + 0.100 + 0.240]   [0.682]

Step 4: Add bias
b_h = [0.0]    (often initialized to zero)
      [0.0]
      [0.0]

z_h = [0.763]
      [0.581]
      [0.682]

Step 5: Apply tanh activation
h̃_t = tanh(z_h) = [tanh(0.763)]   [0.644]
                  [tanh(0.581)] = [0.524]
                  [tanh(0.682)]   [0.593]

Interpretation:
├─ h̃_t[0] = 0.644: Proposes positive value (suggests importance)
├─ h̃_t[1] = 0.524: Proposes moderate positive value
└─ h̃_t[2] = 0.593: Proposes positive value

All candidate values are positive → New information suggests positive
activations across all hidden dimensions.

Key Difference from Vanilla RNN:
In vanilla RNN, we'd use h_{t-1} directly: tanh(W · [h_{t-1}, x_t])
In GRU, we use r_t ⊙ h_{t-1}: tanh(W · [r_t ⊙ h_{t-1}, x_t])
                                           └──────┬──────┘
                                         Selectively forget!
```

#### Equation 4: Hidden State Update

**Plain English**: This is the **core equation** of the GRU. The new hidden state is a weighted average of the previous hidden state and the candidate hidden state, controlled by the update gate. This is where the magic happens - the network can preserve old information or accept new information.

**Formula**:
$$h_t = z_t \odot h_{t-1} + (1 - z_t) \odot \tilde{h}_t$$

**Alternative form** (element-wise):
$$h_t = (1 - z_t) \odot \tilde{h}_t + z_t \odot h_{t-1}$$

**Complete Legend**:
- $h_t$ = New hidden state at time $t$ (vector of size $n_h$)
- $z_t$ = Update gate activation (vector of size $n_h$, from Equation 2, values in $[0, 1]$)
- $h_{t-1}$ = Previous hidden state (vector of size $n_h$)
- $\tilde{h}_t$ = Candidate hidden state (vector of size $n_h$, from Equation 3)
- $\odot$ = Element-wise (Hadamard) product
- $1$ = Vector of ones (size $n_h$)
- $(1 - z_t)$ = Element-wise subtraction, gives vector of size $n_h$ with values in $[0, 1]$

**Component Breakdown**:
- $z_t \odot h_{t-1}$ = Portion of old memory to keep (element-wise)
- $(1 - z_t) \odot \tilde{h}_t$ = Portion of new candidate to add (element-wise)
- Sum = Weighted average controlled by $z_t$

**Dimension Analysis**:
```
All vectors are size (n_h × 1):
   z_t:        (n_h × 1)
   h_{t-1}:    (n_h × 1)
   h̃_t:        (n_h × 1)
   1:          (n_h × 1)

Element-wise operations:
   z_t ⊙ h_{t-1}:        (n_h × 1)
   (1 - z_t):            (n_h × 1)
   (1 - z_t) ⊙ h̃_t:      (n_h × 1)
   
Final addition:
   h_t = [...] + [...]:  (n_h × 1)
```

**Step-by-Step Visualization**:

```
Continuing with our example: n_h = 3

From previous steps:
h_{t-1} = [0.5]        z_t = [0.696]        h̃_t = [0.644]
          [0.3]              [0.673]              [0.524]
          [0.7]              [0.681]              [0.593]

Step 1: Compute (1 - z_t)
1 - z_t = [1] - [0.696]   [0.304]
          [1]   [0.673] = [0.327]
          [1]   [0.681]   [0.319]

Step 2: Compute z_t ⊙ h_{t-1} (keep old memory)
z_t ⊙ h_{t-1} = [0.696] ⊙ [0.5]   [0.696 × 0.5]   [0.348]
                [0.673]   [0.3] = [0.673 × 0.3] = [0.202]
                [0.681]   [0.7]   [0.681 × 0.7]   [0.477]

Interpretation: How much old memory to keep
├─ Dimension 0: Keep 0.348 (69.6% of original 0.5)
├─ Dimension 1: Keep 0.202 (67.3% of original 0.3)
└─ Dimension 2: Keep 0.477 (68.1% of original 0.7)

Step 3: Compute (1 - z_t) ⊙ h̃_t (add new candidate)
(1 - z_t) ⊙ h̃_t = [0.304] ⊙ [0.644]   [0.304 × 0.644]   [0.196]
                  [0.327]   [0.524] = [0.327 × 0.524] = [0.171]
                  [0.319]   [0.593]   [0.319 × 0.593]   [0.189]

Interpretation: How much new information to add
├─ Dimension 0: Add 0.196 (30.4% of candidate 0.644)
├─ Dimension 1: Add 0.171 (32.7% of candidate 0.524)
└─ Dimension 2: Add 0.189 (31.9% of candidate 0.593)

Step 4: Combine to get new hidden state
h_t = z_t ⊙ h_{t-1} + (1 - z_t) ⊙ h̃_t

h_t = [0.348]   [0.196]   [0.544]
      [0.202] + [0.171] = [0.373]
      [0.477]   [0.189]   [0.666]

Final Result:
┌──────────────────────────────────────────────────────────┐
│ Hidden State Transition                                  │
├──────────────────────────────────────────────────────────┤
│                                                          │
│ h_{t-1} = [0.500, 0.300, 0.700]                         │
│            ↓       ↓       ↓                             │
│ h_t     = [0.544, 0.373, 0.666]                         │
│            ↑       ↑       ↑                             │
│ Change  = [+0.044, +0.073, -0.034]                      │
│                                                          │
│ Analysis:                                                │
│ ─────────                                                │
│ • Dimension 0: Increased by 8.8%  (0.500 → 0.544)      │
│   └─ 69.6% old + 30.4% new = small net increase        │
│                                                          │
│ • Dimension 1: Increased by 24.3% (0.300 → 0.373)      │
│   └─ Old memory (0.202) + New info (0.171) = growth    │
│                                                          │
│ • Dimension 2: Decreased by 4.9% (0.700 → 0.666)       │
│   └─ High old value (0.477) + modest new (0.189)       │
│       = slight decrease                                  │
│                                                          │
│ Overall: Smooth, controlled update - no abrupt changes  │
│ The gating mechanism prevents sudden memory disruption  │
└──────────────────────────────────────────────────────────┘
```

**Visualization of Update Gate Effect**:

```
Update Gate Value Spectrum
═══════════════════════════

For a single hidden dimension:

z_t = 0.0                 z_t = 0.5                 z_t = 1.0
─────────                 ─────────                 ─────────

Old: h_{t-1} = 0.5        Old: h_{t-1} = 0.5        Old: h_{t-1} = 0.5
New: h̃_t = 0.9            New: h̃_t = 0.9            New: h̃_t = 0.9

Keep old:                 Keep old:                 Keep old:
0.0 × 0.5 = 0.0          0.5 × 0.5 = 0.25         1.0 × 0.5 = 0.5

Add new:                  Add new:                  Add new:
1.0 × 0.9 = 0.9          0.5 × 0.9 = 0.45         0.0 × 0.9 = 0.0

Result:                   Result:                   Result:
h_t = 0.9                h_t = 0.70               h_t = 0.5

"Full update"            "Balanced blend"          "No update"
Replace with new!        Mix old and new!          Keep old memory!

Use when:                Use when:                 Use when:
- New info is crucial    - Both old and new        - Old info still
- Past is irrelevant       matter                    important
- Start fresh            - Gradual transition      - New info not useful
```

#### Equation 5: Output Computation

**Plain English**: The output at each time step is computed from the hidden state, just like in vanilla RNNs. This can be a simple linear transformation or include an activation function depending on the task.

**Formula** (for classification):
$$y_t = \text{softmax}(W_y h_t + b_y)$$

**Formula** (for regression or other tasks):
$$y_t = W_y h_t + b_y$$

**Complete Legend**:
- $y_t$ = Output at time $t$ (vector of size $n_y$)
- $W_y$ = Weight matrix from hidden state to output (size $n_y \times n_h$)
- $h_t$ = Current hidden state (vector of size $n_h$, from Equation 4)
- $b_y$ = Bias vector for output (size $n_y$)
- $\text{softmax}$ = Softmax activation for classification: $\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}}$

**Dimension Analysis**:
```
Hidden state: h_t
   (n_h × 1)

Weight multiplication: W_y · h_t
   W_y:    (n_y × n_h)
   h_t:    (n_h × 1)
   Result: (n_y × 1)

Add bias: + b_y
   b_y:    (n_y × 1)
   Result: (n_y × 1)

Apply softmax (optional): softmax(...)
   Input:  (n_y × 1)
   Output: (n_y × 1), values sum to 1

Final y_t: (n_y × 1)
```

### Summary of All GRU Equations

```
╔════════════════════════════════════════════════════════════════╗
║                   COMPLETE GRU EQUATIONS                       ║
╠════════════════════════════════════════════════════════════════╣
║                                                                ║
║  EQUATION 1: Reset Gate                                        ║
║  ─────────────────────                                         ║
║  r_t = σ(W_r [h_{t-1}, x_t] + b_r)                            ║
║                                                                ║
║  Purpose: Decide how much past to use for candidate           ║
║  Range: [0, 1] per element                                     ║
║                                                                ║
║                                                                ║
║  EQUATION 2: Update Gate                                       ║
║  ───────────────────────                                       ║
║  z_t = σ(W_z [h_{t-1}, x_t] + b_z)                            ║
║                                                                ║
║  Purpose: Decide how much to update memory                    ║
║  Range: [0, 1] per element                                     ║
║                                                                ║
║                                                                ║
║  EQUATION 3: Candidate Hidden State                            ║
║  ──────────────────────────────                                ║
║  h̃_t = tanh(W_h [r_t ⊙ h_{t-1}, x_t] + b_h)                   ║
║                                                                ║
║  Purpose: Propose new memory content                           ║
║  Range: [-1, 1] per element                                    ║
║  Key: Uses RESET past (r_t ⊙ h_{t-1})                         ║
║                                                                ║
║                                                                ║
║  EQUATION 4: Hidden State Update (CORE!)                       ║
║  ───────────────────────────────────────                       ║
║  h_t = z_t ⊙ h_{t-1} + (1 - z_t) ⊙ h̃_t                        ║
║                                                                ║
║  Purpose: Blend old and new memory                             ║
║  Interpretation:                                               ║
║    • z_t ⊙ h_{t-1}: Portion of old memory to keep             ║
║    • (1-z_t) ⊙ h̃_t: Portion of new candidate to add          ║
║                                                                ║
║                                                                ║
║  EQUATION 5: Output                                            ║
║  ──────────────────                                            ║
║  y_t = softmax(W_y h_t + b_y)                                 ║
║                                                                ║
║  Purpose: Generate predictions from hidden state               ║
║                                                                ║
╚════════════════════════════════════════════════════════════════╝
```

### Activation Functions Deep Dive

#### Sigmoid ($\sigma$)

**Formula**:
$$\sigma(z) = \frac{1}{1 + e^{-z}}$$

**Derivative**:
$$\frac{d\sigma(z)}{dz} = \sigma(z)(1 - \sigma(z))$$

**Properties**:
- Output range: $(0, 1)$ (always positive, never exactly 0 or 1)
- Acts as a "soft gate": 0 means "block completely", 1 means "pass completely"
- Smooth and differentiable everywhere
- Outputs can be interpreted as probabilities or gate activations

**Why use sigmoid for gates?**
```
Gate Interpretation:
───────────────────
σ(z) = 0.0  → "Close the gate"   (block information flow)
σ(z) = 0.5  → "Half open"        (partial information flow)
σ(z) = 1.0  → "Fully open"       (allow all information through)

The smooth transition allows gradients to flow during backpropagation!
```

**Numerical Examples**:
```
σ(-∞) = 0.000  (very negative input → gate closed)
σ(-2) = 0.119
σ(-1) = 0.269
σ(0)  = 0.500  (zero input → half open)
σ(1)  = 0.731
σ(2)  = 0.881
σ(+∞) = 1.000  (very positive input → gate fully open)
```

#### Hyperbolic Tangent (tanh)

**Formula**:
$$\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} = \frac{e^{2z} - 1}{e^{2z} + 1}$$

**Relationship to sigmoid**:
$$\tanh(z) = 2\sigma(2z) - 1$$

**Derivative**:
$$\frac{d\tanh(z)}{dz} = 1 - \tanh^2(z)$$

**Properties**:
- Output range: $(-1, 1)$ (zero-centered)
- Stronger gradients than sigmoid in the middle range
- Zero-centered helps with learning (positive and negative values)
- Saturates at extremes (gradients → 0 for large |z|)

**Why use tanh for candidate hidden state?**
```
Memory Representation:
─────────────────────
tanh(z) = -1.0  → "Strong negative memory"
tanh(z) =  0.0  → "Neutral/no information"
tanh(z) = +1.0  → "Strong positive memory"

Zero-centered allows both positive and negative contributions to memory!
This is more expressive than sigmoid's [0, 1] range.
```

**Numerical Examples**:
```
tanh(-∞) = -1.000  (very negative → strong negative memory)
tanh(-2) = -0.964
tanh(-1) = -0.762
tanh(0)  =  0.000  (neutral)
tanh(1)  =  0.762
tanh(2)  =  0.964
tanh(+∞) =  1.000  (very positive → strong positive memory)
```

#### Element-wise Multiplication ($\odot$)

**Definition**: The Hadamard product - multiply corresponding elements.

**Formula** for vectors $a, b \in \mathbb{R}^n$:
$$(a \odot b)_i = a_i \cdot b_i \text{ for } i = 1, \ldots, n$$

**Example**:
```
[2]     [3]     [2×3]     [6]
[4]  ⊙  [5]  =  [4×5]  =  [20]
[6]     [7]     [6×7]     [42]
```

**Why crucial for GRU?**
```
Gating Mechanism:
────────────────

Gate value g ∈ [0, 1]     Information i ∈ ℝ

g ⊙ i controls information flow:

g = [0.0]    i = [5.0]      g ⊙ i = [0.0]    "Blocked"
    [0.5]        [3.0]              [1.5]    "Partial"
    [1.0]        [2.0]              [2.0]    "Full pass"

This allows SELECTIVE, LEARNABLE information filtering!
```

### Weight Matrices and Dimensions

**Complete dimension breakdown** for a GRU with:
- Input dimension: $n_x$
- Hidden dimension: $n_h$
- Output dimension: $n_y$

```
╔════════════════════════════════════════════════════════════════╗
║              GRU PARAMETER DIMENSIONS                          ║
╠════════════════════════════════════════════════════════════════╣
║                                                                ║
║ RESET GATE PARAMETERS:                                         ║
║ ─────────────────────                                          ║
║ W_r: (n_h × (n_h + n_x))  - Weight matrix                     ║
║ b_r: (n_h × 1)            - Bias vector                       ║
║                                                                ║
║ Alternative split form:                                        ║
║ W_{r,h}: (n_h × n_h)      - Hidden-to-reset weights           ║
║ W_{r,x}: (n_h × n_x)      - Input-to-reset weights            ║
║                                                                ║
║                                                                ║
║ UPDATE GATE PARAMETERS:                                        ║
║ ──────────────────────                                         ║
║ W_z: (n_h × (n_h + n_x))  - Weight matrix                     ║
║ b_z: (n_h × 1)            - Bias vector                       ║
║                                                                ║
║ Alternative split form:                                        ║
║ W_{z,h}: (n_h × n_h)      - Hidden-to-update weights          ║
║ W_{z,x}: (n_h × n_x)      - Input-to-update weights           ║
║                                                                ║
║                                                                ║
║ CANDIDATE HIDDEN STATE PARAMETERS:                             ║
║ ──────────────────────────────────                             ║
║ W_h: (n_h × (n_h + n_x))  - Weight matrix                     ║
║ b_h: (n_h × 1)            - Bias vector                       ║
║                                                                ║
║ Alternative split form:                                        ║
║ W_{h,h}: (n_h × n_h)      - Reset-hidden-to-candidate         ║
║ W_{h,x}: (n_h × n_x)      - Input-to-candidate weights        ║
║                                                                ║
║                                                                ║
║ OUTPUT PARAMETERS:                                             ║
║ ─────────────────                                              ║
║ W_y: (n_y × n_h)          - Hidden-to-output weights          ║
║ b_y: (n_y × 1)            - Output bias vector                ║
║                                                                ║
║                                                                ║
║ TOTAL PARAMETER COUNT:                                         ║
║ ─────────────────────                                          ║
║ Gates (r, z, h): 3 × [n_h × (n_h + n_x) + n_h]               ║
║                = 3 × n_h × (n_h + n_x + 1)                    ║
║                                                                ║
║ Output:          n_y × (n_h + 1)                              ║
║                                                                ║
║ Total GRU params: 3n_h(n_h + n_x + 1) + n_y(n_h + 1)         ║
║                                                                ║
║ Example (n_x=100, n_h=128, n_y=10):                           ║
║ Gates: 3 × 128 × (128 + 100 + 1) = 87,936 parameters         ║
║ Output: 10 × (128 + 1) = 1,290 parameters                     ║
║ Total: 89,226 parameters                                       ║
║                                                                ║
╚════════════════════════════════════════════════════════════════╝
```

### Complete Numerical Example

Let's work through a complete example with concrete values to solidify understanding.

**Setup**:
```
Task: Binary sentiment classification
Input: Embedding of word at each time step
Hidden state: Captures meaning/context

Dimensions:
- n_x = 3 (word embedding size, simplified)
- n_h = 4 (hidden size)
- n_y = 2 (binary classification: positive/negative)
```

**Initialize Parameters** (simplified for demonstration):

```
W_r (4×7):
[0.1  0.2  0.1  0.3  0.2  0.1  0.3]
[0.2  0.1  0.3  0.2  0.1  0.2  0.1]
[0.3  0.2  0.1  0.1  0.3  0.2  0.2]
[0.1  0.3  0.2  0.2  0.1  0.3  0.1]

W_z (4×7):
[0.2  0.1  0.3  0.2  0.3  0.1  0.2]
[0.3  0.2  0.1  0.3  0.1  0.2  0.3]
[0.1  0.3  0.2  0.1  0.2  0.3  0.1]
[0.2  0.1  0.3  0.2  0.1  0.2  0.3]

W_h (4×7):
[0.3  0.2  0.3  0.1  0.2  0.3  0.1]
[0.1  0.3  0.2  0.3  0.1  0.2  0.2]
[0.2  0.1  0.3  0.2  0.3  0.1  0.3]
[0.3  0.2  0.1  0.2  0.2  0.3  0.1]

W_y (2×4):
[0.5  0.3  0.2  0.4]
[0.4  0.2  0.5  0.3]

Biases:
b_r = [0.1, 0.1, 0.1, 0.1]ᵀ
b_z = [0.1, 0.1, 0.1, 0.1]ᵀ
b_h = [0.0, 0.0, 0.0, 0.0]ᵀ
b_y = [0.0, 0.0]ᵀ

Initial hidden state:
h_{-1} = [0.0, 0.0, 0.0, 0.0]ᵀ

Input at t=0:
x_0 = [0.8, 0.3, 0.5]ᵀ (word embedding)
```

**Step 1: Compute Reset Gate $r_0$**

```
Concatenate: [h_{-1}, x_0] = [0.0, 0.0, 0.0, 0.0, 0.8, 0.3, 0.5]ᵀ

W_r · [h_{-1}, x_0]:

Row 0: 0.1×0.0 + 0.2×0.0 + 0.1×0.0 + 0.3×0.0 + 0.2×0.8 + 0.1×0.3 + 0.3×0.5
     = 0 + 0 + 0 + 0 + 0.16 + 0.03 + 0.15 = 0.34

Row 1: 0.2×0.0 + 0.1×0.0 + 0.3×0.0 + 0.2×0.0 + 0.1×0.8 + 0.2×0.3 + 0.1×0.5
     = 0 + 0 + 0 + 0 + 0.08 + 0.06 + 0.05 = 0.19

Row 2: 0.3×0.0 + 0.2×0.0 + 0.1×0.0 + 0.1×0.0 + 0.3×0.8 + 0.2×0.3 + 0.2×0.5
     = 0 + 0 + 0 + 0 + 0.24 + 0.06 + 0.10 = 0.40

Row 3: 0.1×0.0 + 0.3×0.0 + 0.2×0.0 + 0.2×0.0 + 0.1×0.8 + 0.3×0.3 + 0.1×0.5
     = 0 + 0 + 0 + 0 + 0.08 + 0.09 + 0.05 = 0.22

W_r · [h_{-1}, x_0] = [0.34, 0.19, 0.40, 0.22]ᵀ

Add bias: [0.34, 0.19, 0.40, 0.22]ᵀ + [0.1, 0.1, 0.1, 0.1]ᵀ
        = [0.44, 0.29, 0.50, 0.32]ᵀ

Apply sigmoid:
r_0 = [σ(0.44), σ(0.29), σ(0.50), σ(0.32)]ᵀ
    = [0.608, 0.572, 0.622, 0.579]ᵀ
```

**Step 2: Compute Update Gate $z_0$**

```
W_z · [h_{-1}, x_0]:

Row 0: 0.2×0.0 + 0.1×0.0 + 0.3×0.0 + 0.2×0.0 + 0.3×0.8 + 0.1×0.3 + 0.2×0.5
     = 0 + 0 + 0 + 0 + 0.24 + 0.03 + 0.10 = 0.37

Row 1: 0.3×0.0 + 0.2×0.0 + 0.1×0.0 + 0.3×0.0 + 0.1×0.8 + 0.2×0.3 + 0.3×0.5
     = 0 + 0 + 0 + 0 + 0.08 + 0.06 + 0.15 = 0.29

Row 2: 0.1×0.0 + 0.3×0.0 + 0.2×0.0 + 0.1×0.0 + 0.2×0.8 + 0.3×0.3 + 0.1×0.5
     = 0 + 0 + 0 + 0 + 0.16 + 0.09 + 0.05 = 0.30

Row 3: 0.2×0.0 + 0.1×0.0 + 0.3×0.0 + 0.2×0.0 + 0.1×0.8 + 0.2×0.3 + 0.3×0.5
     = 0 + 0 + 0 + 0 + 0.08 + 0.06 + 0.15 = 0.29

Add bias: [0.37, 0.29, 0.30, 0.29]ᵀ + [0.1, 0.1, 0.1, 0.1]ᵀ
        = [0.47, 0.39, 0.40, 0.39]ᵀ

Apply sigmoid:
z_0 = [σ(0.47), σ(0.39), σ(0.40), σ(0.39)]ᵀ
    = [0.615, 0.596, 0.599, 0.596]ᵀ
```

**Step 3: Compute Candidate Hidden State $\tilde{h}_0$**

```
Reset previous hidden state:
r_0 ⊙ h_{-1} = [0.608, 0.572, 0.622, 0.579]ᵀ ⊙ [0.0, 0.0, 0.0, 0.0]ᵀ
             = [0.0, 0.0, 0.0, 0.0]ᵀ

Concatenate: [r_0 ⊙ h_{-1}, x_0] = [0.0, 0.0, 0.0, 0.0, 0.8, 0.3, 0.5]ᵀ

W_h · [r_0 ⊙ h_{-1}, x_0]:

Row 0: 0.3×0.0 + 0.2×0.0 + 0.3×0.0 + 0.1×0.0 + 0.2×0.8 + 0.3×0.3 + 0.1×0.5
     = 0 + 0 + 0 + 0 + 0.16 + 0.09 + 0.05 = 0.30

Row 1: 0.1×0.0 + 0.3×0.0 + 0.2×0.0 + 0.3×0.0 + 0.1×0.8 + 0.2×0.3 + 0.2×0.5
     = 0 + 0 + 0 + 0 + 0.08 + 0.06 + 0.10 = 0.24

Row 2: 0.2×0.0 + 0.1×0.0 + 0.3×0.0 + 0.2×0.0 + 0.3×0.8 + 0.1×0.3 + 0.3×0.5
     = 0 + 0 + 0 + 0 + 0.24 + 0.03 + 0.15 = 0.42

Row 3: 0.3×0.0 + 0.2×0.0 + 0.1×0.0 + 0.2×0.0 + 0.2×0.8 + 0.3×0.3 + 0.1×0.5
     = 0 + 0 + 0 + 0 + 0.16 + 0.09 + 0.05 = 0.30

Add bias: [0.30, 0.24, 0.42, 0.30]ᵀ + [0.0, 0.0, 0.0, 0.0]ᵀ
        = [0.30, 0.24, 0.42, 0.30]ᵀ

Apply tanh:
h̃_0 = [tanh(0.30), tanh(0.24), tanh(0.42), tanh(0.30)]ᵀ
     = [0.291, 0.236, 0.397, 0.291]ᵀ
```

**Step 4: Update Hidden State $h_0$**

```
Compute z_0 ⊙ h_{-1}:
[0.615, 0.596, 0.599, 0.596]ᵀ ⊙ [0.0, 0.0, 0.0, 0.0]ᵀ = [0.0, 0.0, 0.0, 0.0]ᵀ

Compute (1 - z_0):
[1, 1, 1, 1]ᵀ - [0.615, 0.596, 0.599, 0.596]ᵀ = [0.385, 0.404, 0.401, 0.404]ᵀ

Compute (1 - z_0) ⊙ h̃_0:
[0.385, 0.404, 0.401, 0.404]ᵀ ⊙ [0.291, 0.236, 0.397, 0.291]ᵀ
= [0.112, 0.095, 0.159, 0.118]ᵀ

Final hidden state:
h_0 = [0.0, 0.0, 0.0, 0.0]ᵀ + [0.112, 0.095, 0.159, 0.118]ᵀ
    = [0.112, 0.095, 0.159, 0.118]ᵀ
```

**Step 5: Compute Output $y_0$**

```
W_y · h_0:

Row 0: 0.5×0.112 + 0.3×0.095 + 0.2×0.159 + 0.4×0.118
     = 0.056 + 0.029 + 0.032 + 0.047 = 0.164

Row 1: 0.4×0.112 + 0.2×0.095 + 0.5×0.159 + 0.3×0.118
     = 0.045 + 0.019 + 0.080 + 0.035 = 0.179

Add bias: [0.164, 0.179]ᵀ + [0.0, 0.0]ᵀ = [0.164, 0.179]ᵀ

Apply softmax:
exp(0.164) = 1.178
exp(0.179) = 1.196
sum = 1.178 + 1.196 = 2.374

y_0 = [1.178/2.374, 1.196/2.374]ᵀ = [0.496, 0.504]ᵀ
```

**Summary of Time Step t=0**:

```
╔═══════════════════════════════════════════════════════════════╗
║                    TIME STEP t=0 SUMMARY                      ║
╠═══════════════════════════════════════════════════════════════╣
║                                                               ║
║ INPUT:                                                        ║
║ x_0 = [0.800, 0.300, 0.500]                                  ║
║ h_{-1} = [0.000, 0.000, 0.000, 0.000] (initial)             ║
║                                                               ║
║ GATES COMPUTED:                                               ║
║ r_0 = [0.608, 0.572, 0.622, 0.579]  (reset gate)            ║
║ z_0 = [0.615, 0.596, 0.599, 0.596]  (update gate)           ║
║                                                               ║
║ CANDIDATE:                                                    ║
║ h̃_0 = [0.291, 0.236, 0.397, 0.291]                           ║
║                                                               ║
║ NEW HIDDEN STATE:                                             ║
║ h_0 = [0.112, 0.095, 0.159, 0.118]                          ║
║                                                               ║
║ OUTPUT:                                                       ║
║ y_0 = [0.496, 0.504] (softmax probabilities)                ║
║       ↑       ↑                                               ║
║    negative positive                                          ║
║                                                               ║
║ INTERPRETATION:                                               ║
║ • First time step with no previous context                   ║
║ • Update gates ~0.6: balanced between old and new            ║
║ • Output slightly favors positive (0.504 > 0.496)           ║
║ • Hidden state has been initialized with new information     ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

This numerical example demonstrates how the GRU processes information step by step, using gates to control information flow and building up memory in the hidden state.

---

## Forward Propagation

### Overview

Forward propagation in a GRU processes the input sequence time step by time step, maintaining a hidden state that evolves through gating mechanisms. Unlike vanilla RNNs, the GRU uses gates to selectively update its memory, allowing it to capture long-term dependencies more effectively.

```
Forward Pass Flow in GRU:
═════════════════════════

Initialize: h_{-1} = 0 (or learned initial state)

For t = 0 to T-1:
    1. Receive x_t (current input)
    
    2. Compute reset gate:
       r_t = σ(W_r [h_{t-1}, x_t] + b_r)
    
    3. Compute update gate:
       z_t = σ(W_z [h_{t-1}, x_t] + b_z)
    
    4. Compute candidate hidden state:
       h̃_t = tanh(W_h [r_t ⊙ h_{t-1}, x_t] + b_h)
    
    5. Update hidden state:
       h_t = z_t ⊙ h_{t-1} + (1 - z_t) ⊙ h̃_t
    
    6. Compute output:
       y_t = softmax(W_y h_t + b_y)
    
    7. Compute loss L_t for this time step
    
Total Loss: L = (1/T) Σ L_t (average over all time steps)
```

### Detailed Mathematical Formulation

#### Complete Step-by-Step Equations

**For each time step t = 0, 1, 2, ..., T-1:**

**Step 1: Reset Gate Computation**
$$r_t = \sigma(W_r [h_{t-1}, x_t] + b_r)$$

**Step 2: Update Gate Computation**
$$z_t = \sigma(W_z [h_{t-1}, x_t] + b_z)$$

**Step 3: Candidate Hidden State**
$$\tilde{h}_t = \tanh(W_h [r_t \odot h_{t-1}, x_t] + b_h)$$

**Step 4: Hidden State Update**
$$h_t = z_t \odot h_{t-1} + (1 - z_t) \odot \tilde{h}_t$$

**Step 5: Output Computation** (for classification)
$$o_t = W_y h_t + b_y$$
$$y_t = \text{softmax}(o_t)$$

**Step 6: Loss Computation** (cross-entropy for classification)
$$L_t = -\sum_{i=1}^{n_y} \hat{y}_{t,i} \log(y_{t,i})$$

**Step 7: Total Loss**
$$L = \frac{1}{T} \sum_{t=0}^{T-1} L_t$$

**Complete Legend**:
- $t$ = Current time step index
- $T$ = Total sequence length
- $x_t$ = Input at time $t$ (vector of size $n_x$)
- $h_{t-1}$ = Previous hidden state (vector of size $n_h$)
- $h_t$ = Current hidden state (vector of size $n_h$)
- $r_t$ = Reset gate activation (vector of size $n_h$, values in $[0, 1]$)
- $z_t$ = Update gate activation (vector of size $n_h$, values in $[0, 1]$)
- $\tilde{h}_t$ = Candidate hidden state (vector of size $n_h$, values in $[-1, 1]$)
- $o_t$ = Pre-activation output (vector of size $n_y$)
- $y_t$ = Output probabilities (vector of size $n_y$, sum to 1)
- $\hat{y}_t$ = True target label (one-hot encoded, vector of size $n_y$)
- $L_t$ = Loss at time $t$ (scalar)
- $L$ = Total/average loss over sequence (scalar)

### Complete Numerical Example: Sentiment Classification

Let's work through a complete forward propagation example with the sentence **["good", "movie"]**.

**Task**: Binary sentiment classification (positive/negative)

**Setup**:
```
Vocabulary: {"good": 0, "bad": 1, "movie": 2, "<PAD>": 3}
Input sequence: ["good", "movie"] → indices [0, 2]
Target: positive sentiment → [1, 0] (one-hot: positive=1, negative=0)

Dimensions:
- n_x = 4 (vocabulary size, one-hot encoded)
- n_h = 3 (hidden units - small for clarity)
- n_y = 2 (binary classification)
- T = 2 (sequence length)
```

**Parameters** (simplified for demonstration):

```
Reset gate weights W_r (3×7):
[0.2  0.1  0.3  0.2  0.1  0.2  0.3]  ← computes r_t[0]
[0.1  0.3  0.2  0.1  0.2  0.1  0.2]  ← computes r_t[1]
[0.3  0.2  0.1  0.3  0.1  0.3  0.1]  ← computes r_t[2]
└─────h_{t-1}─────┘  └────x_t─────┘
    (3 dims)           (4 dims)

Update gate weights W_z (3×7):
[0.3  0.2  0.1  0.2  0.2  0.1  0.3]
[0.2  0.1  0.3  0.1  0.3  0.2  0.1]
[0.1  0.3  0.2  0.3  0.1  0.2  0.2]

Candidate weights W_h (3×7):
[0.4  0.2  0.3  0.3  0.1  0.2  0.4]
[0.2  0.4  0.1  0.2  0.3  0.1  0.2]
[0.3  0.1  0.4  0.1  0.2  0.4  0.1]

Output weights W_y (2×3):
[0.5  0.3  0.2]  ← computes y_t[0] (negative)
[0.4  0.2  0.5]  ← computes y_t[1] (positive)

Biases:
b_r = [0.1, 0.1, 0.1]ᵀ
b_z = [0.1, 0.1, 0.1]ᵀ
b_h = [0.0, 0.0, 0.0]ᵀ
b_y = [0.0, 0.0]ᵀ

Initial hidden state:
h_{-1} = [0.0, 0.0, 0.0]ᵀ
```

---

#### Time Step t=0: Input "good" = [1, 0, 0, 0]

**Visualization of Current State**:
```
═══════════════════════════════════════════════════════════════
                      TIME STEP t=0
                    Processing "good"
═══════════════════════════════════════════════════════════════

INPUT:  x_0 = [1, 0, 0, 0]ᵀ  ("good" - one-hot encoded)
PREVIOUS HIDDEN: h_{-1} = [0.0, 0.0, 0.0]ᵀ  (initialization)

         x_0            h_{-1}
          │               │
          └───────┬───────┘
                  │
     ┌────────────┴────────────┐
     │                         │
     ▼                         ▼
┌─────────┐              ┌─────────┐
│ Reset   │              │ Update  │
│ Gate    │              │ Gate    │
│ r_0     │              │ z_0     │
└────┬────┘              └────┬────┘
     │                        │
     │ Apply to h_{-1}        │
     ▼                        │
  r_0 ⊙ h_{-1}                │
     │                        │
     └────┬────────────────────┘
          │
          ▼
    ┌─────────────┐
    │ Candidate   │
    │   h̃_0       │
    └──────┬──────┘
           │
           │ Blend with h_{-1}
           │ controlled by z_0
           ▼
       ┌───────┐
       │  h_0  │  ← New hidden state
       └───┬───┘
           │
           ▼
       ┌───────┐
       │  y_0  │  ← Output prediction
       └───────┘
```

**Step 1: Compute Reset Gate $r_0$**

```
Concatenate inputs: [h_{-1}, x_0] = [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]ᵀ
                                      └──h_{-1}──┘  └─────x_0─────┘

Linear transformation: W_r · [h_{-1}, x_0]

Row 0: 0.2×0.0 + 0.1×0.0 + 0.3×0.0 + 0.2×1.0 + 0.1×0.0 + 0.2×0.0 + 0.3×0.0
     = 0.0 + 0.0 + 0.0 + 0.2 + 0.0 + 0.0 + 0.0 = 0.2

Row 1: 0.1×0.0 + 0.3×0.0 + 0.2×0.0 + 0.1×1.0 + 0.2×0.0 + 0.1×0.0 + 0.2×0.0
     = 0.0 + 0.0 + 0.0 + 0.1 + 0.0 + 0.0 + 0.0 = 0.1

Row 2: 0.3×0.0 + 0.2×0.0 + 0.1×0.0 + 0.3×1.0 + 0.1×0.0 + 0.3×0.0 + 0.1×0.0
     = 0.0 + 0.0 + 0.0 + 0.3 + 0.0 + 0.0 + 0.0 = 0.3

Pre-activation: z_r = [0.2, 0.1, 0.3]ᵀ

Add bias: z_r + b_r = [0.2, 0.1, 0.3]ᵀ + [0.1, 0.1, 0.1]ᵀ = [0.3, 0.2, 0.4]ᵀ

Apply sigmoid:
r_0[0] = σ(0.3) = 1/(1 + e^(-0.3)) = 1/(1 + 0.741) = 0.574
r_0[1] = σ(0.2) = 1/(1 + e^(-0.2)) = 1/(1 + 0.819) = 0.550
r_0[2] = σ(0.4) = 1/(1 + e^(-0.4)) = 1/(1 + 0.670) = 0.599

r_0 = [0.574, 0.550, 0.599]ᵀ

Interpretation: All gates ~0.5-0.6, suggesting moderate use of past
(but since h_{-1} = 0, this doesn't matter at t=0)
```

**Step 2: Compute Update Gate $z_0$**

```
W_z · [h_{-1}, x_0]:

Row 0: 0.3×0.0 + 0.2×0.0 + 0.1×0.0 + 0.2×1.0 + 0.2×0.0 + 0.1×0.0 + 0.3×0.0
     = 0.2

Row 1: 0.2×0.0 + 0.1×0.0 + 0.3×0.0 + 0.1×1.0 + 0.3×0.0 + 0.2×0.0 + 0.1×0.0
     = 0.1

Row 2: 0.1×0.0 + 0.3×0.0 + 0.2×0.0 + 0.3×1.0 + 0.1×0.0 + 0.2×0.0 + 0.2×0.0
     = 0.3

Add bias: [0.2, 0.1, 0.3]ᵀ + [0.1, 0.1, 0.1]ᵀ = [0.3, 0.2, 0.4]ᵀ

Apply sigmoid:
z_0 = [σ(0.3), σ(0.2), σ(0.4)]ᵀ = [0.574, 0.550, 0.599]ᵀ

Interpretation: Update gates ~0.5-0.6
When z ≈ 0.5: balanced update between old and new
```

**Step 3: Compute Candidate Hidden State $\tilde{h}_0$**

```
Apply reset gate to previous hidden state:
r_0 ⊙ h_{-1} = [0.574, 0.550, 0.599]ᵀ ⊙ [0.0, 0.0, 0.0]ᵀ = [0.0, 0.0, 0.0]ᵀ

Concatenate: [r_0 ⊙ h_{-1}, x_0] = [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]ᵀ

W_h · [r_0 ⊙ h_{-1}, x_0]:

Row 0: 0.4×0.0 + 0.2×0.0 + 0.3×0.0 + 0.3×1.0 + 0.1×0.0 + 0.2×0.0 + 0.4×0.0
     = 0.3

Row 1: 0.2×0.0 + 0.4×0.0 + 0.1×0.0 + 0.2×1.0 + 0.3×0.0 + 0.1×0.0 + 0.2×0.0
     = 0.2

Row 2: 0.3×0.0 + 0.1×0.0 + 0.4×0.0 + 0.1×1.0 + 0.2×0.0 + 0.4×0.0 + 0.1×0.0
     = 0.1

Add bias: [0.3, 0.2, 0.1]ᵀ + [0.0, 0.0, 0.0]ᵀ = [0.3, 0.2, 0.1]ᵀ

Apply tanh:
h̃_0[0] = tanh(0.3) = (e^0.6 - 1)/(e^0.6 + 1) = 0.291
h̃_0[1] = tanh(0.2) = (e^0.4 - 1)/(e^0.4 + 1) = 0.197
h̃_0[2] = tanh(0.1) = (e^0.2 - 1)/(e^0.2 + 1) = 0.100

h̃_0 = [0.291, 0.197, 0.100]ᵀ

Interpretation: All positive candidate values
→ New information suggests positive activations
```

**Step 4: Update Hidden State $h_0$**

```
Compute components:

z_0 ⊙ h_{-1} = [0.574, 0.550, 0.599]ᵀ ⊙ [0.0, 0.0, 0.0]ᵀ = [0.0, 0.0, 0.0]ᵀ
(Keep from old memory - but old memory is zero)

(1 - z_0) = [1.0, 1.0, 1.0]ᵀ - [0.574, 0.550, 0.599]ᵀ = [0.426, 0.450, 0.401]ᵀ

(1 - z_0) ⊙ h̃_0 = [0.426, 0.450, 0.401]ᵀ ⊙ [0.291, 0.197, 0.100]ᵀ
                 = [0.124, 0.089, 0.040]ᵀ
(Add from new candidate)

Final hidden state:
h_0 = [0.0, 0.0, 0.0]ᵀ + [0.124, 0.089, 0.040]ᵀ = [0.124, 0.089, 0.040]ᵀ

Interpretation:
├─ Since h_{-1} = 0, h_0 = (1-z_0) ⊙ h̃_0
├─ Hidden state initialized with ~40-50% of candidate
└─ Memory now contains representation of "good"
```

**Step 5: Compute Output $y_0$**

```
Linear transformation:
o_0 = W_y · h_0 + b_y

o_0[0] = 0.5×0.124 + 0.3×0.089 + 0.2×0.040 + 0.0
       = 0.062 + 0.027 + 0.008 = 0.097  (negative class score)

o_0[1] = 0.4×0.124 + 0.2×0.089 + 0.5×0.040 + 0.0
       = 0.050 + 0.018 + 0.020 = 0.088  (positive class score)

o_0 = [0.097, 0.088]ᵀ

Apply softmax:
exp(o_0) = [exp(0.097), exp(0.088)] = [1.102, 1.092]
sum = 1.102 + 1.092 = 2.194

y_0[0] = 1.102 / 2.194 = 0.502  (probability of negative)
y_0[1] = 1.092 / 2.194 = 0.498  (probability of positive)

y_0 = [0.502, 0.498]ᵀ

Interpretation:
├─ Almost 50-50 split between negative and positive
├─ Slight lean toward negative (0.502 > 0.498)
└─ Network is uncertain - needs more context!
```

**Step 6: Compute Loss $L_0$** (assuming target is [1, 0] = positive)

```
Target: ŷ_0 = [1, 0]ᵀ (positive sentiment)
Predicted: y_0 = [0.502, 0.498]ᵀ

Cross-entropy loss:
L_0 = -Σ ŷ_0[i] log(y_0[i])
    = -(ŷ_0[0] × log(y_0[0]) + ŷ_0[1] × log(y_0[1]))
    = -(1 × log(0.502) + 0 × log(0.498))
    = -log(0.502)
    = -(-0.689)
    = 0.689

Interpretation: Moderate loss since predicted probability
for correct class (positive) is only 0.502
```

**Summary After Time Step t=0**:

```
╔════════════════════════════════════════════════════════════════╗
║                  TIME STEP t=0 COMPLETE                        ║
╠════════════════════════════════════════════════════════════════╣
║                                                                ║
║  INPUT:  "good" = [1, 0, 0, 0]                                ║
║                                                                ║
║  GATES:                                                        ║
║  r_0 = [0.574, 0.550, 0.599]  (reset - moderate)             ║
║  z_0 = [0.574, 0.550, 0.599]  (update - moderate)            ║
║                                                                ║
║  CANDIDATE:                                                    ║
║  h̃_0 = [0.291, 0.197, 0.100]  (all positive)                 ║
║                                                                ║
║  HIDDEN STATE:                                                 ║
║  h_0 = [0.124, 0.089, 0.040]  (initialized from candidate)   ║
║                                                                ║
║  OUTPUT:                                                       ║
║  y_0 = [0.502, 0.498]  (negative vs positive)                ║
║         ↑       ↑                                              ║
║      negative positive                                         ║
║                                                                ║
║  LOSS:                                                         ║
║  L_0 = 0.689  (moderate - network is uncertain)              ║
║                                                                ║
║  INTERPRETATION:                                               ║
║  After seeing "good", the network has slight negative bias    ║
║  (0.502 > 0.498). This will likely change after seeing        ║
║  "movie" at t=1. The hidden state now contains encoded        ║
║  representation of "good".                                     ║
║                                                                ║
╚════════════════════════════════════════════════════════════════╝
```

---

#### Time Step t=1: Input "movie" = [0, 0, 1, 0]

**Visualization of Current State**:
```
═══════════════════════════════════════════════════════════════
                      TIME STEP t=1
                   Processing "movie"
═══════════════════════════════════════════════════════════════

INPUT:  x_1 = [0, 0, 1, 0]ᵀ  ("movie" - one-hot encoded)
PREVIOUS HIDDEN: h_0 = [0.124, 0.089, 0.040]ᵀ  (from t=0)
                         ↑
                    Carries "good"

         x_1            h_0
          │               │
          └───────┬───────┘
                  │ NOW h_0 has information!
     ┌────────────┴────────────┐
     │                         │
     ▼                         ▼
┌─────────┐              ┌─────────┐
│ Reset   │              │ Update  │
│ Gate    │              │ Gate    │
│ r_1     │              │ z_1     │
└────┬────┘              └────┬────┘
     │                        │
     │ Filters h_0            │
     ▼                        │
  r_1 ⊙ h_0                   │
     │   ↑                    │
     │   "Selectively         │
     │    forget"             │
     │                        │
     └────┬────────────────────┘
          │
          ▼
    ┌─────────────┐
    │ Candidate   │
    │   h̃_1       │  Combines reset h_0 with x_1
    └──────┬──────┘
           │
           │ Blend with h_0
           │ controlled by z_1
           ▼
       ┌───────┐
       │  h_1  │  ← New hidden state
       └───┬───┘       (encodes "good movie")
           │
           ▼
       ┌───────┐
       │  y_1  │  ← Final prediction
       └───────┘
```

**Step 1: Compute Reset Gate $r_1$**

```
Concatenate inputs: [h_0, x_1] = [0.124, 0.089, 0.040, 0.0, 0.0, 1.0, 0.0]ᵀ
                                   └────h_0─────┘  └─────x_1─────┘

W_r · [h_0, x_1]:

Row 0: 0.2×0.124 + 0.1×0.089 + 0.3×0.040 + 0.2×0.0 + 0.1×0.0 + 0.2×1.0 + 0.3×0.0
     = 0.025 + 0.009 + 0.012 + 0.0 + 0.0 + 0.2 + 0.0 = 0.246

Row 1: 0.1×0.124 + 0.3×0.089 + 0.2×0.040 + 0.1×0.0 + 0.2×0.0 + 0.1×1.0 + 0.2×0.0
     = 0.012 + 0.027 + 0.008 + 0.0 + 0.0 + 0.1 + 0.0 = 0.147

Row 2: 0.3×0.124 + 0.2×0.089 + 0.1×0.040 + 0.3×0.0 + 0.1×0.0 + 0.3×1.0 + 0.1×0.0
     = 0.037 + 0.018 + 0.004 + 0.0 + 0.0 + 0.3 + 0.0 = 0.359

Add bias: [0.246, 0.147, 0.359]ᵀ + [0.1, 0.1, 0.1]ᵀ = [0.346, 0.247, 0.459]ᵀ

Apply sigmoid:
r_1 = [σ(0.346), σ(0.247), σ(0.459)]ᵀ = [0.586, 0.561, 0.613]ᵀ

Interpretation:
├─ All gates are ~0.56-0.61 (moderate to high)
├─ Network will use most of h_0 when computing candidate
└─ The context from "good" will influence "movie" processing
```

**Step 2: Compute Update Gate $z_1$**

```
W_z · [h_0, x_1]:

Row 0: 0.3×0.124 + 0.2×0.089 + 0.1×0.040 + 0.2×0.0 + 0.2×0.0 + 0.1×1.0 + 0.3×0.0
     = 0.037 + 0.018 + 0.004 + 0.0 + 0.0 + 0.1 + 0.0 = 0.159

Row 1: 0.2×0.124 + 0.1×0.089 + 0.3×0.040 + 0.1×0.0 + 0.3×0.0 + 0.2×1.0 + 0.1×0.0
     = 0.025 + 0.009 + 0.012 + 0.0 + 0.0 + 0.2 + 0.0 = 0.246

Row 2: 0.1×0.124 + 0.3×0.089 + 0.2×0.040 + 0.3×0.0 + 0.1×0.0 + 0.2×1.0 + 0.2×0.0
     = 0.012 + 0.027 + 0.008 + 0.0 + 0.0 + 0.2 + 0.0 = 0.247

Add bias: [0.159, 0.246, 0.247]ᵀ + [0.1, 0.1, 0.1]ᵀ = [0.259, 0.346, 0.347]ᵀ

Apply sigmoid:
z_1 = [σ(0.259), σ(0.346), σ(0.347)]ᵀ = [0.564, 0.586, 0.586]ᵀ

Interpretation:
├─ Update gates are ~0.56-0.59
├─ Will keep ~56-59% of old h_0 (memory of "good")
└─ Will add ~41-44% of new candidate (incorporating "movie")
```

**Step 3: Compute Candidate Hidden State $\tilde{h}_1$**

```
Apply reset gate to previous hidden state:
r_1 ⊙ h_0 = [0.586, 0.561, 0.613]ᵀ ⊙ [0.124, 0.089, 0.040]ᵀ
          = [0.073, 0.050, 0.025]ᵀ

Interpretation of reset:
├─ h_0[0] = 0.124 → filtered to 0.073 (58.6% kept)
├─ h_0[1] = 0.089 → filtered to 0.050 (56.1% kept)
└─ h_0[2] = 0.040 → filtered to 0.025 (61.3% kept)
Network keeps most of the past context but slightly reduces it.

Concatenate: [r_1 ⊙ h_0, x_1] = [0.073, 0.050, 0.025, 0.0, 0.0, 1.0, 0.0]ᵀ

W_h · [r_1 ⊙ h_0, x_1]:

Row 0: 0.4×0.073 + 0.2×0.050 + 0.3×0.025 + 0.3×0.0 + 0.1×0.0 + 0.2×1.0 + 0.4×0.0
     = 0.029 + 0.010 + 0.008 + 0.0 + 0.0 + 0.2 + 0.0 = 0.247

Row 1: 0.2×0.073 + 0.4×0.050 + 0.1×0.025 + 0.2×0.0 + 0.3×0.0 + 0.1×1.0 + 0.2×0.0
     = 0.015 + 0.020 + 0.003 + 0.0 + 0.0 + 0.1 + 0.0 = 0.138

Row 2: 0.3×0.073 + 0.1×0.050 + 0.4×0.025 + 0.1×0.0 + 0.2×0.0 + 0.4×1.0 + 0.1×0.0
     = 0.022 + 0.005 + 0.010 + 0.0 + 0.0 + 0.4 + 0.0 = 0.437

Add bias: [0.247, 0.138, 0.437]ᵀ + [0.0, 0.0, 0.0]ᵀ = [0.247, 0.138, 0.437]ᵀ

Apply tanh:
h̃_1 = [tanh(0.247), tanh(0.138), tanh(0.437)]ᵀ = [0.242, 0.137, 0.411]ᵀ

Interpretation:
├─ All positive candidate values (similar to t=0)
├─ h̃_1[2] = 0.411 is notably higher than h̃_1[0] and h̃_1[1]
└─ This dimension might be specializing in sentiment
```

**Step 4: Update Hidden State $h_1$**

```
Compute components:

z_1 ⊙ h_0 = [0.564, 0.586, 0.586]ᵀ ⊙ [0.124, 0.089, 0.040]ᵀ
          = [0.070, 0.052, 0.023]ᵀ
(Keep this much from "good")

(1 - z_1) = [1.0, 1.0, 1.0]ᵀ - [0.564, 0.586, 0.586]ᵀ = [0.436, 0.414, 0.414]ᵀ

(1 - z_1) ⊙ h̃_1 = [0.436, 0.414, 0.414]ᵀ ⊙ [0.242, 0.137, 0.411]ᵀ
                 = [0.106, 0.057, 0.170]ᵀ
(Add this much from "movie")

Final hidden state:
h_1 = [0.070, 0.052, 0.023]ᵀ + [0.106, 0.057, 0.170]ᵀ
    = [0.176, 0.109, 0.193]ᵀ

Analysis of change:
┌──────────────────────────────────────────────────────────┐
│ Hidden State Evolution: "good" → "good movie"           │
├──────────────────────────────────────────────────────────┤
│                                                          │
│ h_0 = [0.124, 0.089, 0.040]  (after "good")            │
│ h_1 = [0.176, 0.109, 0.193]  (after "good movie")      │
│                                                          │
│ Change:                                                  │
│ Δh[0] = +0.052  (+41.9%)  ← Moderate increase          │
│ Δh[1] = +0.020  (+22.5%)  ← Small increase             │
│ Δh[2] = +0.153  (+382.5%) ← LARGE increase!            │
│                             ↑                            │
│                         This dimension seems to capture  │
│                         positive sentiment strongly      │
│                                                          │
│ The hidden state now encodes the combined meaning of    │
│ "good movie" - notice dimension 2 has grown             │
│ significantly, possibly capturing sentiment.            │
└──────────────────────────────────────────────────────────┘
```

**Step 5: Compute Output $y_1$**

```
Linear transformation:
o_1 = W_y · h_1 + b_y

o_1[0] = 0.5×0.176 + 0.3×0.109 + 0.2×0.193 + 0.0
       = 0.088 + 0.033 + 0.039 = 0.160  (negative class score)

o_1[1] = 0.4×0.176 + 0.2×0.109 + 0.5×0.193 + 0.0
       = 0.070 + 0.022 + 0.097 = 0.189  (positive class score)

o_1 = [0.160, 0.189]ᵀ

Apply softmax:
exp(o_1) = [exp(0.160), exp(0.189)] = [1.174, 1.208]
sum = 1.174 + 1.208 = 2.382

y_1[0] = 1.174 / 2.382 = 0.493  (probability of negative)
y_1[1] = 1.208 / 2.382 = 0.507  (probability of positive)

y_1 = [0.493, 0.507]ᵀ

Interpretation:
├─ NOW the positive class has higher probability (0.507 > 0.493)!
├─ After seeing "good movie", network leans toward positive sentiment
├─ The change from t=0 shows the network is learning to combine words
└─ Still relatively uncertain (close to 50-50), but trending right
```

**Step 6: Compute Loss $L_1$**

```
Target: ŷ_1 = [1, 0]ᵀ (positive sentiment)
Predicted: y_1 = [0.493, 0.507]ᵀ

Cross-entropy loss:
L_1 = -Σ ŷ_1[i] log(y_1[i])
    = -(1 × log(0.507) + 0 × log(0.493))
    = -log(0.507)
    = -(-0.679)
    = 0.679

Comparison with t=0:
L_0 = 0.689 (predicted 0.502 for positive)
L_1 = 0.679 (predicted 0.507 for positive)

The loss has DECREASED slightly! The network is learning!
```

**Summary After Time Step t=1**:

```
╔════════════════════════════════════════════════════════════════╗
║                  TIME STEP t=1 COMPLETE                        ║
╠════════════════════════════════════════════════════════════════╣
║                                                                ║
║  INPUT:  "movie" = [0, 0, 1, 0]                               ║
║                                                                ║
║  PREVIOUS CONTEXT:                                             ║
║  h_0 = [0.124, 0.089, 0.040]  (encoded "good")               ║
║                                                                ║
║  GATES:                                                        ║
║  r_1 = [0.586, 0.561, 0.613]  (reset - moderate-high)        ║
║  z_1 = [0.564, 0.586, 0.586]  (update - moderate-high)       ║
║                                                                ║
║  RESET EFFECT:                                                 ║
║  r_1 ⊙ h_0 = [0.073, 0.050, 0.025]                           ║
║  → Kept ~56-61% of previous context                           ║
║                                                                ║
║  CANDIDATE:                                                    ║
║  h̃_1 = [0.242, 0.137, 0.411]  (combines reset h_0 + "movie") ║
║                                                                ║
║  HIDDEN STATE:                                                 ║
║  h_1 = [0.176, 0.109, 0.193]  (encodes "good movie")         ║
║                                                                ║
║  OUTPUT:                                                       ║
║  y_1 = [0.493, 0.507]  (negative vs positive)                ║
║         ↑       ↑                                              ║
║      negative positive  ← NOW POSITIVE IS HIGHER!             ║
║                                                                ║
║  LOSS:                                                         ║
║  L_1 = 0.679  (slightly improved from L_0 = 0.689)           ║
║                                                                ║
║  KEY OBSERVATION:                                              ║
║  After processing "good movie", the network now correctly     ║
║  predicts positive sentiment (0.507 > 0.493), showing the     ║
║  sequential processing is working! The gating mechanism       ║
║  allowed the network to:                                       ║
║  1. Keep relevant info from "good" via update gate            ║
║  2. Selectively use past via reset gate                       ║
║  3. Combine with "movie" to form composite representation     ║
║                                                                ║
╚════════════════════════════════════════════════════════════════╝
```

---

### Final Loss Computation

```
Total loss over sequence:
L = (L_0 + L_1) / T = (0.689 + 0.679) / 2 = 0.684

Interpretation:
├─ Average loss is 0.684
├─ Network showed improvement from t=0 to t=1
├─ Still room for improvement (perfect prediction would give L ≈ 0)
└─ The gates successfully combined information across time steps
```

### Gate Behavior Visualization

```
═══════════════════════════════════════════════════════════════════════
               GATE ACTIVATION VISUALIZATION
═══════════════════════════════════════════════════════════════════════

Time Step t=0 ("good"):
─────────────────────────

Reset Gate r_0 = [0.574, 0.550, 0.599]
┌────────────────────────────────┐
│ Dim 0: ████████████░░░░░░░░░░ │ 57.4%  Medium
│ Dim 1: ███████████░░░░░░░░░░░ │ 55.0%  Medium  
│ Dim 2: ████████████░░░░░░░░░░ │ 59.9%  Medium
└────────────────────────────────┘

Update Gate z_0 = [0.574, 0.550, 0.599]
┌────────────────────────────────┐
│ Dim 0: ████████████░░░░░░░░░░ │ 57.4%  Keep old
│ Dim 1: ███████████░░░░░░░░░░░ │ 55.0%  Keep old
│ Dim 2: ████████████░░░░░░░░░░ │ 59.9%  Keep old
└────────────────────────────────┘
Effect: Since h_{-1} = 0, these don't matter much


Time Step t=1 ("movie"):
──────────────────────────

Reset Gate r_1 = [0.586, 0.561, 0.613]
┌────────────────────────────────┐
│ Dim 0: ████████████░░░░░░░░░░ │ 58.6%  Medium-High
│ Dim 1: ███████████░░░░░░░░░░░ │ 56.1%  Medium
│ Dim 2: ████████████░░░░░░░░░░ │ 61.3%  Medium-High
└────────────────────────────────┘
Effect: Keep most of "good" context when computing candidate

Update Gate z_1 = [0.564, 0.586, 0.586]
┌────────────────────────────────┐
│ Dim 0: ███████████░░░░░░░░░░░ │ 56.4%  Keep old
│ Dim 1: ████████████░░░░░░░░░░ │ 58.6%  Keep old
│ Dim 2: ████████████░░░░░░░░░░ │ 58.6%  Keep old
└────────────────────────────────┘
Effect: Balanced update - keep ~56-59% old, add ~41-44% new


Information Flow Summary:
═════════════════════════

t=0:  "good" → h_0 [0.124, 0.089, 0.040]
                    │
                    │ Carried forward with
                    │ z_1 ⊙ h_0 = 56-59% kept
                    ▼
t=1:  "movie" → h_1 [0.176, 0.109, 0.193]
                     │
                     └─→ Combined representation
                         of "good movie"

Key Insight:
The update gates (~0.56-0.59) mean the network is maintaining
a good balance: it keeps majority of old information while
still incorporating new input. This is why h_1[2] grew so much
(+383%) - it's accumulating positive sentiment from both words!
```

### Forward Propagation Summary

```
╔════════════════════════════════════════════════════════════════╗
║            GRU FORWARD PROPAGATION ALGORITHM                   ║
╠════════════════════════════════════════════════════════════════╣
║                                                                ║
║ INPUT:                                                         ║
║   - Sequence X = [x_0, x_1, ..., x_{T-1}]                    ║
║   - Parameters: W_r, W_z, W_h, W_y, b_r, b_z, b_h, b_y       ║
║   - Initial hidden state: h_{-1} (usually zeros)              ║
║                                                                ║
║ PROCESS (for each time step t):                                ║
║   1. r_t = σ(W_r [h_{t-1}, x_t] + b_r)       [Reset gate]    ║
║   2. z_t = σ(W_z [h_{t-1}, x_t] + b_z)       [Update gate]   ║
║   3. h̃_t = tanh(W_h [r_t⊙h_{t-1}, x_t] + b_h) [Candidate]    ║
║   4. h_t = z_t⊙h_{t-1} + (1-z_t)⊙h̃_t          [Update]        ║
║   5. y_t = softmax(W_y h_t + b_y)            [Output]        ║
║   6. L_t = -Σ ŷ_{t,i} log(y_{t,i})           [Loss]          ║
║                                                                ║
║ OUTPUT:                                                        ║
║   - Hidden states: H = [h_0, h_1, ..., h_{T-1}]              ║
║   - Predictions: Y = [y_0, y_1, ..., y_{T-1}]                ║
║   - Total loss: L = (1/T) Σ_{t=0}^{T-1} L_t                  ║
║                                                                ║
║ KEY ADVANTAGES OVER VANILLA RNN:                               ║
║   • Gated memory update (not simple replacement)              ║
║   • Selective forgetting via reset gate                       ║
║   • Adaptive information flow via update gate                 ║
║   • Direct gradient path through update gate                  ║
║   • Better handling of long-term dependencies                 ║
║                                                                ║
╚════════════════════════════════════════════════════════════════╝
```

---

## Backward Propagation Through Time (BPTT) for GRU

### Overview

**Backpropagation Through Time (BPTT)** for GRU is more complex than for vanilla RNNs due to the additional gating mechanisms. However, these gates actually *help* with gradient flow, making training more stable and effective.

**Key Challenge**: We need to compute gradients not just for the hidden state, but also for:
1. **Reset gate** ($r_t$)
2. **Update gate** ($z_t$)
3. **Candidate hidden state** ($\tilde{h}_t$)
4. **Hidden state** ($h_t$)
5. All associated weight matrices

```
Gradient Flow in GRU:
═════════════════════

Forward (computation):
h_{t-1} → [gates] → h_t → h_{t+1} → ... → Loss

Backward (gradients):
∂L/∂h_{t-1} ← [gate gradients] ← ∂L/∂h_t ← ∂L/∂h_{t+1} ← ... ← ∂L

The gradients flow through TWO paths:
1. Direct path through update gate: z_t ⊙ h_{t-1}
2. Indirect path through candidate: (1-z_t) ⊙ h̃_t ← r_t ⊙ h_{t-1}
```

### Complete Network Topology (T=2 time steps)

**Understanding the Complete GRU Network Topology:**

This comprehensive diagram shows the full computational graph of a GRU unrolled over 2 time steps. Unlike vanilla RNNs, GRUs have additional internal structure (gates) at each time step that control information flow.

**What Makes GRU Different:**

At each time step, instead of a simple recurrent connection, we have:
1. **Reset Gate** ($r_t$): Filters the previous hidden state
2. **Update Gate** ($z_t$): Controls the memory update
3. **Candidate** ($\tilde{h}_t$): Proposes new information
4. **Hidden State Update**: Blends old and new via update gate

This creates multiple gradient paths, which actually helps prevent vanishing gradients!

```
╔════════════════════════════════════════════════════════════════════════════════════╗
║                         FORWARD PROPAGATION (Left → Right)                         ║
╚════════════════════════════════════════════════════════════════════════════════════╝

                TIME STEP t=0                              TIME STEP t=1
                ═════════════                              ═════════════

Input:              x_0                                          x_1
                     │                                            │
         ┌───────────┴───────────┐                   ┌───────────┴───────────┐
         │                       │                   │                       │
         ▼                       ▼                   ▼                       ▼
    ┌────────┐              ┌────────┐          ┌────────┐              ┌────────┐
h_{-1} │ Reset  │          h_0 │ Update │      h_0 │ Reset  │          h_1 │ Update │
─────► │ Gate   │    ┌────────► │ Gate   │    ────► │ Gate   │    ┌────────► │ Gate   │
(zeros)│  r_0   │    │     │  z_0   │         │  r_1   │    │     │  z_1   │
       └───┬────┘    │         └────┬───┘         └───┬────┘    │         └────┬───┘
           │         │              │                 │         │              │
           │ r_0 ⊙ h_{-1}          │                 │ r_1 ⊙ h_0              │
           ▼         │              │                 ▼         │              │
    ┌─────────────┐ │              │          ┌─────────────┐ │              │
    │  Candidate  │ │              │          │  Candidate  │ │              │
    │    h̃_0      │ │              │          │    h̃_1      │ │              │
    │tanh(W_h·..) │ │              │          │tanh(W_h·..) │ │              │
    └──────┬──────┘ │              │          └──────┬──────┘ │              │
           │        │              │                 │        │              │
           │        │              │                 │        │              │
  (1-z_0)⊙h̃_0      │      z_0⊙h_{-1}       (1-z_1)⊙h̃_1      │      z_1⊙h_0
           │        │              │                 │        │              │
           └────────┴──────┬───────┘                 └────────┴──────┬───────┘
                          │ +                                        │ +
                          ▼                                          ▼
Hidden:                  h_0 ────────────────────────────────────► h_1
State                [0.124]          Recurrent                [0.176]
                     [0.089]          Connection               [0.109]
                     [0.040]          (via z_1⊙h_0)            [0.193]
                          │                                         │
                          │ W_y                                     │ W_y
                          ▼                                         ▼
Pre-output:              o_0                                       o_1
                          │                                         │
                          │ softmax                                 │ softmax
                          ▼                                         ▼
Output:                  y_0                                       y_1
                     [0.502]                                   [0.493]
                     [0.498]                                   [0.507]
                          │                                         │
                          │ Loss                                    │ Loss
                          ▼                                         ▼
Loss:                    L_0                                       L_1
                     (0.689)                                   (0.679)


╔════════════════════════════════════════════════════════════════════════════════════╗
║                        BACKWARD PROPAGATION (Right → Left)                         ║
╚════════════════════════════════════════════════════════════════════════════════════╝

                TIME STEP t=0                              TIME STEP t=1
                ═════════════                              ═════════════

Gradient:         ∂L/∂x_0                                     ∂L/∂x_1
                     ↑                                           ↑
                     │ Via W_r, W_z, W_h                         │ Via W_r, W_z, W_h
                     │                                           │
           ┌─────────┴─────────┐                     ┌─────────┴─────────┐
           │                   │                     │                   │
    ┌──────┴─────┐      ┌──────┴─────┐       ┌──────┴─────┐      ┌──────┴─────┐
    │  ∂L/∂r_0   │      │  ∂L/∂z_0   │       │  ∂L/∂r_1   │      │  ∂L/∂z_1   │
    │  (reset)   │      │  (update)  │       │  (reset)   │      │  (update)  │
    └──────┬─────┘      └──────┬─────┘       └──────┬─────┘      └──────┬─────┘
           │                   │                     │                   │
           │ σ'                │ σ'                  │ σ'                │ σ'
           ▼                   ▼                     ▼                   ▼
    ┌─────────────┐     ┌─────────────┐      ┌─────────────┐     ┌─────────────┐
    │   ∂L/∂h̃_0   │     │             │      │   ∂L/∂h̃_1   │     │             │
    │ (candidate) │     │             │      │ (candidate) │     │             │
    │   tanh'     │     │             │      │   tanh'     │     │             │
    └──────┬──────┘     │             │      └──────┬──────┘     │             │
           │            │             │             │            │             │
           │            │             │             │            │             │
  ∂L/∂((1-z_0)⊙h̃_0)    │   ∂L/∂(z_0⊙h_{-1})      ∂L/∂((1-z_1)⊙h̃_1)    │   ∂L/∂(z_1⊙h_0)
           │            │             │             │            │             │
           └────────────┴──────┬──────┘             └────────────┴──────┬──────┘
                              │                                         │
                              ▼                                         ▼
Hidden:                  ∂L/∂h_0 ◄────────────────────────────────  ∂L/∂h_1
Gradient                 (from)              Temporal               (direct)
                         future              Gradient               from L_1
                              ↑              Flow                       ↑
                              │              (z_1)                      │
                              │                                         │ Via W_y^T
                              │                                         │
                         ∂L/∂o_0                                   ∂L/∂o_1
                              ↑                                         ↑
                              │ Softmax'                                │ Softmax'
                              │                                         │
                         ∂L/∂y_0                                   ∂L/∂y_1
                              ↑                                         ↑
                              │ Loss gradient                           │ Loss gradient
                              │                                         │
                            ∂L_0                                      ∂L_1


╔════════════════════════════════════════════════════════════════════════════════════╗
║                              GRADIENT ACCUMULATION                                 ║
╚════════════════════════════════════════════════════════════════════════════════════╝

Weight matrices are SHARED across time steps, so gradients ACCUMULATE:

Reset Gate Weights (W_r):
    ∂L/∂W_r = [contribution from t=0] + [contribution from t=1]
            = (∂L/∂z_r,0 · [h_{-1}, x_0]^T) + (∂L/∂z_r,1 · [h_0, x_1]^T)

Update Gate Weights (W_z):
    ∂L/∂W_z = [contribution from t=0] + [contribution from t=1]
            = (∂L/∂z_z,0 · [h_{-1}, x_0]^T) + (∂L/∂z_z,1 · [h_0, x_1]^T)

Candidate Weights (W_h):
    ∂L/∂W_h = [contribution from t=0] + [contribution from t=1]
            = (∂L/∂z_h,0 · [r_0⊙h_{-1}, x_0]^T) + (∂L/∂z_h,1 · [r_1⊙h_0, x_1]^T)

Output Weights (W_y):
    ∂L/∂W_y = [contribution from t=0] + [contribution from t=1]
            = (∂L_0/∂o_0 · h_0^T) + (∂L_1/∂o_1 · h_1^T)

Final weight update: W_new = W_old - learning_rate × accumulated_gradient


╔════════════════════════════════════════════════════════════════════════════════════╗
║                                 KEY INSIGHTS                                       ║
╚════════════════════════════════════════════════════════════════════════════════════╝

1. MULTIPLE GRADIENT PATHS: Unlike vanilla RNN, gradients flow through multiple paths:
   • Direct path: z_t ⊙ h_{t-1} (straight through update gate)
   • Indirect path: (1-z_t) ⊙ h̃_t ← [r_t ⊙ h_{t-1}] (through reset + candidate)

2. GATE CONTROL: The update gate z_t controls gradient magnitude
   • High z_t: More gradient flows directly (good for long-term dependencies!)
   • Low z_t: Gradients flow through candidate path

3. VANISHING GRADIENT MITIGATION: The direct path (z_t ⊙ h_{t-1}) provides an
   uninterrupted gradient highway, similar to residual connections in ResNet!

4. SELECTIVE MEMORY: Reset gate r_t allows selective forgetting during backprop,
   which can actually help by preventing irrelevant gradients from dominating

5. SHARED PARAMETERS: All weight matrices (W_r, W_z, W_h, W_y) are shared across
   time → gradients must be accumulated from all time steps before updating

6. COMPUTATIONAL GRAPH: Each time step has 3 "sub-computations":
   • Reset gate branch
   • Update gate branch
   • Candidate branch
   All feed into the hidden state update, creating a rich gradient flow structure
```

---

### Gradient Flow Through GRU Components

Before diving into step-by-step BPTT, let's understand how gradients flow through the GRU architecture.

**Plain English Explanation**:

The GRU hidden state update has a special structure:
$$h_t = z_t \odot h_{t-1} + (1 - z_t) \odot \tilde{h}_t$$

This creates **two paths** for gradients to flow backward:

1. **Direct Path** (through update gate):
   - Gradient flows from $h_t$ directly to $h_{t-1}$ via $z_t \odot h_{t-1}$
   - This is like a "gradient highway" - mostly unobstructed
   - Helps preserve long-term dependencies!

2. **Indirect Path** (through candidate and reset gate):
   - Gradient flows from $h_t$ to $\tilde{h}_t$ via $(1-z_t) \odot \tilde{h}_t$
   - Then from $\tilde{h}_t$ to $h_{t-1}$ via $r_t \odot h_{t-1}$
   - This path involves more nonlinearities (tanh, sigmoid)

```
Gradient Flow Paths:
════════════════════

         ∂L/∂h_t
            │
   ┌────────┴────────┐
   │                 │
   ▼                 ▼
∂L/∂(z_t⊙h_{t-1})  ∂L/∂((1-z_t)⊙h̃_t)
   │                 │
   │ PATH 1:         │ PATH 2:
   │ DIRECT          │ INDIRECT
   │                 │
   │                 ▼
   │            ∂L/∂h̃_t
   │                 │
   │                 │ tanh' derivative
   │                 ▼
   │            ∂L/∂(r_t⊙h_{t-1})
   │                 │
   │                 │
   └────────┬────────┘
            │
            ▼
       ∂L/∂h_{t-1}

KEY: Path 1 has FEWER operations → LESS vanishing!
```

---

### Step-by-Step BPTT with Visualizations

We'll continue with our ["good", "movie"] example and compute gradients backward from t=1 to t=0.

**Recall from forward pass**:
```
Time t=0 ("good"):
  x_0 = [1, 0, 0, 0]
  h_{-1} = [0.0, 0.0, 0.0]
  r_0 = [0.574, 0.550, 0.599]
  z_0 = [0.574, 0.550, 0.599]
  h̃_0 = [0.291, 0.197, 0.100]
  h_0 = [0.124, 0.089, 0.040]
  y_0 = [0.502, 0.498]
  L_0 = 0.689

Time t=1 ("movie"):
  x_1 = [0, 0, 1, 0]
  h_0 = [0.124, 0.089, 0.040]
  r_1 = [0.586, 0.561, 0.613]
  z_1 = [0.564, 0.586, 0.586]
  h̃_1 = [0.242, 0.137, 0.411]
  h_1 = [0.176, 0.109, 0.193]
  y_1 = [0.493, 0.507]
  L_1 = 0.679

Target: ŷ = [1, 0] (positive sentiment)
Learning rate: α = 0.01
```

---

#### STEP 1: Output Layer Gradients at t=1

**Visualization: Gradient Flow from Loss to Output Layer**

```
═══════════════════════════════════════════════════════════════════════
STEP 1: Computing ∂L_1/∂o_1 (Output Error Signal at t=1)
═══════════════════════════════════════════════════════════════════════

At time t=1 (final time step):

                Target         Prediction
                ŷ_1 = [1]      y_1 = [0.493]
                      [0]            [0.507]
                       │              │
                       └──────┬───────┘
                              │ (subtract)
                              ▼
                    Error = y_1 - ŷ_1
                              │
                    ┌─────────┴─────────┐
                    │  [-0.507]         │  ← Predicted too low for class 0
                    │  [ 0.507]         │  ← Predicted too high for class 1
                    └───────────────────┘
                              │
                              │ This is ∂L_1/∂o_1
                              ▼
                   [Ready to backpropagate]


Gradient Flow Diagram at t=1:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

             Loss L_1 = 0.679
                   │
                   │ ∂L_1/∂L_1 = 1.0
                   ▼
             ┌───────────┐
             │ Softmax + │
             │  CE Loss  │
             └─────┬─────┘
                   │ Chain rule simplifies!
                   │ ∂L_1/∂o_1 = y_1 - ŷ_1
                   ▼
         ┌──────────────────┐
         │  Output Error    │
         │  ∂L_1/∂o_1       │
         │  = [-0.507]      │
         │    [ 0.507]      │
         └──────────────────┘
                   │
                   │ Ready to flow backward to:
                   │ 1. Output weights W_y
                   │ 2. Hidden state h_1
                   ▼
```

**Mathematical Computation**:

$$\frac{\partial L_1}{\partial o_1} = y_1 - \hat{y}_1 = \begin{bmatrix} 0.493 \\ 0.507 \end{bmatrix} - \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \begin{bmatrix} -0.507 \\ 0.507 \end{bmatrix}$$

**Gradient for Output Weights**:

$$\frac{\partial L_1}{\partial W_y} = \frac{\partial L_1}{\partial o_1} \cdot h_1^T = \begin{bmatrix} -0.507 \\ 0.507 \end{bmatrix} \cdot \begin{bmatrix} 0.176 & 0.109 & 0.193 \end{bmatrix}$$

```
∂L_1/∂W_y = [-0.507 × 0.176  -0.507 × 0.109  -0.507 × 0.193]
            [ 0.507 × 0.176   0.507 × 0.109   0.507 × 0.193]

          = [-0.089  -0.055  -0.098]
            [ 0.089   0.055   0.098]
```

**Gradient for Output Bias**:

$$\frac{\partial L_1}{\partial b_y} = \frac{\partial L_1}{\partial o_1} = \begin{bmatrix} -0.507 \\ 0.507 \end{bmatrix}$$

---

#### STEP 2: Hidden State Gradient at t=1 (from output)

**Visualization: Gradient Flows Back to Hidden State**

```
═══════════════════════════════════════════════════════════════════════
STEP 2: Computing ∂L_1/∂h_1 (Direct Contribution from Output)
═══════════════════════════════════════════════════════════════════════

Gradient flows from output layer back to hidden state through W_y:

             ∂L_1/∂o_1 = [-0.507]
                          [ 0.507]
                              │
                              │ Multiply by W_y^T
                              ▼
          ┌──────────────────────────────────┐
          │     W_y^T (transposed)            │
          │                                  │
          │  [0.5  0.4]   ← from outputs     │
          │  [0.3  0.2]                      │
          │  [0.2  0.5]                      │
          └────────┬─────────────────────────┘
                   │ Matrix multiplication
                   ▼
         ┌─────────────────────┐
         │   ∂L_1/∂h_1          │
         │   = W_y^T · ∂L_1/∂o_1│
         │                      │
         │   = [-0.051]  ← h_1[0] gradient
         │     [-0.050]  ← h_1[1] gradient
         │     [ 0.152]  ← h_1[2] gradient
         └─────────────────────┘
                   │
                   │ Note: This is only the DIRECT gradient
                   │ from output. At t=1, there's no future!
                   │
                   ▼
           Total ∂L/∂h_1 = ∂L_1/∂h_1  (no future contribution)


Detailed Computation:
━━━━━━━━━━━━━━━━━━━━

W_y^T = [0.5  0.4]^T   [0.5  0.3  0.2]
        [0.3  0.2]   = [0.4  0.2  0.5]
        [0.2  0.5]

W_y^T · ∂L_1/∂o_1:

Row 0: 0.5×(-0.507) + 0.4×0.507 = -0.254 + 0.203 = -0.051
Row 1: 0.3×(-0.507) + 0.2×0.507 = -0.152 + 0.101 = -0.050
Row 2: 0.2×(-0.507) + 0.5×0.507 = -0.101 + 0.254 =  0.152

∂L_1/∂h_1 = [-0.051]
            [-0.050]
            [ 0.152]

Interpretation:
├─ h_1[0] should DECREASE (gradient = -0.051)
├─ h_1[1] should DECREASE (gradient = -0.050)
└─ h_1[2] should INCREASE (gradient = +0.152) ← Supports positive sentiment!
```

---

#### STEP 3: Update Gate Gradients at t=1

**Visualization: Gradient Flow Through Update Gate**

```
═══════════════════════════════════════════════════════════════════════
STEP 3: Computing ∂L/∂z_1 (Update Gate Gradient)
═══════════════════════════════════════════════════════════════════════

Recall the hidden state update equation:
h_1 = z_1 ⊙ h_0 + (1 - z_1) ⊙ h̃_1

The update gate z_1 appears in TWO places!

         h_0          z_1           h̃_1
          │           │              │
          │           │              │
          ▼           ▼              ▼
     ┌────────┐  ┌────────┐   ┌─────────┐
     │ z_1⊙h_0│  │1 - z_1 │   │(1-z_1)⊙h̃_1│
     │        │  │        │   │         │
     └────┬───┘  └───┬────┘   └────┬────┘
          │          │             │
          │   Path 1 │             │ Path 2
          └──────────┴──────┬──────┘
                           │ +
                           ▼
                          h_1
                           │
                           │ ∂L/∂h_1
                           ▼


Chain Rule Application:
━━━━━━━━━━━━━━━━━━━━━━━

∂L/∂z_1 = ∂L/∂h_1 ⊙ ∂h_1/∂z_1

∂h_1/∂z_1 = ?

From h_1 = z_1 ⊙ h_0 + (1-z_1) ⊙ h̃_1:

∂h_1/∂z_1 = h_0 + (-1) ⊙ h̃_1 = h_0 - h̃_1

Therefore:
∂L/∂z_1 = ∂L/∂h_1 ⊙ (h_0 - h̃_1)

This makes intuitive sense!
• If h_0 > h̃_1: Increasing z_1 increases h_1 → positive ∂h_1/∂z_1
• If h_0 < h̃_1: Increasing z_1 decreases h_1 → negative ∂h_1/∂z_1


Computation:
━━━━━━━━━━━

h_0 = [0.124]     h̃_1 = [0.242]
      [0.089]            [0.137]
      [0.040]            [0.411]

h_0 - h̃_1 = [0.124 - 0.242]   [-0.118]
            [0.089 - 0.137] = [-0.048]
            [0.040 - 0.411]   [-0.371]

∂L/∂h_1 = [-0.051]
          [-0.050]
          [ 0.152]

∂L/∂z_1 = ∂L/∂h_1 ⊙ (h_0 - h̃_1)

        = [-0.051] ⊙ [-0.118]   [-0.051 × -0.118]   [ 0.006]
          [-0.050]   [-0.048] = [-0.050 × -0.048] = [ 0.002]
          [ 0.152]   [-0.371]   [ 0.152 × -0.371]   [-0.056]

Interpretation:
├─ z_1[0] should INCREASE slightly (gradient = +0.006)
│  → Keep slightly MORE of h_0[0] (old memory)
├─ z_1[1] should INCREASE slightly (gradient = +0.002)
│  → Keep slightly MORE of h_0[1]
└─ z_1[2] should DECREASE (gradient = -0.056)
   → Keep LESS of h_0[2], accept MORE of h̃_1[2]
   This makes sense! h̃_1[2] = 0.411 is high (positive sentiment)
   and we want more of it!
```

**Now compute gradient w.r.t. pre-activation**:

Recall: $z_1 = \sigma(z_{z,1})$ where $z_{z,1}$ is pre-activation

Sigmoid derivative: $\frac{d\sigma(z)}{dz} = \sigma(z)(1 - \sigma(z))$

```
∂L/∂z_{z,1} = ∂L/∂z_1 ⊙ σ'(z_{z,1})
            = ∂L/∂z_1 ⊙ (z_1 ⊙ (1 - z_1))

z_1 = [0.564]     1 - z_1 = [0.436]
      [0.586]               [0.414]
      [0.586]               [0.414]

z_1 ⊙ (1 - z_1) = [0.564 × 0.436]   [0.246]
                  [0.586 × 0.414] = [0.243]
                  [0.586 × 0.414]   [0.243]

∂L/∂z_{z,1} = [ 0.006] ⊙ [0.246]   [ 0.001]
              [ 0.002]   [0.243] = [ 0.000]
              [-0.056]   [0.243]   [-0.014]
```

---

#### STEP 4: Candidate Hidden State Gradients at t=1

**Visualization: Gradient Flows to Candidate**

```
═══════════════════════════════════════════════════════════════════════
STEP 4: Computing ∂L/∂h̃_1 (Candidate Hidden State Gradient)
═══════════════════════════════════════════════════════════════════════

Recall: h_1 = z_1 ⊙ h_0 + (1 - z_1) ⊙ h̃_1

The candidate h̃_1 appears in the second term!

         ∂L/∂h_1
             │
             │ From hidden state gradient
             ▼
    ┌────────────────┐
    │   h_1 = ...    │
    │   + (1-z_1)⊙h̃_1│
    └────────┬───────┘
             │ Chain rule
             ▼
    ∂h_1/∂h̃_1 = (1 - z_1)
             │
             │ Element-wise multiply
             ▼
    ∂L/∂h̃_1 = ∂L/∂h_1 ⊙ (1 - z_1)


Computation:
━━━━━━━━━━━

∂L/∂h_1 = [-0.051]     1 - z_1 = [0.436]
          [-0.050]               [0.414]
          [ 0.152]               [0.414]

∂L/∂h̃_1 = ∂L/∂h_1 ⊙ (1 - z_1)

        = [-0.051] ⊙ [0.436]   [-0.051 × 0.436]   [-0.022]
          [-0.050]   [0.414] = [-0.050 × 0.414] = [-0.021]
          [ 0.152]   [0.414]   [ 0.152 × 0.414]   [ 0.063]

Interpretation:
├─ h̃_1[0] should DECREASE (gradient = -0.022)
├─ h̃_1[1] should DECREASE (gradient = -0.021)
└─ h̃_1[2] should INCREASE (gradient = +0.063) ← Candidate for positive!

The (1-z_1) factor scales the gradient:
• Where z_1 is high (~0.6): gradient is scaled by ~0.4
• This means the candidate has less influence when update gate is high
  (which makes sense - high z_1 means "keep old memory")
```

**Now compute gradient w.r.t. pre-activation**:

Recall: $\tilde{h}_1 = \tanh(z_{h,1})$ where $z_{h,1}$ is pre-activation

Tanh derivative: $\frac{d\tanh(z)}{dz} = 1 - \tanh^2(z)$

```
∂L/∂z_{h,1} = ∂L/∂h̃_1 ⊙ tanh'(z_{h,1})
            = ∂L/∂h̃_1 ⊙ (1 - h̃_1²)

h̃_1 = [0.242]     h̃_1² = [0.059]
      [0.137]             [0.019]
      [0.411]             [0.169]

1 - h̃_1² = [0.941]
           [0.981]
           [0.831]

∂L/∂z_{h,1} = [-0.022] ⊙ [0.941]   [-0.021]
              [-0.021]   [0.981] = [-0.020]
              [ 0.063]   [0.831]   [ 0.052]
```

**Gradient for candidate weights**:

$$\frac{\partial L_1}{\partial W_h} = \frac{\partial L}{\partial z_{h,1}} \cdot [r_1 \odot h_0, x_1]^T$$

```
r_1 ⊙ h_0 = [0.586, 0.561, 0.613] ⊙ [0.124, 0.089, 0.040]
          = [0.073, 0.050, 0.025]

[r_1 ⊙ h_0, x_1] = [0.073, 0.050, 0.025, 0.0, 0.0, 1.0, 0.0]

∂L_1/∂W_h = [-0.021] × [0.073  0.050  0.025  0.0  0.0  1.0  0.0]
            [-0.020]
            [ 0.052]

          = [-0.002  -0.001  -0.001  0.000  0.000  -0.021  0.000]
            [-0.001  -0.001  -0.001  0.000  0.000  -0.020  0.000]
            [ 0.004   0.003   0.001  0.000  0.000   0.052  0.000]
```

---

#### STEP 5: Reset Gate Gradients at t=1

**Visualization: Gradient Flows Through Reset Gate**

```
═══════════════════════════════════════════════════════════════════════
STEP 5: Computing ∂L/∂r_1 (Reset Gate Gradient)
═══════════════════════════════════════════════════════════════════════

Recall the candidate computation:
h̃_1 = tanh(W_h [r_1 ⊙ h_0, x_1] + b_h)

The reset gate r_1 appears inside the candidate computation!

         ∂L/∂h̃_1
             │
             │ From candidate gradient
             ▼
    ┌────────────────────┐
    │ h̃_1 = tanh(W_h·..)│
    │                    │
    │ Input: [r_1⊙h_0, x_1]│
    └────────┬───────────┘
             │ Chain rule through W_h
             ▼
    ∂L/∂(r_1 ⊙ h_0)
             │
             │ ∂(r_1⊙h_0)/∂r_1 = h_0
             ▼
    ∂L/∂r_1 = (gradient from W_h) ⊙ h_0


Detailed Computation:
━━━━━━━━━━━━━━━━━━━━

First, compute gradient flowing back through W_h:

∂L/∂[r_1 ⊙ h_0, x_1] = W_h^T · ∂L/∂z_{h,1}

W_h^T (7×3) · ∂L/∂z_{h,1} (3×1):

Only first 3 components correspond to r_1 ⊙ h_0:

∂L/∂(r_1 ⊙ h_0) = W_h^T[0:3, :] · ∂L/∂z_{h,1}

For simplified calculation (using our example weights):

∂L/∂(r_1 ⊙ h_0) ≈ [-0.008]
                   [-0.006]
                   [ 0.018]

Now apply chain rule:
∂(r_1 ⊙ h_0)/∂r_1 = h_0 (element-wise derivative)

∂L/∂r_1 = ∂L/∂(r_1 ⊙ h_0) ⊙ h_0

        = [-0.008] ⊙ [0.124]   [-0.008 × 0.124]   [-0.001]
          [-0.006]   [0.089] = [-0.006 × 0.089] = [-0.001]
          [ 0.018]   [0.040]   [ 0.018 × 0.040]   [ 0.001]

Interpretation:
Reset gate gradients are relatively small because:
1. They're modulated by h_0 values (which are small: 0.04-0.12)
2. They're downstream from candidate gradients
3. At t=1, the influence of reset gate is indirect
```

**Gradient w.r.t. pre-activation**:

```
∂L/∂z_{r,1} = ∂L/∂r_1 ⊙ (r_1 ⊙ (1 - r_1))

r_1 = [0.586]     1 - r_1 = [0.414]
      [0.561]               [0.439]
      [0.613]               [0.387]

r_1 ⊙ (1 - r_1) = [0.243]
                  [0.246]
                  [0.237]

∂L/∂z_{r,1} = [-0.001] ⊙ [0.243]   [-0.000]
              [-0.001]   [0.246] = [-0.000]
              [ 0.001]   [0.237]   [ 0.000]

Very small gradients! This is normal - reset gate has indirect influence.
```

---

#### STEP 6: Backpropagation Through Time to t=0

**Visualization: Temporal Gradient Flow from t=1 to t=0**

```
═══════════════════════════════════════════════════════════════════════
STEP 6: Computing ∂L/∂h_0 (Gradient Flows Backward in Time)
═══════════════════════════════════════════════════════════════════════

This is THE KEY STEP where gradients flow backward through time!

At t=0, the hidden state h_0 influences future in THREE ways:

1. Direct path through update gate: z_1 ⊙ h_0
2. Indirect path through reset gate: r_1 ⊙ h_0 → h̃_1
3. Through the gates themselves: h_0 affects r_1 and z_1


Time t=1:                        Time t=0:
  
  ∂L/∂h_1 = [-0.051]
            [-0.050]
            [ 0.152]
                │
                │ From hidden state at t=1
                │
       ┌────────┴────────┐
       │                 │
       ▼                 ▼
   PATH 1:           PATH 2:
   Direct            Candidate
   (z_1 ⊙ h_0)      ((1-z_1) ⊙ h̃_1)
       │                 │
       │                 │ → ∂L/∂h̃_1
       │                 │
       │                 │ → ∂L/∂z_{h,1}
       │                 │
       │                 │ → through W_h
       │                 │
       │                 ▼
       │            ∂L/∂(r_1 ⊙ h_0)
       │                 │
       │                 │ ⊙ r_1
       │                 ▼
       └────────┬────────┘
                │
                ▼
          ∂L/∂h_0 (from future)


Mathematical Formulation:
━━━━━━━━━━━━━━━━━━━━━━━━━

∂L/∂h_0 has three components:

1. From direct path (z_1 ⊙ h_0):
   ∂L/∂h_0|_direct = ∂L/∂h_1 ⊙ z_1

2. From candidate path (via r_1 ⊙ h_0):
   ∂L/∂h_0|_candidate = ∂L/∂(r_1 ⊙ h_0) ⊙ r_1

3. From gates (r_1 and z_1 depend on h_0):
   ∂L/∂h_0|_gates = (via W_r and W_z) - typically computed together


Computation of Main Components:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Component 1: Direct path
∂L/∂h_0|_direct = ∂L/∂h_1 ⊙ z_1

                = [-0.051] ⊙ [0.564]   [-0.051 × 0.564]   [-0.029]
                  [-0.050]   [0.586] = [-0.050 × 0.586] = [-0.029]
                  [ 0.152]   [0.586]   [ 0.152 × 0.586]   [ 0.089]

This is the "gradient highway" - direct flow!


Component 2: Candidate path
∂L/∂h_0|_candidate = ∂L/∂(r_1 ⊙ h_0) ⊙ r_1

From Step 5: ∂L/∂(r_1 ⊙ h_0) ≈ [-0.008, -0.006, 0.018]

                   = [-0.008] ⊙ [0.586]   [-0.005]
                     [-0.006]   [0.561] = [-0.003]
                     [ 0.018]   [0.613]   [ 0.011]


Component 3: Through gates (simplified - via W_r^T and W_z^T)
This requires backpropagating through the gate computations.
For our example, this contribution is relatively small: ≈ [-0.002, -0.001, 0.003]


Total gradient from future:
∂L/∂h_0|_future = ∂L/∂h_0|_direct + ∂L/∂h_0|_candidate + ∂L/∂h_0|_gates

                ≈ [-0.029] + [-0.005] + [-0.002]   [-0.036]
                  [-0.029]   [-0.003]   [-0.001] = [-0.033]
                  [ 0.089]   [ 0.011]   [ 0.003]   [ 0.103]


Interpretation:
━━━━━━━━━━━━━━━

├─ The DIRECT path (z_1 ⊙ h_0) contributes MOST: [-0.029, -0.029, 0.089]
│  This is the "gradient highway" that prevents vanishing gradients!
│
├─ The CANDIDATE path contributes: [-0.005, -0.003, 0.011]
│  Smaller because it goes through more operations (tanh, etc.)
│
└─ The GATE path contributes: [-0.002, -0.001, 0.003]
   Smallest because gates use sigmoid (saturating function)

Key Insight: The direct path z_1 ⊙ h_0 is WHY GRU works well!
It provides a "highway" for gradients, similar to residual connections!


Visualization of Gradient Flow Strengths:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

h_1 at t=1
    │
    │ ∂L/∂h_1
    ▼
┌───────────────────┐
│ Total: [-0.051]   │
│        [-0.050]   │
│        [ 0.152]   │
└─────────┬─────────┘
          │
          │ Split into paths
          │
    ┌─────┴──────────────────┐
    │                        │
    ▼ 80-85% of gradient     ▼ 15-20% of gradient
┌─────────────┐        ┌──────────────┐
│ DIRECT PATH │        │ OTHER PATHS  │
│ (via z_1)   │        │ (via h̃_1,    │
│             │        │  gates)      │
│ [-0.029]    │        │ [-0.007]     │
│ [-0.029]    │        │ [-0.004]     │
│ [ 0.089]    │        │ [ 0.014]     │
└──────┬──────┘        └──────┬───────┘
       │                      │
       └──────────┬───────────┘
                  │
                  ▼
            ∂L/∂h_0 (from future)
            = [-0.036]
              [-0.033]
              [ 0.103]
                  │
                  │ This will be added to
                  │ direct loss gradient at t=0
                  ▼
```

---

#### STEP 7: Gradient Accumulation at t=0

**Visualization: Two Sources of Gradients at t=0**

```
═══════════════════════════════════════════════════════════════════════
STEP 7: Computing Total ∂L/∂h_0 (Both Local and Temporal Gradients)
═══════════════════════════════════════════════════════════════════════

At t=0, we have TWO sources of gradients (just like vanilla RNN):

1. LOCAL gradient: From its own output y_0 and loss L_0
2. TEMPORAL gradient: From future time step (computed in Step 6)


Source 1: Local (from L_0)        Source 2: Temporal (from future)
━━━━━━━━━━━━━━━━━━━━━━━━━━        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

        L_0                               L_1
         │                                 │
         ▼                                 ▼
        o_0                               h_1
         │                                 │
    ∂L_0/∂o_0                         ∂L/∂h_1
   = y_0 - ŷ_0                            │
   = [0.502] - [1]                        │ Through GRU structure
     [0.498]   [0]                        │ (3 paths as shown)
   = [-0.498]                             ▼
     [ 0.498]                      ∂L/∂h_0|_future
         │                         ≈ [-0.036]
         │ W_y^T                     [-0.033]
         ▼                           [ 0.103]
  ∂L_0/∂h_0                              │
  = W_y^T · ∂L_0/∂o_0                    │
         │                               │
         │                               │
         └───────────┬───────────────────┘
                     │
                     │ ADD THEM!
                     ▼
           ┌──────────────────────┐
           │  Total ∂L/∂h_0        │
           │  = ∂L_0/∂h_0 +        │
           │    ∂L/∂h_0|_future    │
           │                       │
           └──────────────────────┘


Computation:
━━━━━━━━━━━

Local gradient from output:
∂L_0/∂h_0 = W_y^T · (y_0 - ŷ_0)

W_y^T = [0.5  0.4]^T   [0.5  0.3  0.2]
        [0.3  0.2]   = [0.4  0.2  0.5]
        [0.2  0.5]

y_0 - ŷ_0 = [0.502 - 1.0]   [-0.498]
            [0.498 - 0.0] = [ 0.498]

∂L_0/∂h_0 = [0.5  0.3  0.2] · [-0.498]
            [0.4  0.2  0.5]   [ 0.498]

Row 0: 0.5×(-0.498) + 0.4×0.498 = -0.249 + 0.199 = -0.050
Row 1: 0.3×(-0.498) + 0.2×0.498 = -0.149 + 0.100 = -0.049
Row 2: 0.2×(-0.498) + 0.5×0.498 = -0.100 + 0.249 =  0.149

∂L_0/∂h_0 = [-0.050]
            [-0.049]
            [ 0.149]


Temporal gradient from future (from Step 6):
∂L/∂h_0|_future ≈ [-0.036]
                  [-0.033]
                  [ 0.103]


Total gradient:
∂L/∂h_0 = ∂L_0/∂h_0 + ∂L/∂h_0|_future

        = [-0.050]   [-0.036]   [-0.086]
          [-0.049] + [-0.033] = [-0.082]
          [ 0.149]   [ 0.103]   [ 0.252]


Analysis:
━━━━━━━━━

┌──────────────────────────────────────────────────────────────┐
│ Gradient Contribution Analysis at t=0                       │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│ Dimension 0:                                                 │
│   Local:    -0.050  (58%)  ← From output at t=0            │
│   Temporal: -0.036  (42%)  ← From future at t=1            │
│   Total:    -0.086         → h_0[0] should DECREASE         │
│                                                              │
│ Dimension 1:                                                 │
│   Local:    -0.049  (60%)  ← From output at t=0            │
│   Temporal: -0.033  (40%)  ← From future at t=1            │
│   Total:    -0.082         → h_0[1] should DECREASE         │
│                                                              │
│ Dimension 2:                                                 │
│   Local:     0.149  (59%)  ← From output at t=0            │
│   Temporal:  0.103  (41%)  ← From future at t=1            │
│   Total:     0.252         → h_0[2] should INCREASE strongly│
│                              (POSITIVE SENTIMENT!)           │
│                                                              │
│ Key Observations:                                            │
│ • Both sources agree on direction for all dimensions!       │
│ • Dimension 2 has STRONGEST positive gradient (0.252)      │
│ • Temporal gradients are significant (~40% of total)       │
│ • The GRU successfully propagated gradient from t=1 to t=0 │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

Now we can compute gradients for all gates and weights at t=0, following the same procedure as t=1.

---

### Why GRU Helps with Vanishing Gradients

**Mathematical Explanation**:

In a vanilla RNN:
$$h_t = \tanh(W_{hh} h_{t-1} + W_{xh} x_t + b_h)$$

Gradient flows as:
$$\frac{\partial L}{\partial h_{t-1}} = \frac{\partial L}{\partial h_t} \cdot W_{hh}^T \cdot \text{diag}(1 - h_t^2)$$

The $(1 - h_t^2)$ term (tanh derivative) is **always ≤ 1**, causing gradients to shrink exponentially over many time steps.

---

In a GRU:
$$h_t = z_t \odot h_{t-1} + (1 - z_t) \odot \tilde{h}_t$$

Gradient flows as:
$$\frac{\partial L}{\partial h_{t-1}} = \frac{\partial L}{\partial h_t} \odot z_t + \text{(gradients through candidate)}$$

**Key difference**: The direct path $z_t \odot h_{t-1}$ has **NO nonlinearity**! The gradient $\frac{\partial L}{\partial h_t} \odot z_t$ flows with only element-wise multiplication by $z_t \in [0, 1]$.

```
╔════════════════════════════════════════════════════════════════╗
║          Why GRU Mitigates Vanishing Gradients                ║
╠════════════════════════════════════════════════════════════════╣
║                                                                ║
║ VANILLA RNN GRADIENT:                                          ║
║ ─────────────────────                                          ║
║                                                                ║
║ ∂L/∂h_0 ← ∂L/∂h_1 · W_hh^T · (1-h_1²)                        ║
║           └────┬────┘         └───┬───┘                       ║
║              matrix          ALWAYS ≤ 1                        ║
║                                                                ║
║ Over T steps: ∂L/∂h_0 ∝ ∏(1-h_t²) · (W_hh^T)^T              ║
║                          └────┬────┘                           ║
║                         Shrinks exponentially!                 ║
║                                                                ║
║                                                                ║
║ GRU GRADIENT (DIRECT PATH):                                    ║
║ ───────────────────────────                                    ║
║                                                                ║
║ ∂L/∂h_0 ← ∂L/∂h_1 ⊙ z_1   (main contribution)                ║
║           └────┬────┘  └┬┘                                     ║
║             gradient   gate value                              ║
║                                                                ║
║ NO matrix multiplication!                                      ║
║ NO saturating nonlinearity!                                    ║
║ Just element-wise scaling!                                     ║
║                                                                ║
║ Over T steps: ∂L/∂h_0 ≈ ∂L/∂h_T ⊙ (∏ z_t)                    ║
║                                    └──┬──┘                     ║
║                              Learned values!                   ║
║                              Network can keep high!            ║
║                                                                ║
║                                                                ║
║ KEY INSIGHT:                                                   ║
║ ───────────                                                    ║
║ The update gate z_t can learn to stay close to 1.0,           ║
║ creating a "gradient highway" where gradients flow             ║
║ almost unimpeded over many time steps!                         ║
║                                                                ║
║ This is similar to:                                            ║
║ • Residual connections in ResNet                              ║
║ • Skip connections in general                                  ║
║ • LSTM's cell state pathway                                    ║
║                                                                ║
╚════════════════════════════════════════════════════════════════╝
```

**Numerical Example**:

```
Vanilla RNN over 100 time steps:
If (1 - h_t²) ≈ 0.75 on average (tanh is often saturated)
Gradient scaling: (0.75)^100 ≈ 3.2 × 10^-13  (VANISHED!)

GRU over 100 time steps:
If z_t ≈ 0.9 on average (network learns to keep memory)
Gradient scaling: (0.9)^100 ≈ 0.000027  (small but not vanished!)

If z_t ≈ 0.98 (even higher memory retention)
Gradient scaling: (0.98)^100 ≈ 0.133  (substantial gradient flow!)
```

---

### Weight Updates

After accumulating gradients from both time steps, we update weights using gradient descent.

**Update formula**:
$$W_{\text{new}} = W_{\text{old}} - \alpha \cdot \frac{\partial L}{\partial W}$$

**Example update for $W_y$** (output weights):

```
Accumulated gradient:
∂L/∂W_y = ∂L_0/∂W_y + ∂L_1/∂W_y

From t=0: ∂L_0/∂W_y ≈ [-0.062  -0.044  -0.020]
                       [ 0.062   0.044   0.020]

From t=1: ∂L_1/∂W_y = [-0.089  -0.055  -0.098]
                       [ 0.089   0.055   0.098]

Total: ∂L/∂W_y = [-0.151  -0.099  -0.118]
                  [ 0.151   0.099   0.118]

Learning rate: α = 0.01

Update:
W_y_new = W_y_old - α · ∂L/∂W_y

W_y_old = [0.5  0.3  0.2]
          [0.4  0.2  0.5]

W_y_new = [0.5  0.3  0.2]   [0.00151  0.00099  0.00118]
          [0.4  0.2  0.5] - [-0.00151 -0.00099 -0.00118]

        = [0.5  0.3  0.2]   [-0.00151 -0.00099 -0.00118]
          [0.4  0.2  0.5] + [ 0.00151  0.00099  0.00118]

        = [0.49849  0.29901  0.19882]
          [0.40151  0.20099  0.50118]
```

Similarly, update gates weights ($W_r$, $W_z$, $W_h$) are updated by accumulating gradients from all time steps.

---

### BPTT Summary for GRU

```
╔════════════════════════════════════════════════════════════════╗
║              GRU BACKPROPAGATION ALGORITHM                     ║
╠════════════════════════════════════════════════════════════════╣
║                                                                ║
║ FORWARD PASS: (Store all intermediate values)                 ║
║   For t = 0 to T-1:                                            ║
║     Store: r_t, z_t, h̃_t, h_t, y_t                             ║
║                                                                ║
║ BACKWARD PASS: (From t=T-1 to t=0)                             ║
║                                                                ║
║   Initialize: ∂L/∂h_T = 0  (no future)                         ║
║                                                                ║
║   For t = T-1 down to 0:                                       ║
║                                                                ║
║     Step 1: Output layer gradients                            ║
║       ∂L_t/∂o_t = y_t - ŷ_t                                    ║
║       ∂L_t/∂W_y += ∂L_t/∂o_t · h_t^T                           ║
║       ∂L_t/∂b_y += ∂L_t/∂o_t                                   ║
║                                                                ║
║     Step 2: Hidden state gradient (direct from output)        ║
║       ∂L_t/∂h_t = W_y^T · ∂L_t/∂o_t                            ║
║                                                                ║
║     Step 3: Add gradient from future                           ║
║       ∂L/∂h_t += ∂L/∂h_{t+1}|_future  (computed in Step 6)    ║
║                                                                ║
║     Step 4: Update gate gradients                              ║
║       ∂L/∂z_t = ∂L/∂h_t ⊙ (h_{t-1} - h̃_t)                     ║
║       ∂L/∂z_{z,t} = ∂L/∂z_t ⊙ z_t ⊙ (1 - z_t)                 ║
║       ∂L/∂W_z += ∂L/∂z_{z,t} · [h_{t-1}, x_t]^T              ║
║                                                                ║
║     Step 5: Candidate hidden state gradients                   ║
║       ∂L/∂h̃_t = ∂L/∂h_t ⊙ (1 - z_t)                           ║
║       ∂L/∂z_{h,t} = ∂L/∂h̃_t ⊙ (1 - h̃_t²)                      ║
║       ∂L/∂W_h += ∂L/∂z_{h,t} · [r_t⊙h_{t-1}, x_t]^T          ║
║                                                                ║
║     Step 6: Reset gate gradients                               ║
║       ∂L/∂(r_t⊙h_{t-1}) = W_h^T[0:n_h,:] · ∂L/∂z_{h,t}       ║
║       ∂L/∂r_t = ∂L/∂(r_t⊙h_{t-1}) ⊙ h_{t-1}                  ║
║       ∂L/∂z_{r,t} = ∂L/∂r_t ⊙ r_t ⊙ (1 - r_t)                ║
║       ∂L/∂W_r += ∂L/∂z_{r,t} · [h_{t-1}, x_t]^T              ║
║                                                                ║
║     Step 7: Gradient to previous hidden state (for next iter) ║
║       ∂L/∂h_{t-1} = ∂L/∂h_t ⊙ z_t  (direct path)              ║
║                   + ∂L/∂(r_t⊙h_{t-1}) ⊙ r_t  (candidate path) ║
║                   + [gradients through gates]  (gate path)    ║
║                                                                ║
║ WEIGHT UPDATES:                                                ║
║   W_y  := W_y  - α·∂L/∂W_y                                    ║
║   W_z  := W_z  - α·∂L/∂W_z                                    ║
║   W_h  := W_h  - α·∂L/∂W_h                                    ║
║   W_r  := W_r  - α·∂L/∂W_r                                    ║
║   (+ corresponding biases)                                     ║
║                                                                ║
╚════════════════════════════════════════════════════════════════╝
```
