{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "convolutional_neural_network.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# What is a Convolutional Neural Network (CNN)?\n\nA network that learns **spatial features** by sliding filters (kernels) over inputs (images, sequences), capturing local patterns (edges → textures → parts → objects).\nRule of thumb: “Convolve → activate → pool (repeat), then classify.”\n\nThink image recognition: early filters detect edges; deeper filters detect parts and objects.\n\n---\n\n# Variables and notation\n\n- Input image: $$X \\in \\mathbb{R}^{H\\times W\\times C}$$ (height, width, channels)\n- Convolution kernel: $$K \\in \\mathbb{R}^{k\\times k\\times C}$$, number of filters $$F$$\n- Stride $$s$$, padding $$p$$\n- Output feature map (same padding): height $$H' = \\lceil H/s \\rceil$$, width $$W' = \\lceil W/s \\rceil$$, channels $$F$$\n\nConvolution at location $$(i,j)$$: $$Y[i,j,f] = \\sum_{u,v,c} K_f[u,v,c] \\cdot X[i+u, j+v, c] + b_f$$\n\n---\n\n# Typical block\n\n1) Conv2D(filters=F, kernel_size=k)  \n2) Activation (ReLU)  \n3) (BatchNorm)  \n4) Pooling (MaxPool2D) to downsample  \nRepeat ×N → Flatten/GlobalAveragePool → Dense → Softmax\n\nData augmentation (random flips/crops/rotations) helps regularization by increasing variation.\n\n---\n\n# Output size formula (valid padding)\n\n$$\nH' = \\left\\lfloor \\frac{H - k + 2p}{s} \\right\\rfloor + 1, \\quad\nW' = \\left\\lfloor \\frac{W - k + 2p}{s} \\right\\rfloor + 1\n$$\n\nFor “same” padding with $$s=1$$: $$H'=H, W'=W$$.\n\n---\n\n# Step‑by‑step tiny example\n\n5×5 grayscale patch, 3×3 edge detector kernel:\n- Slide kernel over 3×3 windows; multiply‑sum → highlights edges.\n- Max pooling 2×2 halves both H and W → invariance to small shifts.\n\n---\n\n# Pseudocode\n\n```\nx = input_image\nfor block in conv_blocks:\n  x = conv2d(x, filters=F, k=k, stride=s, padding=p)\n  x = relu(x)\n  if use_bn: x = batch_norm(x)\n  x = max_pool(x, size=2)\nx = flatten(x) or global_avg_pool(x)\nlogits = dense(x, units=C)\ny_hat = softmax(logits)\nloss = cross_entropy(y_hat, y)\nopt.step(backprop(loss))\n```\n\n---\n\n# Minimal Python (ready to paste – Keras)\n\n```python\nfrom tensorflow.keras import layers as L, models, optimizers, callbacks\n\nmodel = models.Sequential([\n    L.Input(shape=(H, W, C)),\n    L.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\"),\n    L.MaxPool2D((2,2)),\n    L.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n    L.MaxPool2D((2,2)),\n    L.Flatten(),\n    L.Dense(128, activation=\"relu\"),\n    L.Dropout(0.3),\n    L.Dense(C, activation=\"softmax\"),\n])\n\nmodel.compile(optimizer=optimizers.Adam(1e-3),\n              loss=\"sparse_categorical_crossentropy\",\n              metrics=[\"accuracy\"])\n\nes = callbacks.EarlyStopping(patience=8, restore_best_weights=True)\nmodel.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[es])\n```\n\n---\n\n# Practical tips, pitfalls, and variants\n\n- Normalize inputs (per‑channel mean/std); verify channel order (NHWC).\n- Start small; confirm model can overfit a tiny subset.\n- Use augmentation (flip/crop/rotate/color jitter) and dropout.\n- Watch LR schedules; too high → divergence, too low → slow.\n- Memory: tune batch size and feature maps; consider depthwise separable convs.\n- Variants: ResNet (residual connections), DenseNet, MobileNet.\n\n---\n\n# How this notebook implements it\n\n- Dataset: images loaded via Keras generators or folders.\n- Steps: conv‑blocks → dense → compile (Adam + cross‑entropy) → train with augmentation → evaluate.\n- Tip: visualize filters and feature maps to debug.\n\n---\n\n# Quick cheat sheet\n\n- [Conv→ReLU→(BN)→Pool] ×2–3 → Dense → Softmax\n- Normalize inputs; use augmentation\n- Early stopping; tune LR and batch size\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DR-eO17geWu",
    "colab_type": "text"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMefrVPCg-60",
    "colab_type": "text"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sCV30xyVhFbE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FIleuCAjoFD8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tf.__version__"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxQxCBWyoGPE",
    "colab_type": "text"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE-heJNo3GG",
    "colab_type": "text"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0koUcJMJpEBD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCMmGw9pHys",
    "colab_type": "text"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SH4WzfOhpKc3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8O4l90gk7B",
    "colab_type": "text"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ces1gXY2lmoX",
    "colab_type": "text"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SAUt4UMPlhLS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5YJj_XMl5LF",
    "colab_type": "text"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XPzPrMckl-hV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf87FpvxmNOJ",
    "colab_type": "text"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ncpqPl69mOac",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaTOgD8rm4mU",
    "colab_type": "text"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i_-FZjn_m8gk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmiEuvTunKfk",
    "colab_type": "text"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6AZeOGCvnNZn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAoSECOm203v",
    "colab_type": "text"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8GtmUlLd26Nq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTldFvbX28Na",
    "colab_type": "text"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1p_Zj1Mc3Ko_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6XkI90snSDl",
    "colab_type": "text"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfrFQACEnc6i",
    "colab_type": "text"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NALksrNQpUlJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehS-v3MIpX2h",
    "colab_type": "text"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XUj1W4PJptta",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z",
    "colab_type": "text"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gsSiWEJY1BPB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ED9KB3I54c1i",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(prediction)"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}
