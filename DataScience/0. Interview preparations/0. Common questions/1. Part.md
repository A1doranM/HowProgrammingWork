## Что такое линейная регрессия?

Линейная регрессия это метод машинного обучения для предсказания некоторого бесконечного набора чисел, он сводится к тому чтобы для выбранных признаков выставить определенные значения весов. 

$$y = \beta_0 + \beta_1x + \epsilon$$

Where:
- $y$ = dependent variable (target)
- $x$ = independent variable (feature)
- $\beta_0$ = intercept (bias term)
- $\beta_1$ = slope (coefficient)
- $\epsilon$ = error term


Основные подходы для обучения линейной регрессии это аналитический и градиентный спуск: 

### В аналитическом подходе мы решаем уравнение 

$$\mathbf{\hat{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$$

Where:
- $\mathbf{\hat{\beta}}$ = vector of estimated coefficients $[\beta_0, \beta_1, ..., \beta_n]^T$
- $\mathbf{X}$ = design matrix (n × (p+1)) with intercept column
- $\mathbf{y}$ = vector of target values (n × 1)
- $\mathbf{X}^T$ = transpose of X
- $(\mathbf{X}^T\mathbf{X})^{-1}$ = inverse of $\mathbf{X}^T\mathbf{X}$

#### Advantages of Analytical Solution

✅ **Exact solution** - No approximation or iteration needed  
✅ **Fast for small datasets** - One-step calculation  
✅ **No hyperparameters** - No learning rate to tune  
✅ **Guaranteed convergence** - Always finds the optimal solution  

#### Disadvantages

❌ **Computational cost** - Expensive for large feature sets (matrix inversion is $O(p^3)$)  
❌ **Memory intensive** - Requires storing $\mathbf{X}^T\mathbf{X}$ matrix  
❌ **Numerical stability** - Can fail if $\mathbf{X}^T\mathbf{X}$ is singular or near-singular  
❌ **Not scalable** - Poor performance with millions of features  

#### When to Use

- **Use Analytical Solution when:**
  - Number of features $p < 10,000$
  - Need exact solution
  - Dataset fits in memory
  - $\mathbf{X}^T\mathbf{X}$ is well-conditioned

### Второй метод это использование градиентного спуска 

При этом методе мы решаем задачу минимизации некоторой функции потерь. Тоесть мы случайно инициализируем веса, делаем прогноз, считаем функцию ошибки, берем градиент от функции потерь и делаем шаг в сторону его уменьшения. 

Initialize β randomly or to zeros Set learning rate α (e.g., 0.01) Set number of iterations (e.g., 1000)

For each iteration: 
1. Compute predictions: ŷ = Xβ 
2. Compute error: error = ŷ - y 
3. Compute cost: J(β) = (1/2m) × sum(error²) 
4. Compute gradient: ∇J(β) = (1/m) × Xᵀ × error 
5. Update parameters: β := β - α × ∇J(β) 
6. Check convergence (if |J_new - J_old| < threshold, stop)


#### Gradient Descent Update Rules

$$\beta_0 := \beta_0 - \alpha\frac{1}{n}\sum_{i=1}^{n}(\hat{y}_i - y_i)$$

$$\beta_1 := \beta_1 - \alpha\frac{1}{n}\sum_{i=1}^{n}(\hat{y}_i - y_i)x_i$$

Where $\alpha$ is the learning rate.

Самой базовой функцией счиатется MSE (Mean Square Error):

#### Standard Form
$$J(\beta) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)})^2$$

Or equivalently:
$$J(\beta_0, \beta_1, ..., \beta_n) = \frac{1}{2m}\sum_{i=1}^{m}(\hat{y}^{(i)} - y^{(i)})^2$$

Where:
- $J(\beta)$ = cost function
- $m$ = number of training examples
- $h_{\beta}(x^{(i)})$ or $\hat{y}^{(i)}$ = predicted value for example $i$
- $y^{(i)}$ = actual value for example $i$
- $\frac{1}{2}$ = constant for mathematical convenience (cancels during derivative)

## Что такое регуляризация?

Регуляризация используется для передотвращения переобучения в моделях базовые регуляризации это L1 и L2: 

## L2 Regularization (Ridge Regression)

#### Properties
- **Shrinks** coefficients towards zero (but not exactly zero)
- **Reduces model complexity** by penalizing large coefficients
- **Handles multicollinearity** by making $\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I}$ invertible
- **Differentiable** everywhere (smooth optimization)
- **Feature selection:** Does NOT perform feature selection (keeps all features)


#### Cost Function
$$J(\beta) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)})^2 + \frac{\lambda}{2m}\sum_{j=1}^{n}\beta_j^2$$

Or in compact notation:
$$J(\beta) = MSE + \frac{\lambda}{2m}||\beta||_2^2$$

Where:
- $\lambda$ = regularization parameter (hyperparameter, $\lambda \geq 0$)
- $||\beta||_2^2 = \sum_{j=1}^{n}\beta_j^2$ = squared L2 norm
- Note: $\beta_0$ (intercept) is typically **not** regularized

#### Matrix Form
$$J(\beta) = \frac{1}{2m}(\mathbf{X\beta} - \mathbf{y})^T(\mathbf{X\beta} - \mathbf{y}) + \frac{\lambda}{2m}\mathbf{\beta}^T\mathbf{\beta}$$

#### Gradient for Gradient Descent
$$\frac{\partial J(\beta)}{\partial \beta_j} = \frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} + \frac{\lambda}{m}\beta_j$$

#### Vectorized Gradient
$$\nabla J(\beta) = \frac{1}{m}\mathbf{X}^T(\mathbf{X\beta} - \mathbf{y}) + \frac{\lambda}{m}\mathbf{\beta}$$

#### Update Rule (Gradient Descent)
$$\beta_j := \beta_j - \alpha\left[\frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} + \frac{\lambda}{m}\beta_j\right]$$

Which can be rewritten as:
$$\beta_j := \beta_j\left(1 - \alpha\frac{\lambda}{m}\right) - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)}$$

#### Analytical Solution (Normal Equation)
$$\mathbf{\hat{\beta}} = (\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf{y}$$

Where $\mathbf{I}$ is the identity matrix.

## L1 Regularization (Lasso Regression)

### Properties
- **Shrinks** some coefficients **exactly to zero** (sparse solutions)
- **Performs automatic feature selection**
- **Not differentiable** at zero (requires subgradient methods)
- **No closed-form solution** (must use iterative methods)
- Useful when you have many features and want to identify the most important ones

### Cost Function
$$J(\beta) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)})^2 + \frac{\lambda}{m}\sum_{j=1}^{n}|\beta_j|$$

Or in compact notation:
$$J(\beta) = MSE + \frac{\lambda}{m}||\beta||_1$$

Where:
- $\lambda$ = regularization parameter (hyperparameter, $\lambda \geq 0$)
- $||\beta||_1 = \sum_{j=1}^{n}|\beta_j|$ = L1 norm (Manhattan distance)
- Note: $\beta_0$ (intercept) is typically **not** regularized

### Matrix Form
$$J(\beta) = \frac{1}{2m}(\mathbf{X\beta} - \mathbf{y})^T(\mathbf{X\beta} - \mathbf{y}) + \frac{\lambda}{m}\sum_{j=1}^{n}|\beta_j|$$

### Subgradient for Gradient Descent
$$\frac{\partial J(\beta)}{\partial \beta_j} = \frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} + \frac{\lambda}{m} \cdot \text{sign}(\beta_j)$$

Where:
$$\text{sign}(\beta_j) = \begin{cases}
+1 & \text{if } \beta_j > 0 \\
0 & \text{if } \beta_j = 0 \\
-1 & \text{if } \beta_j < 0
\end{cases}$$

### Update Rule (Gradient Descent)
$$\beta_j := \beta_j - \alpha\left[\frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} + \frac{\lambda}{m} \cdot \text{sign}(\beta_j)\right]$$


## Что такое переобучение и как его избегать?

Чтобы избежать переобучения следует использовать регуляризацию, следить за сложностью модели и количеством признаков, полезно отобрать только самые значимые их них, а так же использовать кросс валидацию когда мы разбиваем датасет на несколько частей например на 5 на слотах с первого по 4 обучаемся, на 5 тестируемся, во второй итерации со второго по 5 обучемся на 1 тестируемся и т.д. пока не прогоним все варианты обучения.

### Если в данных есть TimeSeries как в таком случае проводится кросс валидация? 

### Кросс-валидация для временных рядов (Time Series Cross-Validation)

#### Проблема с обычной кросс-валидацией

❌ **Нельзя использовать обычную k-fold CV**, потому что:
- Нарушается временной порядок данных
- Модель "заглядывает в будущее" (data leakage)
- Случайное перемешивание разрушает временные зависимости
- Автокорреляция игнорируется

##### 1. Expanding Window

##### Принцип
Модель всегда обучается на **прошлых** данных и тестируется на **будущих**. Обучающая выборка постоянно __растёт__, включая все прошлые данные.


##### Визуализация

```javascript
Fold 1: [Train] [Test] 
Fold 2: [Train---] [Test] 
Fold 3: [Train------] [Test] 
Fold 4: [Train---------] [Test] 
Fold 5: [Train------------] [Test]
```

##### Когда использовать

- По умолчанию для большинства задач
- Когда все исторические данные полезны
- Для долгосрочного прогнозирования


### 2. Sliding Window (Скользящее окно)

#### Принцип

Обучающее окно имеет __фиксированный размер__ и "скользит" вперёд.

#### Визуализация

```javascript
Fold 1: [Train====] [Test]
Fold 2:    [Train====] [Test]
Fold 3:       [Train====] [Test]
Fold 4:          [Train====] [Test]
Fold 5:             [Train====] [Test]
```

### Формальное описание

__Фолд $i$:__

- __Train set:__ ${t_{i \cdot step}, ..., t_{i \cdot step + window_size}}$
- __Test set:__ ${t_{i \cdot step + window_size + 1}, ..., t_{i \cdot step + window_size + test_size}}$

### Когда использовать

- Когда старые данные становятся неактуальными
- При наличии concept drift
- Для моделей с ограниченной памятью
- Когда вычислительные ресурсы ограничены

### Важные принципы в работе с временными данными

### ✅ Что нужно делать:

1. __Сохранять временной порядок__ — никогда не перемешивать
2. __Обучать только на прошлом__ — тестировать на будущем
3. __Учитывать gap__ — если есть задержка в получении данных
4. __Проверять на разных периодах__ — для оценки стабильности
5. __Использовать достаточно данных__ — минимум 3-5 фолдов

### ❌ Что нельзя делать:

1. Использовать `KFold` или `StratifiedKFold`
2. Перемешивать данные перед split
3. Использовать будущие данные для обучения
4. Игнорировать сезонность
5. Делать feature engineering с использованием будущих данных


## Как можно обнаружить переобучение без использования метрик?

## Что такое асимметричные метрики?

## Что такое логистическая регрессия?

## Что такое отступ логистической регрессии?

## Какие бывают метрики классификации?

## Что такое ROC-AUC и PR-AUC? Какие плюсы и минусы?

## Когда важен Precision, а когда Recall? Практические примеры

## Какие методы существуют для многоклассовой классификации?

## Какое количество моделей при All-vs-All?

## Что такое макро-микро метрики?

## Считаем Precision, Recall, ROC-AUC ручками!

## Объясняю подсчёт ROC-AUC

## Проблемы построенной кривой ROC-AUC
