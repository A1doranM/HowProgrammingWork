## Что такое линейная регрессия?

Линейная регрессия это метод машинного обучения для предсказания некоторого бесконечного набора чисел, он сводится к тому чтобы для выбранных признаков выставить определенные значения весов. 

$$y = \beta_0 + \beta_1x + \epsilon$$

Where:
- $y$ = dependent variable (target)
- $x$ = independent variable (feature)
- $\beta_0$ = intercept (bias term)
- $\beta_1$ = slope (coefficient)
- $\epsilon$ = error term


Основные подходы для обучения линейной регрессии это аналитический и градиентный спуск: 

### В аналитическом подходе мы решаем уравнение 

$$\mathbf{\hat{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$$

Where:
- $\mathbf{\hat{\beta}}$ = vector of estimated coefficients $[\beta_0, \beta_1, ..., \beta_n]^T$
- $\mathbf{X}$ = design matrix (n × (p+1)) with intercept column
- $\mathbf{y}$ = vector of target values (n × 1)
- $\mathbf{X}^T$ = transpose of X
- $(\mathbf{X}^T\mathbf{X})^{-1}$ = inverse of $\mathbf{X}^T\mathbf{X}$

#### Advantages of Analytical Solution

✅ **Exact solution** - No approximation or iteration needed  
✅ **Fast for small datasets** - One-step calculation  
✅ **No hyperparameters** - No learning rate to tune  
✅ **Guaranteed convergence** - Always finds the optimal solution  

#### Disadvantages

❌ **Computational cost** - Expensive for large feature sets (matrix inversion is $O(p^3)$)  
❌ **Memory intensive** - Requires storing $\mathbf{X}^T\mathbf{X}$ matrix  
❌ **Numerical stability** - Can fail if $\mathbf{X}^T\mathbf{X}$ is singular or near-singular  
❌ **Not scalable** - Poor performance with millions of features  

#### When to Use

- **Use Analytical Solution when:**
  - Number of features $p < 10,000$
  - Need exact solution
  - Dataset fits in memory
  - $\mathbf{X}^T\mathbf{X}$ is well-conditioned

### Второй метод это использование градиентного спуска 

При этом методе мы решаем задачу минимизации некоторой функции потерь. Тоесть мы случайно инициализируем веса, делаем прогноз, считаем функцию ошибки, берем градиент от функции потерь и делаем шаг в сторону его уменьшения. 

Initialize β randomly or to zeros Set learning rate α (e.g., 0.01) Set number of iterations (e.g., 1000)

For each iteration: 
1. Compute predictions: ŷ = Xβ 
2. Compute error: error = ŷ - y 
3. Compute cost: J(β) = (1/2m) × sum(error²) 
4. Compute gradient: ∇J(β) = (1/m) × Xᵀ × error 
5. Update parameters: β := β - α × ∇J(β) 
6. Check convergence (if |J_new - J_old| < threshold, stop)


#### Gradient Descent Update Rules

$$\beta_0 := \beta_0 - \alpha\frac{1}{n}\sum_{i=1}^{n}(\hat{y}_i - y_i)$$

$$\beta_1 := \beta_1 - \alpha\frac{1}{n}\sum_{i=1}^{n}(\hat{y}_i - y_i)x_i$$

Where $\alpha$ is the learning rate.

Самой базовой функцией счиатется MSE (Mean Square Error):

#### Standard Form
$$J(\beta) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)})^2$$

Or equivalently:
$$J(\beta_0, \beta_1, ..., \beta_n) = \frac{1}{2m}\sum_{i=1}^{m}(\hat{y}^{(i)} - y^{(i)})^2$$

Where:
- $J(\beta)$ = cost function
- $m$ = number of training examples
- $h_{\beta}(x^{(i)})$ or $\hat{y}^{(i)}$ = predicted value for example $i$
- $y^{(i)}$ = actual value for example $i$
- $\frac{1}{2}$ = constant for mathematical convenience (cancels during derivative)

## Что такое регуляризация?

Регуляризация используется для передотвращения переобучения в моделях базовые регуляризации это L1 и L2: 

## L2 Regularization (Ridge Regression)

#### Properties
- **Shrinks** coefficients towards zero (but not exactly zero)
- **Reduces model complexity** by penalizing large coefficients
- **Handles multicollinearity** by making $\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I}$ invertible
- **Differentiable** everywhere (smooth optimization)
- **Feature selection:** Does NOT perform feature selection (keeps all features)


#### Cost Function
$$J(\beta) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)})^2 + \frac{\lambda}{2m}\sum_{j=1}^{n}\beta_j^2$$

Or in compact notation:
$$J(\beta) = MSE + \frac{\lambda}{2m}||\beta||_2^2$$

Where:
- $\lambda$ = regularization parameter (hyperparameter, $\lambda \geq 0$)
- $||\beta||_2^2 = \sum_{j=1}^{n}\beta_j^2$ = squared L2 norm
- Note: $\beta_0$ (intercept) is typically **not** regularized

#### Matrix Form
$$J(\beta) = \frac{1}{2m}(\mathbf{X\beta} - \mathbf{y})^T(\mathbf{X\beta} - \mathbf{y}) + \frac{\lambda}{2m}\mathbf{\beta}^T\mathbf{\beta}$$

#### Gradient for Gradient Descent
$$\frac{\partial J(\beta)}{\partial \beta_j} = \frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} + \frac{\lambda}{m}\beta_j$$

#### Vectorized Gradient
$$\nabla J(\beta) = \frac{1}{m}\mathbf{X}^T(\mathbf{X\beta} - \mathbf{y}) + \frac{\lambda}{m}\mathbf{\beta}$$

#### Update Rule (Gradient Descent)
$$\beta_j := \beta_j - \alpha\left[\frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} + \frac{\lambda}{m}\beta_j\right]$$

Which can be rewritten as:
$$\beta_j := \beta_j\left(1 - \alpha\frac{\lambda}{m}\right) - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)}$$

#### Analytical Solution (Normal Equation)
$$\mathbf{\hat{\beta}} = (\mathbf{X}^T\mathbf{X} + \lambda\mathbf{I})^{-1}\mathbf{X}^T\mathbf{y}$$

Where $\mathbf{I}$ is the identity matrix.

## L1 Regularization (Lasso Regression)

### Properties
- **Shrinks** some coefficients **exactly to zero** (sparse solutions)
- **Performs automatic feature selection**
- **Not differentiable** at zero (requires subgradient methods)
- **No closed-form solution** (must use iterative methods)
- Useful when you have many features and want to identify the most important ones

### Cost Function
$$J(\beta) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)})^2 + \frac{\lambda}{m}\sum_{j=1}^{n}|\beta_j|$$

Or in compact notation:
$$J(\beta) = MSE + \frac{\lambda}{m}||\beta||_1$$

Where:
- $\lambda$ = regularization parameter (hyperparameter, $\lambda \geq 0$)
- $||\beta||_1 = \sum_{j=1}^{n}|\beta_j|$ = L1 norm (Manhattan distance)
- Note: $\beta_0$ (intercept) is typically **not** regularized

### Matrix Form
$$J(\beta) = \frac{1}{2m}(\mathbf{X\beta} - \mathbf{y})^T(\mathbf{X\beta} - \mathbf{y}) + \frac{\lambda}{m}\sum_{j=1}^{n}|\beta_j|$$

### Subgradient for Gradient Descent
$$\frac{\partial J(\beta)}{\partial \beta_j} = \frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} + \frac{\lambda}{m} \cdot \text{sign}(\beta_j)$$

Where:
$$\text{sign}(\beta_j) = \begin{cases}
+1 & \text{if } \beta_j > 0 \\
0 & \text{if } \beta_j = 0 \\
-1 & \text{if } \beta_j < 0
\end{cases}$$

### Update Rule (Gradient Descent)
$$\beta_j := \beta_j - \alpha\left[\frac{1}{m}\sum_{i=1}^{m}(h_{\beta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} + \frac{\lambda}{m} \cdot \text{sign}(\beta_j)\right]$$


## Что такое переобучение?

## Как можно обнаружить переобучение без использования метрик?

## Что такое асимметричные метрики?

## Что такое логистическая регрессия?

## Что такое отступ логистической регрессии?

## Какие бывают метрики классификации?

## Что такое ROC-AUC и PR-AUC? Какие плюсы и минусы?

## Когда важен Precision, а когда Recall? Практические примеры

## Какие методы существуют для многоклассовой классификации?

## Какое количество моделей при All-vs-All?

## Что такое макро-микро метрики?

## Считаем Precision, Recall, ROC-AUC ручками!

## Объясняю подсчёт ROC-AUC

## Проблемы построенной кривой ROC-AUC
