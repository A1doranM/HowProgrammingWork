{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9fe1e65",
   "metadata": {},
   "source": [
    "# Content   \n",
    "\n",
    "[Confidence Intervals and Margin of Error]()\n",
    "\n",
    "[Confidence Interval Simulation and Interpreting the Confidence *Level*]()\n",
    "\n",
    "[Conditions for a Valid Confidence Interval for a Proportion]()\n",
    "\n",
    "[Critical Value (z*) for a Given Confidence Level]()\n",
    "\n",
    "[Constructing and Interpreting a Confidence Interval for `p`]()\n",
    "\n",
    "[Determining Sample Size]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414663e",
   "metadata": {},
   "source": [
    "### Confidence Intervals and Margin of Error\n",
    "\n",
    "#### Theory\n",
    "A **point estimate** (like a sample proportion, `p̂`) is our single best guess for the true value of a population parameter (like `p`). However, this guess is almost certainly wrong due to random sampling variability.\n",
    "\n",
    "A **confidence interval** addresses this by providing a range of plausible values for the true parameter. Instead of a single point, we give an interval that we believe contains the true value.\n",
    "\n",
    "The general structure of a confidence interval is:\n",
    "**Point Estimate ± Margin of Error**\n",
    "\n",
    "The **Margin of Error (ME)** tells us how much we expect our sample statistic (`p̂`) to vary from the true parameter (`p`) due to random chance, for a given level of confidence. It represents the \"plus or minus\" part that creates the width of the interval. A smaller margin of error means a more precise estimate.\n",
    "\n",
    "**Analogy:** Imagine trying to catch a fish (`p`, the true parameter) in a lake with a small net (`p̂`, your sample). You might miss. A confidence interval is like using a much larger net. You don't know exactly where the fish is inside the net, but you're much more confident that you've caught it. The margin of error is like the radius of your big net.\n",
    "\n",
    "---\n",
    "\n",
    "### Confidence Interval Simulation and Interpreting the Confidence *Level*\n",
    "\n",
    "This is one of the most misunderstood concepts in statistics.\n",
    "\n",
    "#### Theory\n",
    "The **confidence level** (e.g., 95%) does **not** tell us the probability that our *one* calculated interval contains the true parameter. The true parameter `p` is a fixed number; it's either in our interval or it's not. The probability is either 1 or 0.\n",
    "\n",
    "Instead, the **confidence level refers to the long-run success rate of the method**.\n",
    "\n",
    "**Simulation Idea:**\n",
    "Imagine 100 different researchers all go out and collect their own random samples from the same population. They each compute their own 95% confidence interval based on their sample data. Because of sampling variability, their intervals will all be slightly different.\n",
    "\n",
    "A 95% confidence level means that we expect about **95 of those 100 intervals** to successfully capture the true population parameter. The other 5 intervals will miss the true parameter entirely, just due to bad luck in their random sample.\n",
    "\n",
    "**Correct Interpretation of a 95% Confidence Level:**\n",
    "*   \"I am 95% confident that the *method* I used to construct this interval has captured the true population proportion.\"\n",
    "*   \"If I were to take many, many samples and construct an interval for each, I would expect 95% of those intervals to contain the true population proportion.\"\n",
    "\n",
    "**Incorrect Interpretation:**\n",
    "*   \"There is a 95% chance that the true proportion `p` is in my interval [0.52, 0.58].\" (This is wrong!)\n",
    "\n",
    "---\n",
    "\n",
    "### Conditions for a Valid Confidence Interval for a Proportion\n",
    "\n",
    "For the math behind the confidence interval to be reliable, we must check the same conditions we did for the sampling distribution.\n",
    "\n",
    "1.  **Random:** The data must come from a well-designed random sample or randomized experiment. This prevents bias.\n",
    "2.  **Independent (10% Rule):** The sample size `n` should be no more than 10% of the population size `N` (`n ≤ 0.10N`).\n",
    "3.  **Large Counts Condition (Normality):** Since we don't know the true `p`, we use our sample proportion `p̂` as our best guess. The condition requires that the number of successes and failures *in our sample* are both at least 10.\n",
    "    *   **n * p̂ ≥ 10**  and  **n * (1-p̂) ≥ 10**\n",
    "\n",
    "---\n",
    "\n",
    "### Critical Value (z*) for a Given Confidence Level\n",
    "\n",
    "#### Theory\n",
    "The **critical value**, denoted **z*** (read \"z-star\"), defines the width of our interval. It's the number of standard deviations we need to go out from the mean of a standard Normal distribution to capture the central area equal to our confidence level.\n",
    "\n",
    "*   For a **95%** confidence interval, we want the central 95% of the distribution. This leaves 5% for the tails, or 2.5% in each tail. We need the Z-score that corresponds to the 97.5th percentile (1 - 0.025). This value is **z* = 1.96**.\n",
    "*   For a **90%** confidence interval, we leave 5% in each tail. We need the Z-score for the 95th percentile. This value is **z* = 1.645**.\n",
    "*   For a **99%** confidence interval, we leave 0.5% in each tail. We need the Z-score for the 99.5th percentile. This value is **z* = 2.576**.\n",
    "\n",
    "---\n",
    "\n",
    "### Constructing and Interpreting a Confidence Interval for `p`\n",
    "\n",
    "#### Theory\n",
    "Now we combine all the pieces. The formula for a one-sample z-interval for a population proportion `p` is:\n",
    "**p̂ ± z* * √[ p̂(1-p̂) / n ]**\n",
    "\n",
    "Let's break it down:\n",
    "*   `p̂`: The point estimate (from our sample).\n",
    "*   `z*`: The critical value (determined by the confidence level).\n",
    "*   `√[ p̂(1-p̂) / n ]`: This is the **Standard Error of the Proportion (SE_{p̂})**. It's our estimate of the standard deviation of the sampling distribution, since we have to use `p̂` instead of the unknown `p`.\n",
    "*   The entire `z* * SE_{p̂}` part is the **Margin of Error (ME)**.\n",
    "\n",
    "#### Calculation Example\n",
    "A city wants to build a new park and surveys 400 residents. 220 of them say they support the new park. Let's construct and interpret a 95% confidence interval.\n",
    "\n",
    "1.  **State:** We want to estimate the true proportion `p` of all city residents who support the park, with 95% confidence.\n",
    "2.  **Plan:** We will use a one-sample z-interval for `p`.\n",
    "    *   **Check Conditions:**\n",
    "        *   **Random:** The problem states it was a survey, we assume it was random.\n",
    "        *   **Independent:** 400 residents is likely less than 10% of all residents in a city.\n",
    "        *   **Large Counts:** `p̂ = 220/400 = 0.55`.\n",
    "            *   `n * p̂ = 400 * 0.55 = 220` (which is ≥ 10).\n",
    "            *   `n * (1-p̂) = 400 * 0.45 = 180` (which is ≥ 10).\n",
    "        *   Conditions are met.\n",
    "3.  **Do:**\n",
    "    *   `p̂ = 0.55`\n",
    "    *   `z*` for 95% confidence is `1.96`.\n",
    "    *   `SE_{p̂} = √[ 0.55(1-0.55) / 400 ] = √[ 0.2475 / 400 ] ≈ 0.02487`\n",
    "    *   `ME = z* * SE_{p̂} = 1.96 * 0.02487 ≈ 0.04875`\n",
    "    *   **Interval = p̂ ± ME = 0.55 ± 0.04875**\n",
    "    *   Interval = (0.50125, 0.59875) or about **(50.1%, 59.9%)**\n",
    "\n",
    "4.  **Conclude:** \"We are 95% confident that the interval from 50.1% to 59.9% captures the true proportion of all city residents who support building the new park.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Determining Sample Size\n",
    "\n",
    "#### Theory\n",
    "What if we want to plan a study and need to achieve a specific margin of error? We can work backward from the margin of error formula to solve for the required sample size `n`.\n",
    "\n",
    "`ME = z* * √[ p*(1-p*) / n ]`\n",
    "Solving for `n` gives:\n",
    "**n = (z* / ME)² * p*(1-p*)**\n",
    "\n",
    "There's a catch: to calculate the sample size `n`, we need `p*`, which is a guess for the true proportion `p`... which we don't know yet! We have two options:\n",
    "1.  **Use a prior estimate:** If a similar study has been done before, use that `p̂` as your guess for `p*`.\n",
    "2.  **Be conservative (most common):** Use **p* = 0.5**. The term `p*(1-p*)` is maximized when `p*=0.5`. Using this value will guarantee your sample size is large enough to achieve the desired margin of error, regardless of the true value of `p`.\n",
    "\n",
    "#### Calculation Example\n",
    "A political campaign wants to estimate its candidate's support with **95% confidence** and a **margin of error of no more than 3%** (`ME = 0.03`). How many people do they need to survey?\n",
    "\n",
    "1.  `z*` for 95% confidence is `1.96`.\n",
    "2.  `ME = 0.03`.\n",
    "3.  Since they have no prior information, they must use the conservative estimate `p* = 0.5`.\n",
    "4.  `n = (1.96 / 0.03)² * 0.5(1-0.5)`\n",
    "    `n = (65.333)² * 0.25`\n",
    "    `n = 4268.4 * 0.25 ≈ 1067.1`\n",
    "\n",
    "Since we can't survey a fraction of a person, we **always round up** to the next whole number. They need to survey **1068** people.\n",
    "\n",
    "***\n",
    "\n",
    "### Python Code Illustration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0910f7e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
